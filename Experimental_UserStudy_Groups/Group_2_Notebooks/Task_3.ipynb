{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "b4bcefbe0a41f"
   },
   "source": [
    "Before beginning task 3, make sure to run the following cell to import all necessary packages. If you need any additional packages, add the import statement(s) to the cell below and re-run the cell before adding and running code that uses the additional packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "comet_cell_id": "2c7cd3e562e7"
   },
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "# dataset\n",
    "from aif360.datasets import AdultDataset\n",
    "\n",
    "# metrics\n",
    "from fklearn.metric_library import UnifiedMetricLibrary, classifier_quality_score\n",
    "\n",
    "# models\n",
    "from fklearn.scikit_learn_wrapper import LogisticRegression, KNeighborsClassifier, RandomForestClassifier, SVC\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "# pre/post-processing algorithms\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing, RejectOptionClassification\n",
    "\n",
    "from fklearn.fair_selection_aif import ModelSearch, DEFAULT_ADB_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "46991f420accb"
   },
   "source": [
    "# Tutorial 3: fairkit-learn\n",
    "\n",
    "Lastly, we show you how to train and evaluate models using fairkit-learn. You will use the knowledge from this tutorial to complete Task 3, so please read thoroughly and execute the code cells in order.\n",
    "\n",
    "## Step 1: Import the dataset\n",
    "\n",
    "First we need to import the dataset we will use for training and testing our model.\n",
    "\n",
    "Below, we provide code that imports the Adult census dataset. **Note: a warning may pop up when you run this cell. As long as you don't see any errors in the code, it is fine to continue.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "comet_cell_id": "936840797dfba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    }
   ],
   "source": [
    "data_orig = AdultDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "1f7cb8ab1c822"
   },
   "source": [
    "## Step 2: Set protected attributes\n",
    "\n",
    "To use the grid search functionality provided by fairkit-learn, we again need to specify the privileged and unprivileged (protected) attributes. \n",
    "\n",
    "Below we provide code that stores the protected attributes (*race* is 0 for \"Non-white\", *sex* is 0 for \"Female\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "comet_cell_id": "8f3e98f0712d1"
   },
   "outputs": [],
   "source": [
    "unprivileged = [{'race': 0, 'sex': 0}]\n",
    "privileged = [{'race': 1, 'sex': 1}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "8e6392efce817"
   },
   "source": [
    "## Step 3: Specify parameters for grid search\n",
    "\n",
    "Now we need to specify the various parameters required for the grid search provided by fairkit-learn. Each search parameter is a dictionary of options to include in the search. For each search parameter, you can input one or multiple options to consider. \n",
    "\n",
    "Below we provide code that sets parameters for a simple grid search across different hyper-parameter values for the Logistic Regression model, with and without the specified pre-/post-processing algorithms. We specify all performance and fairness metrics for the search -- given the way the classifier quality score is calculated, this cannot be added to the grid search and will be calculated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "comet_cell_id": "e89b66337a2a6"
   },
   "outputs": [],
   "source": [
    "# we use one model here\n",
    "models = {'LogisticRegression': LogisticRegression, 'RandomForestClassifier': RandomForestClassifier,\n",
    "          'AdversarialDebiasing': AdversarialDebiasing}\n",
    "\n",
    "# here we add all the metrics we want to evaluate on (performance and fairness)\n",
    "metrics = {'UnifiedMetricLibrary': [UnifiedMetricLibrary,\n",
    "                                    'accuracy_score',\n",
    "                                    'average_odds_difference',\n",
    "                                    'statistical_parity_difference',\n",
    "                                    'equal_opportunity_difference',\n",
    "                                    'disparate_impact'\n",
    "                                   ]\n",
    "          }\n",
    "\n",
    "# Hyperparameters may either be specified as a dictionary of string to lists, or by an empty dictionary to\n",
    "# use the default ones set by sklearn (or AIF360). The keys are the names of the hyperparameters, and the\n",
    "# values and lists of possible values to form a grid search over (example shown with LogisticRegression)\n",
    "\n",
    "# For the AdversarialDebiasing classifier, you would specify hyperparameters using the following dictionary\n",
    "# entry:\n",
    "# 'AdversarialDebiasing' : DEFAULT_ADB_PARAMS(unprivileged=unprivileged, privileged=privileged)\n",
    "\n",
    "hyperparameters = {'LogisticRegression':{'penalty': ['l1', 'l2'], 'C': [0.1, 0.5, 1]},\n",
    "                   'RandomForestClassifier':{},\n",
    "                  'AdversarialDebiasing': DEFAULT_ADB_PARAMS(unprivileged=unprivileged, privileged=privileged)                  }\n",
    "\n",
    "# this parameter is needed for the search and does not need to be modified\n",
    "thresholds = [i * 10.0/100 for i in range(5)]\n",
    "\n",
    "# Specify pre/post-processors as a list of initialized AIF360 pre/post-processing instances; \n",
    "# you can also run without any pre/post-processing algorithms (empty list)\n",
    "processor_args = {'unprivileged_groups': unprivileged, 'privileged_groups': privileged}\n",
    "\n",
    "# Options: DisparateImpactRemover(), Reweighing(unprivileged_groups=unprivileged,privileged_groups=privileged), or both\n",
    "preprocessors=[DisparateImpactRemover(), Reweighing(**processor_args)]\n",
    "# Options: CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged,privileged_groups=privileged), RejectOptionClassification(unprivileged_groups=unprivileged,privileged_groups=privileged), or both\n",
    "postprocessors=[CalibratedEqOddsPostprocessing(**processor_args), RejectOptionClassification(**processor_args)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "7bba44eb7e995"
   },
   "source": [
    "## Step 4: Run the grid search\n",
    "\n",
    "Now that we've set all the parameters necessary for the grid search, we're ready to run it. The output of the grid search is saved to a .csv file.\n",
    "\n",
    "Below we provide code that creates and uses the `ModelSearch` object to run a grid search over the parameters we specified and saves the output to a .csv file in the specified directory.  **The search take a while to complete. Wait until the search completes before attempting to execute more cells.**\n",
    "\n",
    "**Note: warnings may appear during search, however, as long as you donâ€™t see any code errors it is fine to continue.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "470c3e83a0934"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bjohnson/anaconda3/envs/fairkit-learn/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 54.887466; batch adversarial loss: 1.003274\n",
      "epoch 0; iter: 200; batch classifier loss: 5.715112; batch adversarial loss: 0.646678\n",
      "epoch 1; iter: 0; batch classifier loss: 10.366486; batch adversarial loss: 0.655044\n",
      "epoch 1; iter: 200; batch classifier loss: 4.235228; batch adversarial loss: 0.635479\n",
      "epoch 2; iter: 0; batch classifier loss: 5.100244; batch adversarial loss: 0.571705\n",
      "epoch 2; iter: 200; batch classifier loss: 2.136794; batch adversarial loss: 0.533594\n",
      "epoch 3; iter: 0; batch classifier loss: 0.483770; batch adversarial loss: 0.520919\n",
      "epoch 3; iter: 200; batch classifier loss: 1.424919; batch adversarial loss: 0.469341\n",
      "epoch 4; iter: 0; batch classifier loss: 1.732073; batch adversarial loss: 0.497323\n",
      "epoch 4; iter: 200; batch classifier loss: 0.547906; batch adversarial loss: 0.438416\n",
      "epoch 5; iter: 0; batch classifier loss: 0.655766; batch adversarial loss: 0.454126\n",
      "epoch 5; iter: 200; batch classifier loss: 1.014563; batch adversarial loss: 0.530376\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549786; batch adversarial loss: 0.497668\n",
      "epoch 6; iter: 200; batch classifier loss: 0.476599; batch adversarial loss: 0.464443\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520617; batch adversarial loss: 0.429120\n",
      "epoch 7; iter: 200; batch classifier loss: 0.439203; batch adversarial loss: 0.436504\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506826; batch adversarial loss: 0.361051\n",
      "epoch 8; iter: 200; batch classifier loss: 0.563290; batch adversarial loss: 0.493916\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384968; batch adversarial loss: 0.417970\n",
      "epoch 9; iter: 200; batch classifier loss: 0.566154; batch adversarial loss: 0.391075\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571964; batch adversarial loss: 0.363791\n",
      "epoch 10; iter: 200; batch classifier loss: 0.350056; batch adversarial loss: 0.349334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526332; batch adversarial loss: 0.430342\n",
      "epoch 11; iter: 200; batch classifier loss: 0.384792; batch adversarial loss: 0.414985\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325362; batch adversarial loss: 0.445612\n",
      "epoch 12; iter: 200; batch classifier loss: 0.399499; batch adversarial loss: 0.393316\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455602; batch adversarial loss: 0.455518\n",
      "epoch 13; iter: 200; batch classifier loss: 0.459606; batch adversarial loss: 0.453084\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352679; batch adversarial loss: 0.288742\n",
      "epoch 14; iter: 200; batch classifier loss: 0.364078; batch adversarial loss: 0.393888\n",
      "epoch 15; iter: 0; batch classifier loss: 0.441375; batch adversarial loss: 0.426999\n",
      "epoch 15; iter: 200; batch classifier loss: 0.437686; batch adversarial loss: 0.390249\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402266; batch adversarial loss: 0.483420\n",
      "epoch 16; iter: 200; batch classifier loss: 0.276104; batch adversarial loss: 0.349118\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340000; batch adversarial loss: 0.412768\n",
      "epoch 17; iter: 200; batch classifier loss: 0.481917; batch adversarial loss: 0.442920\n",
      "epoch 18; iter: 0; batch classifier loss: 0.288811; batch adversarial loss: 0.416406\n",
      "epoch 18; iter: 200; batch classifier loss: 0.318529; batch adversarial loss: 0.461565\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337113; batch adversarial loss: 0.416210\n",
      "epoch 19; iter: 200; batch classifier loss: 0.307111; batch adversarial loss: 0.441656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.399326; batch adversarial loss: 0.420615\n",
      "epoch 20; iter: 200; batch classifier loss: 0.387844; batch adversarial loss: 0.406280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485917; batch adversarial loss: 0.364887\n",
      "epoch 21; iter: 200; batch classifier loss: 0.353828; batch adversarial loss: 0.332541\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246014; batch adversarial loss: 0.363280\n",
      "epoch 22; iter: 200; batch classifier loss: 0.352105; batch adversarial loss: 0.464573\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448071; batch adversarial loss: 0.402844\n",
      "epoch 23; iter: 200; batch classifier loss: 0.347223; batch adversarial loss: 0.397374\n",
      "epoch 24; iter: 0; batch classifier loss: 0.294030; batch adversarial loss: 0.517517\n",
      "epoch 24; iter: 200; batch classifier loss: 0.295614; batch adversarial loss: 0.361324\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344234; batch adversarial loss: 0.320224\n",
      "epoch 25; iter: 200; batch classifier loss: 0.363370; batch adversarial loss: 0.310702\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276262; batch adversarial loss: 0.538712\n",
      "epoch 26; iter: 200; batch classifier loss: 0.308234; batch adversarial loss: 0.443852\n",
      "epoch 27; iter: 0; batch classifier loss: 0.334165; batch adversarial loss: 0.442977\n",
      "epoch 27; iter: 200; batch classifier loss: 0.315616; batch adversarial loss: 0.439939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.784895; batch adversarial loss: 0.391522\n",
      "epoch 28; iter: 200; batch classifier loss: 0.297791; batch adversarial loss: 0.415810\n",
      "epoch 29; iter: 0; batch classifier loss: 0.291953; batch adversarial loss: 0.395389\n",
      "epoch 29; iter: 200; batch classifier loss: 0.450324; batch adversarial loss: 0.385225\n",
      "epoch 30; iter: 0; batch classifier loss: 0.334723; batch adversarial loss: 0.421450\n",
      "epoch 30; iter: 200; batch classifier loss: 0.279477; batch adversarial loss: 0.318071\n",
      "epoch 31; iter: 0; batch classifier loss: 0.339347; batch adversarial loss: 0.449787\n",
      "epoch 31; iter: 200; batch classifier loss: 0.334238; batch adversarial loss: 0.427947\n",
      "epoch 32; iter: 0; batch classifier loss: 0.313331; batch adversarial loss: 0.384776\n",
      "epoch 32; iter: 200; batch classifier loss: 0.358752; batch adversarial loss: 0.331454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417247; batch adversarial loss: 0.480705\n",
      "epoch 33; iter: 200; batch classifier loss: 0.284771; batch adversarial loss: 0.398680\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327902; batch adversarial loss: 0.407897\n",
      "epoch 34; iter: 200; batch classifier loss: 0.292557; batch adversarial loss: 0.347520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.272759; batch adversarial loss: 0.386651\n",
      "epoch 35; iter: 200; batch classifier loss: 0.294533; batch adversarial loss: 0.467784\n",
      "epoch 36; iter: 0; batch classifier loss: 0.313680; batch adversarial loss: 0.399482\n",
      "epoch 36; iter: 200; batch classifier loss: 0.309702; batch adversarial loss: 0.376663\n",
      "epoch 37; iter: 0; batch classifier loss: 0.291829; batch adversarial loss: 0.387278\n",
      "epoch 37; iter: 200; batch classifier loss: 0.343677; batch adversarial loss: 0.500729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.301164; batch adversarial loss: 0.477619\n",
      "epoch 38; iter: 200; batch classifier loss: 0.312093; batch adversarial loss: 0.339827\n",
      "epoch 39; iter: 0; batch classifier loss: 0.361274; batch adversarial loss: 0.421161\n",
      "epoch 39; iter: 200; batch classifier loss: 0.376595; batch adversarial loss: 0.474587\n",
      "epoch 40; iter: 0; batch classifier loss: 0.287291; batch adversarial loss: 0.423114\n",
      "epoch 40; iter: 200; batch classifier loss: 0.336544; batch adversarial loss: 0.439622\n",
      "epoch 41; iter: 0; batch classifier loss: 0.309833; batch adversarial loss: 0.371870\n",
      "epoch 41; iter: 200; batch classifier loss: 0.362111; batch adversarial loss: 0.318808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.250073; batch adversarial loss: 0.458194\n",
      "epoch 42; iter: 200; batch classifier loss: 0.356795; batch adversarial loss: 0.374033\n",
      "epoch 43; iter: 0; batch classifier loss: 0.306186; batch adversarial loss: 0.497856\n",
      "epoch 43; iter: 200; batch classifier loss: 0.358681; batch adversarial loss: 0.446086\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431187; batch adversarial loss: 0.403766\n",
      "epoch 44; iter: 200; batch classifier loss: 0.327225; batch adversarial loss: 0.558786\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368608; batch adversarial loss: 0.458679\n",
      "epoch 45; iter: 200; batch classifier loss: 0.392729; batch adversarial loss: 0.343611\n",
      "epoch 46; iter: 0; batch classifier loss: 0.316098; batch adversarial loss: 0.452681\n",
      "epoch 46; iter: 200; batch classifier loss: 0.309440; batch adversarial loss: 0.415853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.316597; batch adversarial loss: 0.388761\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369854; batch adversarial loss: 0.440665\n",
      "epoch 48; iter: 0; batch classifier loss: 0.327807; batch adversarial loss: 0.403074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 200; batch classifier loss: 0.385514; batch adversarial loss: 0.316370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437600; batch adversarial loss: 0.348870\n",
      "epoch 49; iter: 200; batch classifier loss: 0.435185; batch adversarial loss: 0.394058\n",
      "epoch 0; iter: 0; batch classifier loss: 70.984344; batch adversarial loss: 0.830426\n",
      "epoch 0; iter: 200; batch classifier loss: 22.551861; batch adversarial loss: 0.701002\n",
      "epoch 1; iter: 0; batch classifier loss: 7.257968; batch adversarial loss: 0.695446\n",
      "epoch 1; iter: 200; batch classifier loss: 3.941057; batch adversarial loss: 0.565313\n",
      "epoch 2; iter: 0; batch classifier loss: 1.924273; batch adversarial loss: 0.553151\n",
      "epoch 2; iter: 200; batch classifier loss: 0.942435; batch adversarial loss: 0.508871\n",
      "epoch 3; iter: 0; batch classifier loss: 1.816519; batch adversarial loss: 0.527285\n",
      "epoch 3; iter: 200; batch classifier loss: 1.674798; batch adversarial loss: 0.465521\n",
      "epoch 4; iter: 0; batch classifier loss: 1.291459; batch adversarial loss: 0.434069\n",
      "epoch 4; iter: 200; batch classifier loss: 0.952845; batch adversarial loss: 0.427350\n",
      "epoch 5; iter: 0; batch classifier loss: 1.196889; batch adversarial loss: 0.456638\n",
      "epoch 5; iter: 200; batch classifier loss: 0.981189; batch adversarial loss: 0.385334\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451161; batch adversarial loss: 0.495169\n",
      "epoch 6; iter: 200; batch classifier loss: 0.444450; batch adversarial loss: 0.384495\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454286; batch adversarial loss: 0.478315\n",
      "epoch 7; iter: 200; batch classifier loss: 0.500418; batch adversarial loss: 0.449832\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465683; batch adversarial loss: 0.543531\n",
      "epoch 8; iter: 200; batch classifier loss: 0.829485; batch adversarial loss: 0.450353\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536047; batch adversarial loss: 0.435273\n",
      "epoch 9; iter: 200; batch classifier loss: 0.462592; batch adversarial loss: 0.478177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472673; batch adversarial loss: 0.413395\n",
      "epoch 10; iter: 200; batch classifier loss: 0.412085; batch adversarial loss: 0.453762\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416935; batch adversarial loss: 0.542488\n",
      "epoch 11; iter: 200; batch classifier loss: 0.411438; batch adversarial loss: 0.413615\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437098; batch adversarial loss: 0.447438\n",
      "epoch 12; iter: 200; batch classifier loss: 0.524003; batch adversarial loss: 0.434542\n",
      "epoch 13; iter: 0; batch classifier loss: 0.444000; batch adversarial loss: 0.426048\n",
      "epoch 13; iter: 200; batch classifier loss: 0.384348; batch adversarial loss: 0.334183\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393953; batch adversarial loss: 0.453488\n",
      "epoch 14; iter: 200; batch classifier loss: 0.354494; batch adversarial loss: 0.459775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366033; batch adversarial loss: 0.469705\n",
      "epoch 15; iter: 200; batch classifier loss: 0.418046; batch adversarial loss: 0.441220\n",
      "epoch 16; iter: 0; batch classifier loss: 0.457765; batch adversarial loss: 0.423434\n",
      "epoch 16; iter: 200; batch classifier loss: 0.345338; batch adversarial loss: 0.418507\n",
      "epoch 17; iter: 0; batch classifier loss: 0.413930; batch adversarial loss: 0.408364\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370987; batch adversarial loss: 0.365346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342289; batch adversarial loss: 0.416886\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367393; batch adversarial loss: 0.412230\n",
      "epoch 19; iter: 0; batch classifier loss: 0.320347; batch adversarial loss: 0.401361\n",
      "epoch 19; iter: 200; batch classifier loss: 0.352285; batch adversarial loss: 0.444934\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333735; batch adversarial loss: 0.407768\n",
      "epoch 20; iter: 200; batch classifier loss: 0.319969; batch adversarial loss: 0.318325\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457539; batch adversarial loss: 0.427001\n",
      "epoch 21; iter: 200; batch classifier loss: 0.460404; batch adversarial loss: 0.424333\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282302; batch adversarial loss: 0.383353\n",
      "epoch 22; iter: 200; batch classifier loss: 0.289810; batch adversarial loss: 0.461621\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287772; batch adversarial loss: 0.433678\n",
      "epoch 23; iter: 200; batch classifier loss: 0.252342; batch adversarial loss: 0.477174\n",
      "epoch 24; iter: 0; batch classifier loss: 0.342633; batch adversarial loss: 0.412135\n",
      "epoch 24; iter: 200; batch classifier loss: 0.429500; batch adversarial loss: 0.408092\n",
      "epoch 25; iter: 0; batch classifier loss: 0.447816; batch adversarial loss: 0.507876\n",
      "epoch 25; iter: 200; batch classifier loss: 0.444393; batch adversarial loss: 0.402932\n",
      "epoch 26; iter: 0; batch classifier loss: 0.322340; batch adversarial loss: 0.440019\n",
      "epoch 26; iter: 200; batch classifier loss: 0.341244; batch adversarial loss: 0.417765\n",
      "epoch 27; iter: 0; batch classifier loss: 0.370377; batch adversarial loss: 0.358097\n",
      "epoch 27; iter: 200; batch classifier loss: 0.426366; batch adversarial loss: 0.362480\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369188; batch adversarial loss: 0.402702\n",
      "epoch 28; iter: 200; batch classifier loss: 0.288038; batch adversarial loss: 0.404321\n",
      "epoch 29; iter: 0; batch classifier loss: 0.367239; batch adversarial loss: 0.461507\n",
      "epoch 29; iter: 200; batch classifier loss: 0.328732; batch adversarial loss: 0.441367\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315286; batch adversarial loss: 0.359090\n",
      "epoch 30; iter: 200; batch classifier loss: 0.305912; batch adversarial loss: 0.409734\n",
      "epoch 31; iter: 0; batch classifier loss: 0.343200; batch adversarial loss: 0.408014\n",
      "epoch 31; iter: 200; batch classifier loss: 0.301234; batch adversarial loss: 0.470281\n",
      "epoch 32; iter: 0; batch classifier loss: 0.353588; batch adversarial loss: 0.422355\n",
      "epoch 32; iter: 200; batch classifier loss: 0.363574; batch adversarial loss: 0.310446\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318899; batch adversarial loss: 0.418586\n",
      "epoch 33; iter: 200; batch classifier loss: 0.298915; batch adversarial loss: 0.423852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.321669; batch adversarial loss: 0.276198\n",
      "epoch 34; iter: 200; batch classifier loss: 0.250688; batch adversarial loss: 0.330809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.331281; batch adversarial loss: 0.355490\n",
      "epoch 35; iter: 200; batch classifier loss: 0.293248; batch adversarial loss: 0.436033\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480537; batch adversarial loss: 0.355262\n",
      "epoch 36; iter: 200; batch classifier loss: 0.372304; batch adversarial loss: 0.304161\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422243; batch adversarial loss: 0.350682\n",
      "epoch 37; iter: 200; batch classifier loss: 0.351192; batch adversarial loss: 0.382936\n",
      "epoch 38; iter: 0; batch classifier loss: 0.305256; batch adversarial loss: 0.503868\n",
      "epoch 38; iter: 200; batch classifier loss: 0.343755; batch adversarial loss: 0.390025\n",
      "epoch 39; iter: 0; batch classifier loss: 0.307877; batch adversarial loss: 0.475358\n",
      "epoch 39; iter: 200; batch classifier loss: 0.278652; batch adversarial loss: 0.519807\n",
      "epoch 40; iter: 0; batch classifier loss: 0.328467; batch adversarial loss: 0.499029\n",
      "epoch 40; iter: 200; batch classifier loss: 0.316449; batch adversarial loss: 0.372999\n",
      "epoch 41; iter: 0; batch classifier loss: 0.291224; batch adversarial loss: 0.311720\n",
      "epoch 41; iter: 200; batch classifier loss: 0.291069; batch adversarial loss: 0.400561\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408915; batch adversarial loss: 0.511944\n",
      "epoch 42; iter: 200; batch classifier loss: 0.381499; batch adversarial loss: 0.347395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270699; batch adversarial loss: 0.402125\n",
      "epoch 43; iter: 200; batch classifier loss: 0.330198; batch adversarial loss: 0.420661\n",
      "epoch 44; iter: 0; batch classifier loss: 0.359929; batch adversarial loss: 0.297198\n",
      "epoch 44; iter: 200; batch classifier loss: 0.356072; batch adversarial loss: 0.363495\n",
      "epoch 45; iter: 0; batch classifier loss: 0.282269; batch adversarial loss: 0.348400\n",
      "epoch 45; iter: 200; batch classifier loss: 0.328760; batch adversarial loss: 0.389395\n",
      "epoch 46; iter: 0; batch classifier loss: 0.321033; batch adversarial loss: 0.402384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 200; batch classifier loss: 0.257916; batch adversarial loss: 0.469531\n",
      "epoch 47; iter: 0; batch classifier loss: 0.345392; batch adversarial loss: 0.299593\n",
      "epoch 47; iter: 200; batch classifier loss: 0.312110; batch adversarial loss: 0.371880\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406908; batch adversarial loss: 0.377222\n",
      "epoch 48; iter: 200; batch classifier loss: 0.266886; batch adversarial loss: 0.396561\n",
      "epoch 49; iter: 0; batch classifier loss: 0.308528; batch adversarial loss: 0.413882\n",
      "epoch 49; iter: 200; batch classifier loss: 0.469918; batch adversarial loss: 0.288544\n",
      "epoch 0; iter: 0; batch classifier loss: 27.580425; batch adversarial loss: 0.836468\n",
      "epoch 0; iter: 200; batch classifier loss: 4.694711; batch adversarial loss: 0.626460\n",
      "epoch 1; iter: 0; batch classifier loss: 7.703262; batch adversarial loss: 0.633186\n",
      "epoch 1; iter: 200; batch classifier loss: 1.808448; batch adversarial loss: 0.565212\n",
      "epoch 2; iter: 0; batch classifier loss: 1.942724; batch adversarial loss: 0.545644\n",
      "epoch 2; iter: 200; batch classifier loss: 2.226718; batch adversarial loss: 0.550660\n",
      "epoch 3; iter: 0; batch classifier loss: 2.919845; batch adversarial loss: 0.467665\n",
      "epoch 3; iter: 200; batch classifier loss: 0.717258; batch adversarial loss: 0.461307\n",
      "epoch 4; iter: 0; batch classifier loss: 0.925416; batch adversarial loss: 0.501434\n",
      "epoch 4; iter: 200; batch classifier loss: 0.765185; batch adversarial loss: 0.481818\n",
      "epoch 5; iter: 0; batch classifier loss: 1.333666; batch adversarial loss: 0.465895\n",
      "epoch 5; iter: 200; batch classifier loss: 4.417207; batch adversarial loss: 0.432556\n",
      "epoch 6; iter: 0; batch classifier loss: 1.050827; batch adversarial loss: 0.387583\n",
      "epoch 6; iter: 200; batch classifier loss: 0.390370; batch adversarial loss: 0.467457\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547704; batch adversarial loss: 0.505638\n",
      "epoch 7; iter: 200; batch classifier loss: 0.394511; batch adversarial loss: 0.417166\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486668; batch adversarial loss: 0.381476\n",
      "epoch 8; iter: 200; batch classifier loss: 0.498685; batch adversarial loss: 0.436970\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516308; batch adversarial loss: 0.418722\n",
      "epoch 9; iter: 200; batch classifier loss: 0.856306; batch adversarial loss: 0.366048\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447102; batch adversarial loss: 0.414620\n",
      "epoch 10; iter: 200; batch classifier loss: 0.436316; batch adversarial loss: 0.417661\n",
      "epoch 11; iter: 0; batch classifier loss: 0.904828; batch adversarial loss: 0.380810\n",
      "epoch 11; iter: 200; batch classifier loss: 0.422951; batch adversarial loss: 0.420139\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408860; batch adversarial loss: 0.439485\n",
      "epoch 12; iter: 200; batch classifier loss: 0.362271; batch adversarial loss: 0.434319\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462426; batch adversarial loss: 0.414777\n",
      "epoch 13; iter: 200; batch classifier loss: 0.315666; batch adversarial loss: 0.378530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406680; batch adversarial loss: 0.355418\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358165; batch adversarial loss: 0.457206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.429524; batch adversarial loss: 0.420680\n",
      "epoch 15; iter: 200; batch classifier loss: 0.331863; batch adversarial loss: 0.386974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330779; batch adversarial loss: 0.428524\n",
      "epoch 16; iter: 200; batch classifier loss: 0.379992; batch adversarial loss: 0.423007\n",
      "epoch 17; iter: 0; batch classifier loss: 0.378805; batch adversarial loss: 0.384367\n",
      "epoch 17; iter: 200; batch classifier loss: 0.415801; batch adversarial loss: 0.449743\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246493; batch adversarial loss: 0.432627\n",
      "epoch 18; iter: 200; batch classifier loss: 0.379619; batch adversarial loss: 0.433904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492597; batch adversarial loss: 0.385536\n",
      "epoch 19; iter: 200; batch classifier loss: 0.332302; batch adversarial loss: 0.377391\n",
      "epoch 20; iter: 0; batch classifier loss: 0.343001; batch adversarial loss: 0.367510\n",
      "epoch 20; iter: 200; batch classifier loss: 0.388723; batch adversarial loss: 0.365228\n",
      "epoch 21; iter: 0; batch classifier loss: 0.373533; batch adversarial loss: 0.362229\n",
      "epoch 21; iter: 200; batch classifier loss: 0.353863; batch adversarial loss: 0.272884\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329923; batch adversarial loss: 0.302507\n",
      "epoch 22; iter: 200; batch classifier loss: 0.421266; batch adversarial loss: 0.365765\n",
      "epoch 23; iter: 0; batch classifier loss: 0.382426; batch adversarial loss: 0.426280\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371992; batch adversarial loss: 0.349662\n",
      "epoch 24; iter: 0; batch classifier loss: 0.306212; batch adversarial loss: 0.424848\n",
      "epoch 24; iter: 200; batch classifier loss: 0.304137; batch adversarial loss: 0.416173\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326757; batch adversarial loss: 0.402032\n",
      "epoch 25; iter: 200; batch classifier loss: 0.397992; batch adversarial loss: 0.481806\n",
      "epoch 26; iter: 0; batch classifier loss: 0.360224; batch adversarial loss: 0.356404\n",
      "epoch 26; iter: 200; batch classifier loss: 0.364964; batch adversarial loss: 0.386526\n",
      "epoch 27; iter: 0; batch classifier loss: 0.371260; batch adversarial loss: 0.341735\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328185; batch adversarial loss: 0.461024\n",
      "epoch 28; iter: 0; batch classifier loss: 0.350938; batch adversarial loss: 0.423715\n",
      "epoch 28; iter: 200; batch classifier loss: 0.306330; batch adversarial loss: 0.396141\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425680; batch adversarial loss: 0.483503\n",
      "epoch 29; iter: 200; batch classifier loss: 0.391954; batch adversarial loss: 0.406465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.310376; batch adversarial loss: 0.369263\n",
      "epoch 30; iter: 200; batch classifier loss: 0.331176; batch adversarial loss: 0.357577\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302347; batch adversarial loss: 0.460257\n",
      "epoch 31; iter: 200; batch classifier loss: 0.401314; batch adversarial loss: 0.417793\n",
      "epoch 32; iter: 0; batch classifier loss: 0.388430; batch adversarial loss: 0.362415\n",
      "epoch 32; iter: 200; batch classifier loss: 0.367731; batch adversarial loss: 0.396188\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522524; batch adversarial loss: 0.427923\n",
      "epoch 33; iter: 200; batch classifier loss: 0.378066; batch adversarial loss: 0.384235\n",
      "epoch 34; iter: 0; batch classifier loss: 0.285948; batch adversarial loss: 0.405648\n",
      "epoch 34; iter: 200; batch classifier loss: 0.324235; batch adversarial loss: 0.381000\n",
      "epoch 35; iter: 0; batch classifier loss: 0.366846; batch adversarial loss: 0.388572\n",
      "epoch 35; iter: 200; batch classifier loss: 0.253536; batch adversarial loss: 0.467095\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366578; batch adversarial loss: 0.295843\n",
      "epoch 36; iter: 200; batch classifier loss: 0.267424; batch adversarial loss: 0.400121\n",
      "epoch 37; iter: 0; batch classifier loss: 0.337617; batch adversarial loss: 0.391436\n",
      "epoch 37; iter: 200; batch classifier loss: 0.368219; batch adversarial loss: 0.360229\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442187; batch adversarial loss: 0.392691\n",
      "epoch 38; iter: 200; batch classifier loss: 0.290901; batch adversarial loss: 0.370651\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457112; batch adversarial loss: 0.410016\n",
      "epoch 39; iter: 200; batch classifier loss: 0.311458; batch adversarial loss: 0.359780\n",
      "epoch 40; iter: 0; batch classifier loss: 0.298023; batch adversarial loss: 0.385855\n",
      "epoch 40; iter: 200; batch classifier loss: 0.393102; batch adversarial loss: 0.493737\n",
      "epoch 41; iter: 0; batch classifier loss: 0.311552; batch adversarial loss: 0.381559\n",
      "epoch 41; iter: 200; batch classifier loss: 0.357390; batch adversarial loss: 0.411096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357660; batch adversarial loss: 0.359173\n",
      "epoch 42; iter: 200; batch classifier loss: 0.343760; batch adversarial loss: 0.417636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.311655; batch adversarial loss: 0.397387\n",
      "epoch 43; iter: 200; batch classifier loss: 0.340288; batch adversarial loss: 0.403522\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336463; batch adversarial loss: 0.473378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 200; batch classifier loss: 0.278117; batch adversarial loss: 0.440354\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382031; batch adversarial loss: 0.304193\n",
      "epoch 45; iter: 200; batch classifier loss: 0.402520; batch adversarial loss: 0.479109\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377590; batch adversarial loss: 0.367668\n",
      "epoch 46; iter: 200; batch classifier loss: 0.295521; batch adversarial loss: 0.368840\n",
      "epoch 47; iter: 0; batch classifier loss: 0.346250; batch adversarial loss: 0.361970\n",
      "epoch 47; iter: 200; batch classifier loss: 0.312633; batch adversarial loss: 0.438291\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404884; batch adversarial loss: 0.306957\n",
      "epoch 48; iter: 200; batch classifier loss: 0.243585; batch adversarial loss: 0.546587\n",
      "epoch 49; iter: 0; batch classifier loss: 0.328229; batch adversarial loss: 0.419319\n",
      "epoch 49; iter: 200; batch classifier loss: 0.328237; batch adversarial loss: 0.447410\n",
      "epoch 0; iter: 0; batch classifier loss: 21.507036; batch adversarial loss: 0.713650\n",
      "epoch 0; iter: 200; batch classifier loss: 11.603228; batch adversarial loss: 0.622148\n",
      "epoch 1; iter: 0; batch classifier loss: 5.634496; batch adversarial loss: 0.608931\n",
      "epoch 1; iter: 200; batch classifier loss: 3.719025; batch adversarial loss: 0.572934\n",
      "epoch 2; iter: 0; batch classifier loss: 4.667289; batch adversarial loss: 0.547559\n",
      "epoch 2; iter: 200; batch classifier loss: 0.969535; batch adversarial loss: 0.503270\n",
      "epoch 3; iter: 0; batch classifier loss: 2.212356; batch adversarial loss: 0.485879\n",
      "epoch 3; iter: 200; batch classifier loss: 1.110332; batch adversarial loss: 0.457834\n",
      "epoch 4; iter: 0; batch classifier loss: 5.321178; batch adversarial loss: 0.469158\n",
      "epoch 4; iter: 200; batch classifier loss: 0.888076; batch adversarial loss: 0.479119\n",
      "epoch 5; iter: 0; batch classifier loss: 0.808450; batch adversarial loss: 0.421320\n",
      "epoch 5; iter: 200; batch classifier loss: 0.818966; batch adversarial loss: 0.384968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577662; batch adversarial loss: 0.423477\n",
      "epoch 6; iter: 200; batch classifier loss: 0.400379; batch adversarial loss: 0.426050\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596867; batch adversarial loss: 0.443678\n",
      "epoch 7; iter: 200; batch classifier loss: 0.421149; batch adversarial loss: 0.453617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.371426; batch adversarial loss: 0.420784\n",
      "epoch 8; iter: 200; batch classifier loss: 0.362838; batch adversarial loss: 0.358672\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306711; batch adversarial loss: 0.370098\n",
      "epoch 9; iter: 200; batch classifier loss: 0.401227; batch adversarial loss: 0.370574\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466441; batch adversarial loss: 0.400253\n",
      "epoch 10; iter: 200; batch classifier loss: 0.334676; batch adversarial loss: 0.446502\n",
      "epoch 11; iter: 0; batch classifier loss: 0.399169; batch adversarial loss: 0.452068\n",
      "epoch 11; iter: 200; batch classifier loss: 0.353589; batch adversarial loss: 0.446159\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352457; batch adversarial loss: 0.410823\n",
      "epoch 12; iter: 200; batch classifier loss: 0.418198; batch adversarial loss: 0.377987\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323079; batch adversarial loss: 0.539752\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396324; batch adversarial loss: 0.434602\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387367; batch adversarial loss: 0.325579\n",
      "epoch 14; iter: 200; batch classifier loss: 0.291549; batch adversarial loss: 0.444127\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474142; batch adversarial loss: 0.345273\n",
      "epoch 15; iter: 200; batch classifier loss: 0.289382; batch adversarial loss: 0.449332\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271909; batch adversarial loss: 0.400908\n",
      "epoch 16; iter: 200; batch classifier loss: 0.344953; batch adversarial loss: 0.481447\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388027; batch adversarial loss: 0.391978\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388855; batch adversarial loss: 0.400029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378779; batch adversarial loss: 0.490446\n",
      "epoch 18; iter: 200; batch classifier loss: 0.365438; batch adversarial loss: 0.430021\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321129; batch adversarial loss: 0.424462\n",
      "epoch 19; iter: 200; batch classifier loss: 0.374185; batch adversarial loss: 0.482318\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281542; batch adversarial loss: 0.387695\n",
      "epoch 20; iter: 200; batch classifier loss: 0.352974; batch adversarial loss: 0.425856\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295434; batch adversarial loss: 0.365985\n",
      "epoch 21; iter: 200; batch classifier loss: 0.368488; batch adversarial loss: 0.392882\n",
      "epoch 22; iter: 0; batch classifier loss: 0.362873; batch adversarial loss: 0.338800\n",
      "epoch 22; iter: 200; batch classifier loss: 0.328697; batch adversarial loss: 0.384533\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311673; batch adversarial loss: 0.485801\n",
      "epoch 23; iter: 200; batch classifier loss: 0.248140; batch adversarial loss: 0.499601\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422199; batch adversarial loss: 0.428211\n",
      "epoch 24; iter: 200; batch classifier loss: 0.300176; batch adversarial loss: 0.405917\n",
      "epoch 25; iter: 0; batch classifier loss: 0.322438; batch adversarial loss: 0.384482\n",
      "epoch 25; iter: 200; batch classifier loss: 0.339523; batch adversarial loss: 0.486113\n",
      "epoch 26; iter: 0; batch classifier loss: 0.349379; batch adversarial loss: 0.395627\n",
      "epoch 26; iter: 200; batch classifier loss: 0.295350; batch adversarial loss: 0.359681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.326580; batch adversarial loss: 0.441561\n",
      "epoch 27; iter: 200; batch classifier loss: 0.370283; batch adversarial loss: 0.486464\n",
      "epoch 28; iter: 0; batch classifier loss: 0.306339; batch adversarial loss: 0.499831\n",
      "epoch 28; iter: 200; batch classifier loss: 0.331370; batch adversarial loss: 0.300316\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342508; batch adversarial loss: 0.433189\n",
      "epoch 29; iter: 200; batch classifier loss: 0.244101; batch adversarial loss: 0.390709\n",
      "epoch 30; iter: 0; batch classifier loss: 0.313826; batch adversarial loss: 0.375376\n",
      "epoch 30; iter: 200; batch classifier loss: 0.375374; batch adversarial loss: 0.494455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.291098; batch adversarial loss: 0.469277\n",
      "epoch 31; iter: 200; batch classifier loss: 0.395490; batch adversarial loss: 0.371781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.354492; batch adversarial loss: 0.417970\n",
      "epoch 32; iter: 200; batch classifier loss: 0.281718; batch adversarial loss: 0.425260\n",
      "epoch 33; iter: 0; batch classifier loss: 0.271843; batch adversarial loss: 0.389909\n",
      "epoch 33; iter: 200; batch classifier loss: 0.335259; batch adversarial loss: 0.351333\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392576; batch adversarial loss: 0.334927\n",
      "epoch 34; iter: 200; batch classifier loss: 0.335489; batch adversarial loss: 0.342442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.373858; batch adversarial loss: 0.394926\n",
      "epoch 35; iter: 200; batch classifier loss: 0.299777; batch adversarial loss: 0.349137\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365498; batch adversarial loss: 0.352919\n",
      "epoch 36; iter: 200; batch classifier loss: 0.373380; batch adversarial loss: 0.469627\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407270; batch adversarial loss: 0.389927\n",
      "epoch 37; iter: 200; batch classifier loss: 0.315089; batch adversarial loss: 0.427717\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405946; batch adversarial loss: 0.244310\n",
      "epoch 38; iter: 200; batch classifier loss: 0.375039; batch adversarial loss: 0.423048\n",
      "epoch 39; iter: 0; batch classifier loss: 0.320150; batch adversarial loss: 0.393622\n",
      "epoch 39; iter: 200; batch classifier loss: 0.416328; batch adversarial loss: 0.402458\n",
      "epoch 40; iter: 0; batch classifier loss: 0.339129; batch adversarial loss: 0.371212\n",
      "epoch 40; iter: 200; batch classifier loss: 0.275121; batch adversarial loss: 0.403582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.333063; batch adversarial loss: 0.427421\n",
      "epoch 41; iter: 200; batch classifier loss: 0.439771; batch adversarial loss: 0.372959\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350475; batch adversarial loss: 0.362250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 200; batch classifier loss: 0.332184; batch adversarial loss: 0.481640\n",
      "epoch 43; iter: 0; batch classifier loss: 0.298377; batch adversarial loss: 0.535090\n",
      "epoch 43; iter: 200; batch classifier loss: 0.283814; batch adversarial loss: 0.420943\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382865; batch adversarial loss: 0.395089\n",
      "epoch 44; iter: 200; batch classifier loss: 0.319452; batch adversarial loss: 0.473344\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387393; batch adversarial loss: 0.343189\n",
      "epoch 45; iter: 200; batch classifier loss: 0.367107; batch adversarial loss: 0.396017\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430934; batch adversarial loss: 0.403915\n",
      "epoch 46; iter: 200; batch classifier loss: 0.350209; batch adversarial loss: 0.496324\n",
      "epoch 47; iter: 0; batch classifier loss: 0.251705; batch adversarial loss: 0.399672\n",
      "epoch 47; iter: 200; batch classifier loss: 0.551083; batch adversarial loss: 0.342619\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335256; batch adversarial loss: 0.391755\n",
      "epoch 48; iter: 200; batch classifier loss: 0.322737; batch adversarial loss: 0.426899\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406250; batch adversarial loss: 0.450849\n",
      "epoch 49; iter: 200; batch classifier loss: 0.237003; batch adversarial loss: 0.370946\n",
      "epoch 0; iter: 0; batch classifier loss: 9.597620; batch adversarial loss: 0.486782\n",
      "epoch 0; iter: 200; batch classifier loss: 2.498873; batch adversarial loss: 0.531685\n",
      "epoch 1; iter: 0; batch classifier loss: 3.239024; batch adversarial loss: 0.569590\n",
      "epoch 1; iter: 200; batch classifier loss: 7.198884; batch adversarial loss: 0.514404\n",
      "epoch 2; iter: 0; batch classifier loss: 8.512027; batch adversarial loss: 0.498759\n",
      "epoch 2; iter: 200; batch classifier loss: 2.234089; batch adversarial loss: 0.455931\n",
      "epoch 3; iter: 0; batch classifier loss: 1.854280; batch adversarial loss: 0.404398\n",
      "epoch 3; iter: 200; batch classifier loss: 0.664536; batch adversarial loss: 0.419070\n",
      "epoch 4; iter: 0; batch classifier loss: 2.088266; batch adversarial loss: 0.424681\n",
      "epoch 4; iter: 200; batch classifier loss: 0.520297; batch adversarial loss: 0.449096\n",
      "epoch 5; iter: 0; batch classifier loss: 0.704824; batch adversarial loss: 0.459582\n",
      "epoch 5; iter: 200; batch classifier loss: 0.560076; batch adversarial loss: 0.417243\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574798; batch adversarial loss: 0.451610\n",
      "epoch 6; iter: 200; batch classifier loss: 0.447600; batch adversarial loss: 0.435604\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526106; batch adversarial loss: 0.497730\n",
      "epoch 7; iter: 200; batch classifier loss: 0.857025; batch adversarial loss: 0.446952\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581936; batch adversarial loss: 0.411021\n",
      "epoch 8; iter: 200; batch classifier loss: 0.363886; batch adversarial loss: 0.393173\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401542; batch adversarial loss: 0.446579\n",
      "epoch 9; iter: 200; batch classifier loss: 0.429432; batch adversarial loss: 0.479237\n",
      "epoch 10; iter: 0; batch classifier loss: 0.353669; batch adversarial loss: 0.459235\n",
      "epoch 10; iter: 200; batch classifier loss: 0.490577; batch adversarial loss: 0.436686\n",
      "epoch 11; iter: 0; batch classifier loss: 1.243226; batch adversarial loss: 0.430017\n",
      "epoch 11; iter: 200; batch classifier loss: 0.404459; batch adversarial loss: 0.483861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297153; batch adversarial loss: 0.401421\n",
      "epoch 12; iter: 200; batch classifier loss: 0.509567; batch adversarial loss: 0.519606\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504424; batch adversarial loss: 0.440928\n",
      "epoch 13; iter: 200; batch classifier loss: 0.427402; batch adversarial loss: 0.483240\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387965; batch adversarial loss: 0.340878\n",
      "epoch 14; iter: 200; batch classifier loss: 0.468016; batch adversarial loss: 0.444828\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324728; batch adversarial loss: 0.399361\n",
      "epoch 15; iter: 200; batch classifier loss: 0.431762; batch adversarial loss: 0.378548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.388697; batch adversarial loss: 0.416563\n",
      "epoch 16; iter: 200; batch classifier loss: 0.331813; batch adversarial loss: 0.420423\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352392; batch adversarial loss: 0.333109\n",
      "epoch 17; iter: 200; batch classifier loss: 0.365812; batch adversarial loss: 0.341353\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314251; batch adversarial loss: 0.453116\n",
      "epoch 18; iter: 200; batch classifier loss: 0.315951; batch adversarial loss: 0.451859\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334931; batch adversarial loss: 0.375656\n",
      "epoch 19; iter: 200; batch classifier loss: 0.426118; batch adversarial loss: 0.438867\n",
      "epoch 20; iter: 0; batch classifier loss: 0.335369; batch adversarial loss: 0.417485\n",
      "epoch 20; iter: 200; batch classifier loss: 0.326994; batch adversarial loss: 0.407912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.396037; batch adversarial loss: 0.401483\n",
      "epoch 21; iter: 200; batch classifier loss: 0.352725; batch adversarial loss: 0.428620\n",
      "epoch 22; iter: 0; batch classifier loss: 0.343322; batch adversarial loss: 0.342016\n",
      "epoch 22; iter: 200; batch classifier loss: 0.361320; batch adversarial loss: 0.501023\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359655; batch adversarial loss: 0.369988\n",
      "epoch 23; iter: 200; batch classifier loss: 0.330943; batch adversarial loss: 0.467657\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351453; batch adversarial loss: 0.371474\n",
      "epoch 24; iter: 200; batch classifier loss: 0.327586; batch adversarial loss: 0.355468\n",
      "epoch 25; iter: 0; batch classifier loss: 0.353743; batch adversarial loss: 0.483550\n",
      "epoch 25; iter: 200; batch classifier loss: 0.326299; batch adversarial loss: 0.542367\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397429; batch adversarial loss: 0.395533\n",
      "epoch 26; iter: 200; batch classifier loss: 0.353934; batch adversarial loss: 0.325758\n",
      "epoch 27; iter: 0; batch classifier loss: 0.361763; batch adversarial loss: 0.489001\n",
      "epoch 27; iter: 200; batch classifier loss: 0.315241; batch adversarial loss: 0.460158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362208; batch adversarial loss: 0.507785\n",
      "epoch 28; iter: 200; batch classifier loss: 0.326620; batch adversarial loss: 0.339428\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299843; batch adversarial loss: 0.430285\n",
      "epoch 29; iter: 200; batch classifier loss: 0.342615; batch adversarial loss: 0.273540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342392; batch adversarial loss: 0.383192\n",
      "epoch 30; iter: 200; batch classifier loss: 0.354033; batch adversarial loss: 0.444021\n",
      "epoch 31; iter: 0; batch classifier loss: 0.369123; batch adversarial loss: 0.300577\n",
      "epoch 31; iter: 200; batch classifier loss: 0.339770; batch adversarial loss: 0.447602\n",
      "epoch 32; iter: 0; batch classifier loss: 0.300494; batch adversarial loss: 0.360489\n",
      "epoch 32; iter: 200; batch classifier loss: 0.329072; batch adversarial loss: 0.427955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264953; batch adversarial loss: 0.323301\n",
      "epoch 33; iter: 200; batch classifier loss: 0.343006; batch adversarial loss: 0.318201\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404340; batch adversarial loss: 0.472909\n",
      "epoch 34; iter: 200; batch classifier loss: 0.394970; batch adversarial loss: 0.444161\n",
      "epoch 35; iter: 0; batch classifier loss: 0.336963; batch adversarial loss: 0.374937\n",
      "epoch 35; iter: 200; batch classifier loss: 0.283162; batch adversarial loss: 0.384770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329093; batch adversarial loss: 0.359737\n",
      "epoch 36; iter: 200; batch classifier loss: 0.416282; batch adversarial loss: 0.476290\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343140; batch adversarial loss: 0.402788\n",
      "epoch 37; iter: 200; batch classifier loss: 0.281473; batch adversarial loss: 0.373041\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296938; batch adversarial loss: 0.319980\n",
      "epoch 38; iter: 200; batch classifier loss: 0.291778; batch adversarial loss: 0.361205\n",
      "epoch 39; iter: 0; batch classifier loss: 0.374831; batch adversarial loss: 0.335203\n",
      "epoch 39; iter: 200; batch classifier loss: 0.322946; batch adversarial loss: 0.430635\n",
      "epoch 40; iter: 0; batch classifier loss: 0.300687; batch adversarial loss: 0.466321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 200; batch classifier loss: 0.403403; batch adversarial loss: 0.453533\n",
      "epoch 41; iter: 0; batch classifier loss: 0.272603; batch adversarial loss: 0.403425\n",
      "epoch 41; iter: 200; batch classifier loss: 0.319511; batch adversarial loss: 0.441964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221246; batch adversarial loss: 0.359044\n",
      "epoch 42; iter: 200; batch classifier loss: 0.304838; batch adversarial loss: 0.459358\n",
      "epoch 43; iter: 0; batch classifier loss: 0.280953; batch adversarial loss: 0.404912\n",
      "epoch 43; iter: 200; batch classifier loss: 0.340718; batch adversarial loss: 0.403002\n",
      "epoch 44; iter: 0; batch classifier loss: 0.277612; batch adversarial loss: 0.563569\n",
      "epoch 44; iter: 200; batch classifier loss: 0.298712; batch adversarial loss: 0.360838\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233290; batch adversarial loss: 0.381682\n",
      "epoch 45; iter: 200; batch classifier loss: 0.314817; batch adversarial loss: 0.358644\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314670; batch adversarial loss: 0.347070\n",
      "epoch 46; iter: 200; batch classifier loss: 0.331402; batch adversarial loss: 0.356998\n",
      "epoch 47; iter: 0; batch classifier loss: 0.300363; batch adversarial loss: 0.404073\n",
      "epoch 47; iter: 200; batch classifier loss: 0.304663; batch adversarial loss: 0.384254\n",
      "epoch 48; iter: 0; batch classifier loss: 0.317324; batch adversarial loss: 0.420728\n",
      "epoch 48; iter: 200; batch classifier loss: 0.311488; batch adversarial loss: 0.365458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.288667; batch adversarial loss: 0.442093\n",
      "epoch 49; iter: 200; batch classifier loss: 0.295386; batch adversarial loss: 0.409442\n",
      "epoch 0; iter: 0; batch classifier loss: 57.825535; batch adversarial loss: 0.529879\n",
      "epoch 0; iter: 200; batch classifier loss: 9.955279; batch adversarial loss: 0.563184\n",
      "epoch 1; iter: 0; batch classifier loss: 4.970466; batch adversarial loss: 0.556511\n",
      "epoch 1; iter: 200; batch classifier loss: 2.122300; batch adversarial loss: 0.507348\n",
      "epoch 2; iter: 0; batch classifier loss: 4.333900; batch adversarial loss: 0.499868\n",
      "epoch 2; iter: 200; batch classifier loss: 4.725748; batch adversarial loss: 0.495805\n",
      "epoch 3; iter: 0; batch classifier loss: 1.138536; batch adversarial loss: 0.495957\n",
      "epoch 3; iter: 200; batch classifier loss: 12.537689; batch adversarial loss: 0.471371\n",
      "epoch 4; iter: 0; batch classifier loss: 1.791106; batch adversarial loss: 0.453921\n",
      "epoch 4; iter: 200; batch classifier loss: 0.686103; batch adversarial loss: 0.453332\n",
      "epoch 5; iter: 0; batch classifier loss: 0.620388; batch adversarial loss: 0.483757\n",
      "epoch 5; iter: 200; batch classifier loss: 1.011056; batch adversarial loss: 0.438833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562330; batch adversarial loss: 0.450457\n",
      "epoch 6; iter: 200; batch classifier loss: 0.531332; batch adversarial loss: 0.389100\n",
      "epoch 7; iter: 0; batch classifier loss: 0.780392; batch adversarial loss: 0.466281\n",
      "epoch 7; iter: 200; batch classifier loss: 0.329461; batch adversarial loss: 0.477937\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356222; batch adversarial loss: 0.442826\n",
      "epoch 8; iter: 200; batch classifier loss: 0.570237; batch adversarial loss: 0.417256\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432111; batch adversarial loss: 0.506569\n",
      "epoch 9; iter: 200; batch classifier loss: 0.513209; batch adversarial loss: 0.460773\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366560; batch adversarial loss: 0.366753\n",
      "epoch 10; iter: 200; batch classifier loss: 0.503240; batch adversarial loss: 0.471017\n",
      "epoch 11; iter: 0; batch classifier loss: 0.402911; batch adversarial loss: 0.473299\n",
      "epoch 11; iter: 200; batch classifier loss: 0.545917; batch adversarial loss: 0.446261\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362794; batch adversarial loss: 0.400823\n",
      "epoch 12; iter: 200; batch classifier loss: 0.418194; batch adversarial loss: 0.298229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382687; batch adversarial loss: 0.529093\n",
      "epoch 13; iter: 200; batch classifier loss: 0.486424; batch adversarial loss: 0.432737\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471996; batch adversarial loss: 0.427139\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416251; batch adversarial loss: 0.413413\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405041; batch adversarial loss: 0.379256\n",
      "epoch 15; iter: 200; batch classifier loss: 0.385989; batch adversarial loss: 0.466084\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425974; batch adversarial loss: 0.480107\n",
      "epoch 16; iter: 200; batch classifier loss: 0.364255; batch adversarial loss: 0.435776\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301685; batch adversarial loss: 0.436752\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384959; batch adversarial loss: 0.366659\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555254; batch adversarial loss: 0.371607\n",
      "epoch 18; iter: 200; batch classifier loss: 0.436721; batch adversarial loss: 0.420852\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335825; batch adversarial loss: 0.340884\n",
      "epoch 19; iter: 200; batch classifier loss: 0.370401; batch adversarial loss: 0.348223\n",
      "epoch 20; iter: 0; batch classifier loss: 0.381584; batch adversarial loss: 0.283057\n",
      "epoch 20; iter: 200; batch classifier loss: 0.370211; batch adversarial loss: 0.412603\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528853; batch adversarial loss: 0.317912\n",
      "epoch 21; iter: 200; batch classifier loss: 0.337892; batch adversarial loss: 0.306685\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427847; batch adversarial loss: 0.384669\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332188; batch adversarial loss: 0.329050\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308668; batch adversarial loss: 0.475559\n",
      "epoch 23; iter: 200; batch classifier loss: 0.332725; batch adversarial loss: 0.356599\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433644; batch adversarial loss: 0.391513\n",
      "epoch 24; iter: 200; batch classifier loss: 0.290225; batch adversarial loss: 0.342237\n",
      "epoch 25; iter: 0; batch classifier loss: 0.375829; batch adversarial loss: 0.373777\n",
      "epoch 25; iter: 200; batch classifier loss: 0.233490; batch adversarial loss: 0.520440\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258999; batch adversarial loss: 0.421989\n",
      "epoch 26; iter: 200; batch classifier loss: 0.332463; batch adversarial loss: 0.274934\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392608; batch adversarial loss: 0.471520\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321644; batch adversarial loss: 0.363388\n",
      "epoch 28; iter: 0; batch classifier loss: 0.400224; batch adversarial loss: 0.340041\n",
      "epoch 28; iter: 200; batch classifier loss: 0.292669; batch adversarial loss: 0.438829\n",
      "epoch 29; iter: 0; batch classifier loss: 0.274836; batch adversarial loss: 0.409633\n",
      "epoch 29; iter: 200; batch classifier loss: 0.417317; batch adversarial loss: 0.502538\n",
      "epoch 30; iter: 0; batch classifier loss: 0.344189; batch adversarial loss: 0.332156\n",
      "epoch 30; iter: 200; batch classifier loss: 0.298105; batch adversarial loss: 0.393061\n",
      "epoch 31; iter: 0; batch classifier loss: 0.257245; batch adversarial loss: 0.504551\n",
      "epoch 31; iter: 200; batch classifier loss: 0.417785; batch adversarial loss: 0.296798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.345373; batch adversarial loss: 0.277185\n",
      "epoch 32; iter: 200; batch classifier loss: 0.294039; batch adversarial loss: 0.410435\n",
      "epoch 33; iter: 0; batch classifier loss: 0.276925; batch adversarial loss: 0.436527\n",
      "epoch 33; iter: 200; batch classifier loss: 0.282763; batch adversarial loss: 0.344393\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420049; batch adversarial loss: 0.345208\n",
      "epoch 34; iter: 200; batch classifier loss: 0.299500; batch adversarial loss: 0.337974\n",
      "epoch 35; iter: 0; batch classifier loss: 0.343938; batch adversarial loss: 0.413532\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325005; batch adversarial loss: 0.326564\n",
      "epoch 36; iter: 0; batch classifier loss: 0.388804; batch adversarial loss: 0.319374\n",
      "epoch 36; iter: 200; batch classifier loss: 0.360161; batch adversarial loss: 0.419734\n",
      "epoch 37; iter: 0; batch classifier loss: 0.362139; batch adversarial loss: 0.438589\n",
      "epoch 37; iter: 200; batch classifier loss: 0.290638; batch adversarial loss: 0.514001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288950; batch adversarial loss: 0.472588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 200; batch classifier loss: 0.312181; batch adversarial loss: 0.393121\n",
      "epoch 39; iter: 0; batch classifier loss: 0.367808; batch adversarial loss: 0.474631\n",
      "epoch 39; iter: 200; batch classifier loss: 0.366374; batch adversarial loss: 0.329715\n",
      "epoch 40; iter: 0; batch classifier loss: 0.323514; batch adversarial loss: 0.426982\n",
      "epoch 40; iter: 200; batch classifier loss: 0.309031; batch adversarial loss: 0.442916\n",
      "epoch 41; iter: 0; batch classifier loss: 0.278254; batch adversarial loss: 0.401226\n",
      "epoch 41; iter: 200; batch classifier loss: 0.354041; batch adversarial loss: 0.473871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425127; batch adversarial loss: 0.378339\n",
      "epoch 42; iter: 200; batch classifier loss: 0.320507; batch adversarial loss: 0.342621\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392442; batch adversarial loss: 0.391229\n",
      "epoch 43; iter: 200; batch classifier loss: 0.336535; batch adversarial loss: 0.430799\n",
      "epoch 44; iter: 0; batch classifier loss: 0.270947; batch adversarial loss: 0.343811\n",
      "epoch 44; iter: 200; batch classifier loss: 0.393021; batch adversarial loss: 0.500051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.280841; batch adversarial loss: 0.419887\n",
      "epoch 45; iter: 200; batch classifier loss: 0.347089; batch adversarial loss: 0.389995\n",
      "epoch 46; iter: 0; batch classifier loss: 0.337101; batch adversarial loss: 0.331929\n",
      "epoch 46; iter: 200; batch classifier loss: 0.397964; batch adversarial loss: 0.440969\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341759; batch adversarial loss: 0.449573\n",
      "epoch 47; iter: 200; batch classifier loss: 0.377676; batch adversarial loss: 0.458719\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351576; batch adversarial loss: 0.452470\n",
      "epoch 48; iter: 200; batch classifier loss: 0.256878; batch adversarial loss: 0.448626\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444044; batch adversarial loss: 0.358334\n",
      "epoch 49; iter: 200; batch classifier loss: 0.338316; batch adversarial loss: 0.449189\n",
      "epoch 0; iter: 0; batch classifier loss: 5.999223; batch adversarial loss: 0.675018\n",
      "epoch 0; iter: 200; batch classifier loss: 2.767458; batch adversarial loss: 0.593024\n",
      "epoch 1; iter: 0; batch classifier loss: 2.095081; batch adversarial loss: 0.594058\n",
      "epoch 1; iter: 200; batch classifier loss: 4.068276; batch adversarial loss: 0.534637\n",
      "epoch 2; iter: 0; batch classifier loss: 1.038240; batch adversarial loss: 0.514438\n",
      "epoch 2; iter: 200; batch classifier loss: 0.994277; batch adversarial loss: 0.503668\n",
      "epoch 3; iter: 0; batch classifier loss: 1.308955; batch adversarial loss: 0.471050\n",
      "epoch 3; iter: 200; batch classifier loss: 1.005235; batch adversarial loss: 0.409287\n",
      "epoch 4; iter: 0; batch classifier loss: 1.379478; batch adversarial loss: 0.451083\n",
      "epoch 4; iter: 200; batch classifier loss: 0.876182; batch adversarial loss: 0.373408\n",
      "epoch 5; iter: 0; batch classifier loss: 0.412622; batch adversarial loss: 0.466545\n",
      "epoch 5; iter: 200; batch classifier loss: 0.495720; batch adversarial loss: 0.385482\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315007; batch adversarial loss: 0.427132\n",
      "epoch 6; iter: 200; batch classifier loss: 0.370466; batch adversarial loss: 0.377441\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411676; batch adversarial loss: 0.416579\n",
      "epoch 7; iter: 200; batch classifier loss: 0.423055; batch adversarial loss: 0.436399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.433244; batch adversarial loss: 0.395486\n",
      "epoch 8; iter: 200; batch classifier loss: 0.408053; batch adversarial loss: 0.480522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.355567; batch adversarial loss: 0.517413\n",
      "epoch 9; iter: 200; batch classifier loss: 0.362327; batch adversarial loss: 0.423640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368831; batch adversarial loss: 0.345888\n",
      "epoch 10; iter: 200; batch classifier loss: 0.409030; batch adversarial loss: 0.453141\n",
      "epoch 11; iter: 0; batch classifier loss: 0.365179; batch adversarial loss: 0.415956\n",
      "epoch 11; iter: 200; batch classifier loss: 0.318001; batch adversarial loss: 0.377420\n",
      "epoch 12; iter: 0; batch classifier loss: 0.332851; batch adversarial loss: 0.447303\n",
      "epoch 12; iter: 200; batch classifier loss: 0.454107; batch adversarial loss: 0.446654\n",
      "epoch 13; iter: 0; batch classifier loss: 0.367543; batch adversarial loss: 0.429197\n",
      "epoch 13; iter: 200; batch classifier loss: 0.434223; batch adversarial loss: 0.428970\n",
      "epoch 14; iter: 0; batch classifier loss: 1.191971; batch adversarial loss: 0.382006\n",
      "epoch 14; iter: 200; batch classifier loss: 0.332927; batch adversarial loss: 0.381709\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364602; batch adversarial loss: 0.421233\n",
      "epoch 15; iter: 200; batch classifier loss: 0.405769; batch adversarial loss: 0.486255\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335944; batch adversarial loss: 0.385481\n",
      "epoch 16; iter: 200; batch classifier loss: 0.434818; batch adversarial loss: 0.415458\n",
      "epoch 17; iter: 0; batch classifier loss: 0.385316; batch adversarial loss: 0.389617\n",
      "epoch 17; iter: 200; batch classifier loss: 0.426953; batch adversarial loss: 0.403022\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350085; batch adversarial loss: 0.339499\n",
      "epoch 18; iter: 200; batch classifier loss: 0.320648; batch adversarial loss: 0.422169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.282339; batch adversarial loss: 0.382351\n",
      "epoch 19; iter: 200; batch classifier loss: 0.343755; batch adversarial loss: 0.507476\n",
      "epoch 20; iter: 0; batch classifier loss: 0.317880; batch adversarial loss: 0.427875\n",
      "epoch 20; iter: 200; batch classifier loss: 0.322454; batch adversarial loss: 0.367226\n",
      "epoch 21; iter: 0; batch classifier loss: 0.362188; batch adversarial loss: 0.392082\n",
      "epoch 21; iter: 200; batch classifier loss: 0.336017; batch adversarial loss: 0.405987\n",
      "epoch 22; iter: 0; batch classifier loss: 0.320269; batch adversarial loss: 0.374452\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332181; batch adversarial loss: 0.420455\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381923; batch adversarial loss: 0.526738\n",
      "epoch 23; iter: 200; batch classifier loss: 0.329916; batch adversarial loss: 0.443146\n",
      "epoch 24; iter: 0; batch classifier loss: 0.316532; batch adversarial loss: 0.317910\n",
      "epoch 24; iter: 200; batch classifier loss: 0.333635; batch adversarial loss: 0.471256\n",
      "epoch 25; iter: 0; batch classifier loss: 0.325452; batch adversarial loss: 0.302747\n",
      "epoch 25; iter: 200; batch classifier loss: 0.379362; batch adversarial loss: 0.340812\n",
      "epoch 26; iter: 0; batch classifier loss: 0.313826; batch adversarial loss: 0.445759\n",
      "epoch 26; iter: 200; batch classifier loss: 0.268961; batch adversarial loss: 0.468228\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337996; batch adversarial loss: 0.369978\n",
      "epoch 27; iter: 200; batch classifier loss: 0.341676; batch adversarial loss: 0.436196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275779; batch adversarial loss: 0.368614\n",
      "epoch 28; iter: 200; batch classifier loss: 0.353033; batch adversarial loss: 0.325510\n",
      "epoch 29; iter: 0; batch classifier loss: 0.391772; batch adversarial loss: 0.360828\n",
      "epoch 29; iter: 200; batch classifier loss: 0.413953; batch adversarial loss: 0.429066\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422079; batch adversarial loss: 0.425556\n",
      "epoch 30; iter: 200; batch classifier loss: 0.340869; batch adversarial loss: 0.409577\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356808; batch adversarial loss: 0.423733\n",
      "epoch 31; iter: 200; batch classifier loss: 0.283099; batch adversarial loss: 0.376320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417256; batch adversarial loss: 0.359901\n",
      "epoch 32; iter: 200; batch classifier loss: 0.295221; batch adversarial loss: 0.413180\n",
      "epoch 33; iter: 0; batch classifier loss: 0.383736; batch adversarial loss: 0.382466\n",
      "epoch 33; iter: 200; batch classifier loss: 0.390373; batch adversarial loss: 0.462055\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.359659\n",
      "epoch 34; iter: 200; batch classifier loss: 0.321082; batch adversarial loss: 0.370377\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432650; batch adversarial loss: 0.390415\n",
      "epoch 35; iter: 200; batch classifier loss: 0.355657; batch adversarial loss: 0.404960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390438; batch adversarial loss: 0.337085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 200; batch classifier loss: 0.448285; batch adversarial loss: 0.481588\n",
      "epoch 37; iter: 0; batch classifier loss: 0.370110; batch adversarial loss: 0.377217\n",
      "epoch 37; iter: 200; batch classifier loss: 0.332254; batch adversarial loss: 0.478857\n",
      "epoch 38; iter: 0; batch classifier loss: 0.251518; batch adversarial loss: 0.374625\n",
      "epoch 38; iter: 200; batch classifier loss: 0.316278; batch adversarial loss: 0.404686\n",
      "epoch 39; iter: 0; batch classifier loss: 0.324834; batch adversarial loss: 0.478584\n",
      "epoch 39; iter: 200; batch classifier loss: 0.355289; batch adversarial loss: 0.441876\n",
      "epoch 40; iter: 0; batch classifier loss: 0.356229; batch adversarial loss: 0.441092\n",
      "epoch 40; iter: 200; batch classifier loss: 0.373719; batch adversarial loss: 0.346624\n",
      "epoch 41; iter: 0; batch classifier loss: 0.346026; batch adversarial loss: 0.375467\n",
      "epoch 41; iter: 200; batch classifier loss: 0.338357; batch adversarial loss: 0.387088\n",
      "epoch 42; iter: 0; batch classifier loss: 0.388183; batch adversarial loss: 0.347422\n",
      "epoch 42; iter: 200; batch classifier loss: 0.203108; batch adversarial loss: 0.321271\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328376; batch adversarial loss: 0.373581\n",
      "epoch 43; iter: 200; batch classifier loss: 0.292269; batch adversarial loss: 0.394679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287961; batch adversarial loss: 0.415901\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353930; batch adversarial loss: 0.308544\n",
      "epoch 45; iter: 0; batch classifier loss: 0.346528; batch adversarial loss: 0.435536\n",
      "epoch 45; iter: 200; batch classifier loss: 0.351623; batch adversarial loss: 0.418332\n",
      "epoch 46; iter: 0; batch classifier loss: 0.359753; batch adversarial loss: 0.297316\n",
      "epoch 46; iter: 200; batch classifier loss: 0.375923; batch adversarial loss: 0.373543\n",
      "epoch 47; iter: 0; batch classifier loss: 0.345154; batch adversarial loss: 0.328819\n",
      "epoch 47; iter: 200; batch classifier loss: 0.286985; batch adversarial loss: 0.381035\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454731; batch adversarial loss: 0.352708\n",
      "epoch 48; iter: 200; batch classifier loss: 0.347116; batch adversarial loss: 0.333937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421344; batch adversarial loss: 0.470536\n",
      "epoch 49; iter: 200; batch classifier loss: 0.281401; batch adversarial loss: 0.412168\n",
      "epoch 0; iter: 0; batch classifier loss: 25.620239; batch adversarial loss: 0.802003\n",
      "epoch 0; iter: 200; batch classifier loss: 16.115465; batch adversarial loss: 0.657067\n",
      "epoch 1; iter: 0; batch classifier loss: 10.362656; batch adversarial loss: 0.619618\n",
      "epoch 1; iter: 200; batch classifier loss: 5.155468; batch adversarial loss: 0.567544\n",
      "epoch 2; iter: 0; batch classifier loss: 10.160528; batch adversarial loss: 0.572653\n",
      "epoch 2; iter: 200; batch classifier loss: 2.790235; batch adversarial loss: 0.523492\n",
      "epoch 3; iter: 0; batch classifier loss: 1.591787; batch adversarial loss: 0.559744\n",
      "epoch 3; iter: 200; batch classifier loss: 1.621272; batch adversarial loss: 0.498702\n",
      "epoch 4; iter: 0; batch classifier loss: 1.697609; batch adversarial loss: 0.520723\n",
      "epoch 4; iter: 200; batch classifier loss: 1.342922; batch adversarial loss: 0.450682\n",
      "epoch 5; iter: 0; batch classifier loss: 2.872501; batch adversarial loss: 0.384210\n",
      "epoch 5; iter: 200; batch classifier loss: 0.562397; batch adversarial loss: 0.485561\n",
      "epoch 6; iter: 0; batch classifier loss: 1.839366; batch adversarial loss: 0.465535\n",
      "epoch 6; iter: 200; batch classifier loss: 0.532351; batch adversarial loss: 0.398627\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471816; batch adversarial loss: 0.445014\n",
      "epoch 7; iter: 200; batch classifier loss: 0.624494; batch adversarial loss: 0.406882\n",
      "epoch 8; iter: 0; batch classifier loss: 1.117929; batch adversarial loss: 0.346669\n",
      "epoch 8; iter: 200; batch classifier loss: 0.371894; batch adversarial loss: 0.391546\n",
      "epoch 9; iter: 0; batch classifier loss: 1.218566; batch adversarial loss: 0.474020\n",
      "epoch 9; iter: 200; batch classifier loss: 0.287425; batch adversarial loss: 0.414822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371534; batch adversarial loss: 0.477983\n",
      "epoch 10; iter: 200; batch classifier loss: 0.439354; batch adversarial loss: 0.474168\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505563; batch adversarial loss: 0.328719\n",
      "epoch 11; iter: 200; batch classifier loss: 0.463099; batch adversarial loss: 0.348043\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327017; batch adversarial loss: 0.413625\n",
      "epoch 12; iter: 200; batch classifier loss: 0.373123; batch adversarial loss: 0.394320\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406104; batch adversarial loss: 0.467355\n",
      "epoch 13; iter: 200; batch classifier loss: 0.391946; batch adversarial loss: 0.468150\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360069; batch adversarial loss: 0.452082\n",
      "epoch 14; iter: 200; batch classifier loss: 0.393505; batch adversarial loss: 0.404709\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505634; batch adversarial loss: 0.404252\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353287; batch adversarial loss: 0.421293\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304472; batch adversarial loss: 0.355814\n",
      "epoch 16; iter: 200; batch classifier loss: 0.369514; batch adversarial loss: 0.493937\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356585; batch adversarial loss: 0.417015\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312385; batch adversarial loss: 0.397373\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274815; batch adversarial loss: 0.459429\n",
      "epoch 18; iter: 200; batch classifier loss: 0.286427; batch adversarial loss: 0.349265\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473504; batch adversarial loss: 0.445427\n",
      "epoch 19; iter: 200; batch classifier loss: 0.423912; batch adversarial loss: 0.384247\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428327; batch adversarial loss: 0.434211\n",
      "epoch 20; iter: 200; batch classifier loss: 0.242352; batch adversarial loss: 0.402066\n",
      "epoch 21; iter: 0; batch classifier loss: 0.322919; batch adversarial loss: 0.469447\n",
      "epoch 21; iter: 200; batch classifier loss: 0.447897; batch adversarial loss: 0.332656\n",
      "epoch 22; iter: 0; batch classifier loss: 0.365832; batch adversarial loss: 0.439615\n",
      "epoch 22; iter: 200; batch classifier loss: 0.327170; batch adversarial loss: 0.333845\n",
      "epoch 23; iter: 0; batch classifier loss: 0.395954; batch adversarial loss: 0.539107\n",
      "epoch 23; iter: 200; batch classifier loss: 0.299370; batch adversarial loss: 0.386561\n",
      "epoch 24; iter: 0; batch classifier loss: 0.310645; batch adversarial loss: 0.442655\n",
      "epoch 24; iter: 200; batch classifier loss: 0.387740; batch adversarial loss: 0.507489\n",
      "epoch 25; iter: 0; batch classifier loss: 0.363505; batch adversarial loss: 0.360391\n",
      "epoch 25; iter: 200; batch classifier loss: 0.393418; batch adversarial loss: 0.462168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303137; batch adversarial loss: 0.406975\n",
      "epoch 26; iter: 200; batch classifier loss: 0.330599; batch adversarial loss: 0.330929\n",
      "epoch 27; iter: 0; batch classifier loss: 0.329952; batch adversarial loss: 0.406060\n",
      "epoch 27; iter: 200; batch classifier loss: 0.306580; batch adversarial loss: 0.414775\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328002; batch adversarial loss: 0.510770\n",
      "epoch 28; iter: 200; batch classifier loss: 0.340550; batch adversarial loss: 0.367286\n",
      "epoch 29; iter: 0; batch classifier loss: 0.309229; batch adversarial loss: 0.416914\n",
      "epoch 29; iter: 200; batch classifier loss: 0.397511; batch adversarial loss: 0.439463\n",
      "epoch 30; iter: 0; batch classifier loss: 0.354950; batch adversarial loss: 0.469311\n",
      "epoch 30; iter: 200; batch classifier loss: 0.315000; batch adversarial loss: 0.332689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.299980; batch adversarial loss: 0.439175\n",
      "epoch 31; iter: 200; batch classifier loss: 0.317368; batch adversarial loss: 0.385324\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299187; batch adversarial loss: 0.458109\n",
      "epoch 32; iter: 200; batch classifier loss: 0.337511; batch adversarial loss: 0.479132\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455307; batch adversarial loss: 0.386636\n",
      "epoch 33; iter: 200; batch classifier loss: 0.343399; batch adversarial loss: 0.437586\n",
      "epoch 34; iter: 0; batch classifier loss: 0.362941; batch adversarial loss: 0.382638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 200; batch classifier loss: 0.336631; batch adversarial loss: 0.383857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.315961; batch adversarial loss: 0.424322\n",
      "epoch 35; iter: 200; batch classifier loss: 0.274718; batch adversarial loss: 0.496410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406298; batch adversarial loss: 0.450582\n",
      "epoch 36; iter: 200; batch classifier loss: 0.313378; batch adversarial loss: 0.489368\n",
      "epoch 37; iter: 0; batch classifier loss: 0.373967; batch adversarial loss: 0.445503\n",
      "epoch 37; iter: 200; batch classifier loss: 0.243567; batch adversarial loss: 0.403293\n",
      "epoch 38; iter: 0; batch classifier loss: 0.307150; batch adversarial loss: 0.444825\n",
      "epoch 38; iter: 200; batch classifier loss: 0.292418; batch adversarial loss: 0.422754\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255698; batch adversarial loss: 0.403091\n",
      "epoch 39; iter: 200; batch classifier loss: 0.364515; batch adversarial loss: 0.398507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.340260; batch adversarial loss: 0.413257\n",
      "epoch 40; iter: 200; batch classifier loss: 0.367297; batch adversarial loss: 0.373876\n",
      "epoch 41; iter: 0; batch classifier loss: 0.361856; batch adversarial loss: 0.331358\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383216; batch adversarial loss: 0.300628\n",
      "epoch 42; iter: 0; batch classifier loss: 0.373462; batch adversarial loss: 0.462945\n",
      "epoch 42; iter: 200; batch classifier loss: 0.403892; batch adversarial loss: 0.361305\n",
      "epoch 43; iter: 0; batch classifier loss: 0.269652; batch adversarial loss: 0.458811\n",
      "epoch 43; iter: 200; batch classifier loss: 0.350392; batch adversarial loss: 0.470839\n",
      "epoch 44; iter: 0; batch classifier loss: 0.319585; batch adversarial loss: 0.466918\n",
      "epoch 44; iter: 200; batch classifier loss: 0.344493; batch adversarial loss: 0.381388\n",
      "epoch 45; iter: 0; batch classifier loss: 0.265541; batch adversarial loss: 0.394890\n",
      "epoch 45; iter: 200; batch classifier loss: 0.311612; batch adversarial loss: 0.396698\n",
      "epoch 46; iter: 0; batch classifier loss: 0.344255; batch adversarial loss: 0.414334\n",
      "epoch 46; iter: 200; batch classifier loss: 0.296761; batch adversarial loss: 0.371343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.394791; batch adversarial loss: 0.453233\n",
      "epoch 47; iter: 200; batch classifier loss: 0.320035; batch adversarial loss: 0.567718\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335880; batch adversarial loss: 0.339588\n",
      "epoch 48; iter: 200; batch classifier loss: 0.281887; batch adversarial loss: 0.485022\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380269; batch adversarial loss: 0.328062\n",
      "epoch 49; iter: 200; batch classifier loss: 0.275602; batch adversarial loss: 0.504003\n",
      "epoch 0; iter: 0; batch classifier loss: 21.501823; batch adversarial loss: 0.722017\n",
      "epoch 0; iter: 200; batch classifier loss: 8.117151; batch adversarial loss: 0.632398\n",
      "epoch 1; iter: 0; batch classifier loss: 6.827087; batch adversarial loss: 0.629053\n",
      "epoch 1; iter: 200; batch classifier loss: 3.629909; batch adversarial loss: 0.543939\n",
      "epoch 2; iter: 0; batch classifier loss: 3.158067; batch adversarial loss: 0.534598\n",
      "epoch 2; iter: 200; batch classifier loss: 0.695970; batch adversarial loss: 0.479344\n",
      "epoch 3; iter: 0; batch classifier loss: 2.711539; batch adversarial loss: 0.527192\n",
      "epoch 3; iter: 200; batch classifier loss: 4.762783; batch adversarial loss: 0.470567\n",
      "epoch 4; iter: 0; batch classifier loss: 1.235548; batch adversarial loss: 0.474799\n",
      "epoch 4; iter: 200; batch classifier loss: 0.361032; batch adversarial loss: 0.400924\n",
      "epoch 5; iter: 0; batch classifier loss: 1.162243; batch adversarial loss: 0.428706\n",
      "epoch 5; iter: 200; batch classifier loss: 0.671881; batch adversarial loss: 0.456062\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340486; batch adversarial loss: 0.443041\n",
      "epoch 6; iter: 200; batch classifier loss: 0.487564; batch adversarial loss: 0.385756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505366; batch adversarial loss: 0.454247\n",
      "epoch 7; iter: 200; batch classifier loss: 0.446506; batch adversarial loss: 0.402660\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564053; batch adversarial loss: 0.483811\n",
      "epoch 8; iter: 200; batch classifier loss: 0.569114; batch adversarial loss: 0.327474\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356413; batch adversarial loss: 0.356007\n",
      "epoch 9; iter: 200; batch classifier loss: 0.349596; batch adversarial loss: 0.331692\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419251; batch adversarial loss: 0.348408\n",
      "epoch 10; iter: 200; batch classifier loss: 0.525727; batch adversarial loss: 0.394168\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565664; batch adversarial loss: 0.413805\n",
      "epoch 11; iter: 200; batch classifier loss: 0.384719; batch adversarial loss: 0.317316\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341761; batch adversarial loss: 0.435745\n",
      "epoch 12; iter: 200; batch classifier loss: 0.460104; batch adversarial loss: 0.489570\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429287; batch adversarial loss: 0.435433\n",
      "epoch 13; iter: 200; batch classifier loss: 0.360770; batch adversarial loss: 0.422044\n",
      "epoch 14; iter: 0; batch classifier loss: 0.320846; batch adversarial loss: 0.432097\n",
      "epoch 14; iter: 200; batch classifier loss: 0.562988; batch adversarial loss: 0.378111\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316257; batch adversarial loss: 0.370081\n",
      "epoch 15; iter: 200; batch classifier loss: 0.520639; batch adversarial loss: 0.414868\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364062; batch adversarial loss: 0.446264\n",
      "epoch 16; iter: 200; batch classifier loss: 0.283052; batch adversarial loss: 0.404052\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348882; batch adversarial loss: 0.434590\n",
      "epoch 17; iter: 200; batch classifier loss: 0.474471; batch adversarial loss: 0.406265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294420; batch adversarial loss: 0.481628\n",
      "epoch 18; iter: 200; batch classifier loss: 0.269159; batch adversarial loss: 0.421481\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434941; batch adversarial loss: 0.413782\n",
      "epoch 19; iter: 200; batch classifier loss: 0.411876; batch adversarial loss: 0.424271\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556744; batch adversarial loss: 0.479603\n",
      "epoch 20; iter: 200; batch classifier loss: 0.261552; batch adversarial loss: 0.489991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.365893; batch adversarial loss: 0.295216\n",
      "epoch 21; iter: 200; batch classifier loss: 0.360374; batch adversarial loss: 0.420565\n",
      "epoch 22; iter: 0; batch classifier loss: 0.311841; batch adversarial loss: 0.400790\n",
      "epoch 22; iter: 200; batch classifier loss: 0.382389; batch adversarial loss: 0.463909\n",
      "epoch 23; iter: 0; batch classifier loss: 0.324089; batch adversarial loss: 0.359164\n",
      "epoch 23; iter: 200; batch classifier loss: 0.322676; batch adversarial loss: 0.459336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343662; batch adversarial loss: 0.462172\n",
      "epoch 24; iter: 200; batch classifier loss: 0.367699; batch adversarial loss: 0.532098\n",
      "epoch 25; iter: 0; batch classifier loss: 0.328292; batch adversarial loss: 0.469484\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332452; batch adversarial loss: 0.393935\n",
      "epoch 26; iter: 0; batch classifier loss: 0.339150; batch adversarial loss: 0.365958\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336157; batch adversarial loss: 0.503974\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305457; batch adversarial loss: 0.383884\n",
      "epoch 27; iter: 200; batch classifier loss: 0.435063; batch adversarial loss: 0.457725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.357144; batch adversarial loss: 0.486273\n",
      "epoch 28; iter: 200; batch classifier loss: 0.445547; batch adversarial loss: 0.350807\n",
      "epoch 29; iter: 0; batch classifier loss: 0.346789; batch adversarial loss: 0.438585\n",
      "epoch 29; iter: 200; batch classifier loss: 0.332806; batch adversarial loss: 0.434869\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320046; batch adversarial loss: 0.394378\n",
      "epoch 30; iter: 200; batch classifier loss: 0.348966; batch adversarial loss: 0.351945\n",
      "epoch 31; iter: 0; batch classifier loss: 0.314744; batch adversarial loss: 0.436860\n",
      "epoch 31; iter: 200; batch classifier loss: 0.310606; batch adversarial loss: 0.376222\n",
      "epoch 32; iter: 0; batch classifier loss: 0.375430; batch adversarial loss: 0.349784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 200; batch classifier loss: 0.360633; batch adversarial loss: 0.344820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330670; batch adversarial loss: 0.403838\n",
      "epoch 33; iter: 200; batch classifier loss: 0.359642; batch adversarial loss: 0.372957\n",
      "epoch 34; iter: 0; batch classifier loss: 0.585198; batch adversarial loss: 0.447678\n",
      "epoch 34; iter: 200; batch classifier loss: 0.396576; batch adversarial loss: 0.471619\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349152; batch adversarial loss: 0.303245\n",
      "epoch 35; iter: 200; batch classifier loss: 0.336125; batch adversarial loss: 0.424628\n",
      "epoch 36; iter: 0; batch classifier loss: 0.345984; batch adversarial loss: 0.329270\n",
      "epoch 36; iter: 200; batch classifier loss: 0.213555; batch adversarial loss: 0.396646\n",
      "epoch 37; iter: 0; batch classifier loss: 0.280266; batch adversarial loss: 0.457199\n",
      "epoch 37; iter: 200; batch classifier loss: 0.349977; batch adversarial loss: 0.358116\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359519; batch adversarial loss: 0.384117\n",
      "epoch 38; iter: 200; batch classifier loss: 0.404922; batch adversarial loss: 0.332118\n",
      "epoch 39; iter: 0; batch classifier loss: 0.378209; batch adversarial loss: 0.390347\n",
      "epoch 39; iter: 200; batch classifier loss: 0.575299; batch adversarial loss: 0.394221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.324732; batch adversarial loss: 0.320407\n",
      "epoch 40; iter: 200; batch classifier loss: 0.306132; batch adversarial loss: 0.267752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.264024; batch adversarial loss: 0.486433\n",
      "epoch 41; iter: 200; batch classifier loss: 0.429055; batch adversarial loss: 0.490675\n",
      "epoch 42; iter: 0; batch classifier loss: 0.262569; batch adversarial loss: 0.517859\n",
      "epoch 42; iter: 200; batch classifier loss: 0.303356; batch adversarial loss: 0.392403\n",
      "epoch 43; iter: 0; batch classifier loss: 0.291677; batch adversarial loss: 0.465101\n",
      "epoch 43; iter: 200; batch classifier loss: 0.313917; batch adversarial loss: 0.341640\n",
      "epoch 44; iter: 0; batch classifier loss: 0.313850; batch adversarial loss: 0.370608\n",
      "epoch 44; iter: 200; batch classifier loss: 0.362725; batch adversarial loss: 0.320349\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372014; batch adversarial loss: 0.342095\n",
      "epoch 45; iter: 200; batch classifier loss: 0.427652; batch adversarial loss: 0.350870\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377301; batch adversarial loss: 0.419230\n",
      "epoch 46; iter: 200; batch classifier loss: 0.314685; batch adversarial loss: 0.415757\n",
      "epoch 47; iter: 0; batch classifier loss: 0.302024; batch adversarial loss: 0.355815\n",
      "epoch 47; iter: 200; batch classifier loss: 0.314580; batch adversarial loss: 0.396925\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351804; batch adversarial loss: 0.390395\n",
      "epoch 48; iter: 200; batch classifier loss: 0.343077; batch adversarial loss: 0.350844\n",
      "epoch 49; iter: 0; batch classifier loss: 0.332162; batch adversarial loss: 0.623343\n",
      "epoch 49; iter: 200; batch classifier loss: 0.450242; batch adversarial loss: 0.331996\n",
      "epoch 0; iter: 0; batch classifier loss: 19.987368; batch adversarial loss: 0.790042\n",
      "epoch 0; iter: 200; batch classifier loss: 2.779099; batch adversarial loss: 0.613431\n",
      "epoch 1; iter: 0; batch classifier loss: 10.270325; batch adversarial loss: 0.601772\n",
      "epoch 1; iter: 200; batch classifier loss: 2.139714; batch adversarial loss: 0.552823\n",
      "epoch 2; iter: 0; batch classifier loss: 3.587690; batch adversarial loss: 0.521720\n",
      "epoch 2; iter: 200; batch classifier loss: 1.327488; batch adversarial loss: 0.502131\n",
      "epoch 3; iter: 0; batch classifier loss: 1.994964; batch adversarial loss: 0.491142\n",
      "epoch 3; iter: 200; batch classifier loss: 1.207407; batch adversarial loss: 0.498669\n",
      "epoch 4; iter: 0; batch classifier loss: 2.676801; batch adversarial loss: 0.453087\n",
      "epoch 4; iter: 200; batch classifier loss: 1.082122; batch adversarial loss: 0.429645\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602754; batch adversarial loss: 0.431858\n",
      "epoch 5; iter: 200; batch classifier loss: 0.619934; batch adversarial loss: 0.428383\n",
      "epoch 6; iter: 0; batch classifier loss: 0.718780; batch adversarial loss: 0.467999\n",
      "epoch 6; iter: 200; batch classifier loss: 0.384599; batch adversarial loss: 0.435531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339610; batch adversarial loss: 0.412722\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397672; batch adversarial loss: 0.367288\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368862; batch adversarial loss: 0.431521\n",
      "epoch 8; iter: 200; batch classifier loss: 0.419446; batch adversarial loss: 0.485950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377682; batch adversarial loss: 0.349950\n",
      "epoch 9; iter: 200; batch classifier loss: 0.425165; batch adversarial loss: 0.446188\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440047; batch adversarial loss: 0.389800\n",
      "epoch 10; iter: 200; batch classifier loss: 0.356547; batch adversarial loss: 0.406767\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384261; batch adversarial loss: 0.461125\n",
      "epoch 11; iter: 200; batch classifier loss: 0.349090; batch adversarial loss: 0.424273\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412395; batch adversarial loss: 0.476739\n",
      "epoch 12; iter: 200; batch classifier loss: 0.376079; batch adversarial loss: 0.409611\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382437; batch adversarial loss: 0.486546\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408021; batch adversarial loss: 0.432719\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435638; batch adversarial loss: 0.433863\n",
      "epoch 14; iter: 200; batch classifier loss: 0.346828; batch adversarial loss: 0.462145\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362199; batch adversarial loss: 0.430590\n",
      "epoch 15; iter: 200; batch classifier loss: 0.378716; batch adversarial loss: 0.368004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379927; batch adversarial loss: 0.454135\n",
      "epoch 16; iter: 200; batch classifier loss: 0.314025; batch adversarial loss: 0.352583\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371790; batch adversarial loss: 0.439709\n",
      "epoch 17; iter: 200; batch classifier loss: 0.362473; batch adversarial loss: 0.382554\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290732; batch adversarial loss: 0.398126\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371077; batch adversarial loss: 0.320126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315379; batch adversarial loss: 0.387109\n",
      "epoch 19; iter: 200; batch classifier loss: 0.339318; batch adversarial loss: 0.395940\n",
      "epoch 20; iter: 0; batch classifier loss: 0.389358; batch adversarial loss: 0.385784\n",
      "epoch 20; iter: 200; batch classifier loss: 0.349567; batch adversarial loss: 0.491140\n",
      "epoch 21; iter: 0; batch classifier loss: 0.334144; batch adversarial loss: 0.315389\n",
      "epoch 21; iter: 200; batch classifier loss: 0.359224; batch adversarial loss: 0.473233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361945; batch adversarial loss: 0.343047\n",
      "epoch 22; iter: 200; batch classifier loss: 0.301365; batch adversarial loss: 0.468667\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319345; batch adversarial loss: 0.358724\n",
      "epoch 23; iter: 200; batch classifier loss: 0.302506; batch adversarial loss: 0.505845\n",
      "epoch 24; iter: 0; batch classifier loss: 0.283573; batch adversarial loss: 0.411126\n",
      "epoch 24; iter: 200; batch classifier loss: 0.330376; batch adversarial loss: 0.504863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.379442; batch adversarial loss: 0.469609\n",
      "epoch 25; iter: 200; batch classifier loss: 0.415948; batch adversarial loss: 0.483682\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450049; batch adversarial loss: 0.438708\n",
      "epoch 26; iter: 200; batch classifier loss: 0.295399; batch adversarial loss: 0.451141\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315670; batch adversarial loss: 0.509059\n",
      "epoch 27; iter: 200; batch classifier loss: 0.306250; batch adversarial loss: 0.459316\n",
      "epoch 28; iter: 0; batch classifier loss: 0.355347; batch adversarial loss: 0.442841\n",
      "epoch 28; iter: 200; batch classifier loss: 0.338601; batch adversarial loss: 0.414856\n",
      "epoch 29; iter: 0; batch classifier loss: 0.289551; batch adversarial loss: 0.309988\n",
      "epoch 29; iter: 200; batch classifier loss: 0.362151; batch adversarial loss: 0.389221\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342409; batch adversarial loss: 0.400559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 200; batch classifier loss: 0.412101; batch adversarial loss: 0.373055\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443919; batch adversarial loss: 0.392605\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331053; batch adversarial loss: 0.298546\n",
      "epoch 32; iter: 0; batch classifier loss: 0.312295; batch adversarial loss: 0.304579\n",
      "epoch 32; iter: 200; batch classifier loss: 0.204957; batch adversarial loss: 0.384362\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502116; batch adversarial loss: 0.375610\n",
      "epoch 33; iter: 200; batch classifier loss: 0.334160; batch adversarial loss: 0.391896\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311633; batch adversarial loss: 0.367239\n",
      "epoch 34; iter: 200; batch classifier loss: 0.316047; batch adversarial loss: 0.360655\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390426; batch adversarial loss: 0.397339\n",
      "epoch 35; iter: 200; batch classifier loss: 0.570494; batch adversarial loss: 0.422375\n",
      "epoch 36; iter: 0; batch classifier loss: 0.294959; batch adversarial loss: 0.447614\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327847; batch adversarial loss: 0.486846\n",
      "epoch 37; iter: 0; batch classifier loss: 0.355134; batch adversarial loss: 0.435603\n",
      "epoch 37; iter: 200; batch classifier loss: 0.367167; batch adversarial loss: 0.360126\n",
      "epoch 38; iter: 0; batch classifier loss: 0.294725; batch adversarial loss: 0.377628\n",
      "epoch 38; iter: 200; batch classifier loss: 0.335231; batch adversarial loss: 0.493709\n",
      "epoch 39; iter: 0; batch classifier loss: 0.285939; batch adversarial loss: 0.413788\n",
      "epoch 39; iter: 200; batch classifier loss: 0.250049; batch adversarial loss: 0.394834\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390170; batch adversarial loss: 0.491947\n",
      "epoch 40; iter: 200; batch classifier loss: 0.319193; batch adversarial loss: 0.424282\n",
      "epoch 41; iter: 0; batch classifier loss: 0.331021; batch adversarial loss: 0.390196\n",
      "epoch 41; iter: 200; batch classifier loss: 0.314213; batch adversarial loss: 0.416483\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364720; batch adversarial loss: 0.468391\n",
      "epoch 42; iter: 200; batch classifier loss: 0.408657; batch adversarial loss: 0.360952\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420628; batch adversarial loss: 0.394439\n",
      "epoch 43; iter: 200; batch classifier loss: 0.351497; batch adversarial loss: 0.305378\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408816; batch adversarial loss: 0.459676\n",
      "epoch 44; iter: 200; batch classifier loss: 0.339127; batch adversarial loss: 0.332613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374067; batch adversarial loss: 0.425060\n",
      "epoch 45; iter: 200; batch classifier loss: 0.365664; batch adversarial loss: 0.330087\n",
      "epoch 46; iter: 0; batch classifier loss: 0.357977; batch adversarial loss: 0.478273\n",
      "epoch 46; iter: 200; batch classifier loss: 0.370767; batch adversarial loss: 0.476311\n",
      "epoch 47; iter: 0; batch classifier loss: 0.380582; batch adversarial loss: 0.430596\n",
      "epoch 47; iter: 200; batch classifier loss: 0.381694; batch adversarial loss: 0.402510\n",
      "epoch 48; iter: 0; batch classifier loss: 0.333247; batch adversarial loss: 0.425681\n",
      "epoch 48; iter: 200; batch classifier loss: 0.410051; batch adversarial loss: 0.441189\n",
      "epoch 49; iter: 0; batch classifier loss: 0.327591; batch adversarial loss: 0.462264\n",
      "epoch 49; iter: 200; batch classifier loss: 0.298433; batch adversarial loss: 0.276351\n",
      "epoch 0; iter: 0; batch classifier loss: 47.212856; batch adversarial loss: 0.655529\n",
      "epoch 0; iter: 200; batch classifier loss: 6.179523; batch adversarial loss: 0.630630\n",
      "epoch 1; iter: 0; batch classifier loss: 8.790640; batch adversarial loss: 0.597218\n",
      "epoch 1; iter: 200; batch classifier loss: 5.316544; batch adversarial loss: 0.566696\n",
      "epoch 2; iter: 0; batch classifier loss: 2.860279; batch adversarial loss: 0.531705\n",
      "epoch 2; iter: 200; batch classifier loss: 1.002850; batch adversarial loss: 0.502124\n",
      "epoch 3; iter: 0; batch classifier loss: 1.545861; batch adversarial loss: 0.511549\n",
      "epoch 3; iter: 200; batch classifier loss: 1.203905; batch adversarial loss: 0.457021\n",
      "epoch 4; iter: 0; batch classifier loss: 1.337918; batch adversarial loss: 0.477031\n",
      "epoch 4; iter: 200; batch classifier loss: 0.840201; batch adversarial loss: 0.475231\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613220; batch adversarial loss: 0.413226\n",
      "epoch 5; iter: 200; batch classifier loss: 0.587834; batch adversarial loss: 0.418655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357796; batch adversarial loss: 0.514669\n",
      "epoch 6; iter: 200; batch classifier loss: 0.467418; batch adversarial loss: 0.449342\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376714; batch adversarial loss: 0.475598\n",
      "epoch 7; iter: 200; batch classifier loss: 0.409551; batch adversarial loss: 0.462000\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418510; batch adversarial loss: 0.471271\n",
      "epoch 8; iter: 200; batch classifier loss: 0.420597; batch adversarial loss: 0.490276\n",
      "epoch 9; iter: 0; batch classifier loss: 0.427252; batch adversarial loss: 0.335142\n",
      "epoch 9; iter: 200; batch classifier loss: 0.688634; batch adversarial loss: 0.361486\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515955; batch adversarial loss: 0.369490\n",
      "epoch 10; iter: 200; batch classifier loss: 0.427314; batch adversarial loss: 0.470019\n",
      "epoch 11; iter: 0; batch classifier loss: 0.434607; batch adversarial loss: 0.509707\n",
      "epoch 11; iter: 200; batch classifier loss: 0.567832; batch adversarial loss: 0.388501\n",
      "epoch 12; iter: 0; batch classifier loss: 0.336466; batch adversarial loss: 0.463402\n",
      "epoch 12; iter: 200; batch classifier loss: 0.643198; batch adversarial loss: 0.437460\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389066; batch adversarial loss: 0.469957\n",
      "epoch 13; iter: 200; batch classifier loss: 0.559037; batch adversarial loss: 0.418703\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422984; batch adversarial loss: 0.390438\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388535; batch adversarial loss: 0.354119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284021; batch adversarial loss: 0.328320\n",
      "epoch 15; iter: 200; batch classifier loss: 0.306066; batch adversarial loss: 0.349046\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333083; batch adversarial loss: 0.413419\n",
      "epoch 16; iter: 200; batch classifier loss: 0.234819; batch adversarial loss: 0.394086\n",
      "epoch 17; iter: 0; batch classifier loss: 0.442586; batch adversarial loss: 0.346098\n",
      "epoch 17; iter: 200; batch classifier loss: 0.366499; batch adversarial loss: 0.360883\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329451; batch adversarial loss: 0.294616\n",
      "epoch 18; iter: 200; batch classifier loss: 0.314362; batch adversarial loss: 0.319605\n",
      "epoch 19; iter: 0; batch classifier loss: 0.326415; batch adversarial loss: 0.457564\n",
      "epoch 19; iter: 200; batch classifier loss: 0.292911; batch adversarial loss: 0.465856\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356507; batch adversarial loss: 0.413965\n",
      "epoch 20; iter: 200; batch classifier loss: 0.322323; batch adversarial loss: 0.439531\n",
      "epoch 21; iter: 0; batch classifier loss: 0.318989; batch adversarial loss: 0.416366\n",
      "epoch 21; iter: 200; batch classifier loss: 0.401956; batch adversarial loss: 0.362523\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333564; batch adversarial loss: 0.493212\n",
      "epoch 22; iter: 200; batch classifier loss: 0.340171; batch adversarial loss: 0.312929\n",
      "epoch 23; iter: 0; batch classifier loss: 0.315781; batch adversarial loss: 0.461477\n",
      "epoch 23; iter: 200; batch classifier loss: 0.333353; batch adversarial loss: 0.388734\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370556; batch adversarial loss: 0.346879\n",
      "epoch 24; iter: 200; batch classifier loss: 0.313499; batch adversarial loss: 0.414682\n",
      "epoch 25; iter: 0; batch classifier loss: 0.287701; batch adversarial loss: 0.385063\n",
      "epoch 25; iter: 200; batch classifier loss: 0.427711; batch adversarial loss: 0.413329\n",
      "epoch 26; iter: 0; batch classifier loss: 0.284782; batch adversarial loss: 0.444745\n",
      "epoch 26; iter: 200; batch classifier loss: 0.238110; batch adversarial loss: 0.509903\n",
      "epoch 27; iter: 0; batch classifier loss: 0.364429; batch adversarial loss: 0.347562\n",
      "epoch 27; iter: 200; batch classifier loss: 0.455715; batch adversarial loss: 0.302044\n",
      "epoch 28; iter: 0; batch classifier loss: 0.280604; batch adversarial loss: 0.415646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 200; batch classifier loss: 0.302446; batch adversarial loss: 0.441855\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376183; batch adversarial loss: 0.335079\n",
      "epoch 29; iter: 200; batch classifier loss: 0.327816; batch adversarial loss: 0.401316\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329577; batch adversarial loss: 0.335463\n",
      "epoch 30; iter: 200; batch classifier loss: 0.384980; batch adversarial loss: 0.453954\n",
      "epoch 31; iter: 0; batch classifier loss: 0.326987; batch adversarial loss: 0.368274\n",
      "epoch 31; iter: 200; batch classifier loss: 0.317283; batch adversarial loss: 0.387729\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361964; batch adversarial loss: 0.412229\n",
      "epoch 32; iter: 200; batch classifier loss: 0.299572; batch adversarial loss: 0.368095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323822; batch adversarial loss: 0.418746\n",
      "epoch 33; iter: 200; batch classifier loss: 0.409539; batch adversarial loss: 0.416404\n",
      "epoch 34; iter: 0; batch classifier loss: 0.316876; batch adversarial loss: 0.482482\n",
      "epoch 34; iter: 200; batch classifier loss: 0.409987; batch adversarial loss: 0.438515\n",
      "epoch 35; iter: 0; batch classifier loss: 0.282865; batch adversarial loss: 0.448831\n",
      "epoch 35; iter: 200; batch classifier loss: 0.382493; batch adversarial loss: 0.408855\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432350; batch adversarial loss: 0.363954\n",
      "epoch 36; iter: 200; batch classifier loss: 0.348199; batch adversarial loss: 0.385369\n",
      "epoch 37; iter: 0; batch classifier loss: 0.358061; batch adversarial loss: 0.388339\n",
      "epoch 37; iter: 200; batch classifier loss: 0.263122; batch adversarial loss: 0.286210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252177; batch adversarial loss: 0.369348\n",
      "epoch 38; iter: 200; batch classifier loss: 0.355215; batch adversarial loss: 0.382545\n",
      "epoch 39; iter: 0; batch classifier loss: 0.331960; batch adversarial loss: 0.346748\n",
      "epoch 39; iter: 200; batch classifier loss: 0.390884; batch adversarial loss: 0.314258\n",
      "epoch 40; iter: 0; batch classifier loss: 0.322568; batch adversarial loss: 0.263066\n",
      "epoch 40; iter: 200; batch classifier loss: 0.391008; batch adversarial loss: 0.419220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.346897; batch adversarial loss: 0.322479\n",
      "epoch 41; iter: 200; batch classifier loss: 0.316869; batch adversarial loss: 0.461554\n",
      "epoch 42; iter: 0; batch classifier loss: 0.273450; batch adversarial loss: 0.391950\n",
      "epoch 42; iter: 200; batch classifier loss: 0.420360; batch adversarial loss: 0.477960\n",
      "epoch 43; iter: 0; batch classifier loss: 0.278069; batch adversarial loss: 0.464971\n",
      "epoch 43; iter: 200; batch classifier loss: 0.422777; batch adversarial loss: 0.407961\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321740; batch adversarial loss: 0.505197\n",
      "epoch 44; iter: 200; batch classifier loss: 0.310914; batch adversarial loss: 0.285850\n",
      "epoch 45; iter: 0; batch classifier loss: 0.308005; batch adversarial loss: 0.359536\n",
      "epoch 45; iter: 200; batch classifier loss: 0.304710; batch adversarial loss: 0.430229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406453; batch adversarial loss: 0.397363\n",
      "epoch 46; iter: 200; batch classifier loss: 0.323201; batch adversarial loss: 0.465733\n",
      "epoch 47; iter: 0; batch classifier loss: 0.333753; batch adversarial loss: 0.385441\n",
      "epoch 47; iter: 200; batch classifier loss: 0.363439; batch adversarial loss: 0.323310\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403442; batch adversarial loss: 0.318142\n",
      "epoch 48; iter: 200; batch classifier loss: 0.415903; batch adversarial loss: 0.500165\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474463; batch adversarial loss: 0.428637\n",
      "epoch 49; iter: 200; batch classifier loss: 0.248914; batch adversarial loss: 0.320744\n",
      "epoch 0; iter: 0; batch classifier loss: 4.877922; batch adversarial loss: 0.496609\n",
      "epoch 0; iter: 200; batch classifier loss: 4.418737; batch adversarial loss: 0.578356\n",
      "epoch 1; iter: 0; batch classifier loss: 1.884585; batch adversarial loss: 0.546467\n",
      "epoch 1; iter: 200; batch classifier loss: 1.831757; batch adversarial loss: 0.470169\n",
      "epoch 2; iter: 0; batch classifier loss: 1.889799; batch adversarial loss: 0.533027\n",
      "epoch 2; iter: 200; batch classifier loss: 2.099110; batch adversarial loss: 0.475065\n",
      "epoch 3; iter: 0; batch classifier loss: 10.220181; batch adversarial loss: 0.452035\n",
      "epoch 3; iter: 200; batch classifier loss: 2.136830; batch adversarial loss: 0.471140\n",
      "epoch 4; iter: 0; batch classifier loss: 2.680093; batch adversarial loss: 0.382171\n",
      "epoch 4; iter: 200; batch classifier loss: 1.350555; batch adversarial loss: 0.481123\n",
      "epoch 5; iter: 0; batch classifier loss: 2.004608; batch adversarial loss: 0.434258\n",
      "epoch 5; iter: 200; batch classifier loss: 0.643870; batch adversarial loss: 0.434927\n",
      "epoch 6; iter: 0; batch classifier loss: 0.454207; batch adversarial loss: 0.406250\n",
      "epoch 6; iter: 200; batch classifier loss: 0.613048; batch adversarial loss: 0.522327\n",
      "epoch 7; iter: 0; batch classifier loss: 0.988582; batch adversarial loss: 0.398004\n",
      "epoch 7; iter: 200; batch classifier loss: 0.411837; batch adversarial loss: 0.443126\n",
      "epoch 8; iter: 0; batch classifier loss: 0.670554; batch adversarial loss: 0.408365\n",
      "epoch 8; iter: 200; batch classifier loss: 0.330471; batch adversarial loss: 0.313850\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443531; batch adversarial loss: 0.451475\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368106; batch adversarial loss: 0.368804\n",
      "epoch 10; iter: 0; batch classifier loss: 0.356443; batch adversarial loss: 0.546089\n",
      "epoch 10; iter: 200; batch classifier loss: 0.438229; batch adversarial loss: 0.421763\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301675; batch adversarial loss: 0.459170\n",
      "epoch 11; iter: 200; batch classifier loss: 0.425804; batch adversarial loss: 0.438798\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495255; batch adversarial loss: 0.396329\n",
      "epoch 12; iter: 200; batch classifier loss: 0.398315; batch adversarial loss: 0.361933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.397261; batch adversarial loss: 0.443104\n",
      "epoch 13; iter: 200; batch classifier loss: 0.414241; batch adversarial loss: 0.422388\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309490; batch adversarial loss: 0.382924\n",
      "epoch 14; iter: 200; batch classifier loss: 0.374575; batch adversarial loss: 0.387470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474227; batch adversarial loss: 0.379336\n",
      "epoch 15; iter: 200; batch classifier loss: 0.414540; batch adversarial loss: 0.499366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.342040; batch adversarial loss: 0.471401\n",
      "epoch 16; iter: 200; batch classifier loss: 0.272256; batch adversarial loss: 0.348341\n",
      "epoch 17; iter: 0; batch classifier loss: 0.442764; batch adversarial loss: 0.308998\n",
      "epoch 17; iter: 200; batch classifier loss: 0.294160; batch adversarial loss: 0.408679\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300219; batch adversarial loss: 0.404357\n",
      "epoch 18; iter: 200; batch classifier loss: 0.428057; batch adversarial loss: 0.467715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396287; batch adversarial loss: 0.427918\n",
      "epoch 19; iter: 200; batch classifier loss: 0.450342; batch adversarial loss: 0.382527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310002; batch adversarial loss: 0.337165\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380051; batch adversarial loss: 0.412363\n",
      "epoch 21; iter: 0; batch classifier loss: 0.362615; batch adversarial loss: 0.412169\n",
      "epoch 21; iter: 200; batch classifier loss: 0.389720; batch adversarial loss: 0.331354\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330995; batch adversarial loss: 0.453454\n",
      "epoch 22; iter: 200; batch classifier loss: 0.503850; batch adversarial loss: 0.359598\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449734; batch adversarial loss: 0.379052\n",
      "epoch 23; iter: 200; batch classifier loss: 0.349101; batch adversarial loss: 0.391782\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387093; batch adversarial loss: 0.355331\n",
      "epoch 24; iter: 200; batch classifier loss: 0.358667; batch adversarial loss: 0.387363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357999; batch adversarial loss: 0.481765\n",
      "epoch 25; iter: 200; batch classifier loss: 0.354080; batch adversarial loss: 0.354837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.385580; batch adversarial loss: 0.302614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 200; batch classifier loss: 0.381937; batch adversarial loss: 0.366852\n",
      "epoch 27; iter: 0; batch classifier loss: 0.339671; batch adversarial loss: 0.417550\n",
      "epoch 27; iter: 200; batch classifier loss: 0.391610; batch adversarial loss: 0.380335\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286657; batch adversarial loss: 0.427847\n",
      "epoch 28; iter: 200; batch classifier loss: 0.244728; batch adversarial loss: 0.413857\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303979; batch adversarial loss: 0.412742\n",
      "epoch 29; iter: 200; batch classifier loss: 0.306376; batch adversarial loss: 0.346119\n",
      "epoch 30; iter: 0; batch classifier loss: 0.388609; batch adversarial loss: 0.380775\n",
      "epoch 30; iter: 200; batch classifier loss: 0.300800; batch adversarial loss: 0.302238\n",
      "epoch 31; iter: 0; batch classifier loss: 0.365673; batch adversarial loss: 0.338355\n",
      "epoch 31; iter: 200; batch classifier loss: 0.336274; batch adversarial loss: 0.316433\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364259; batch adversarial loss: 0.398176\n",
      "epoch 32; iter: 200; batch classifier loss: 0.293295; batch adversarial loss: 0.415579\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432882; batch adversarial loss: 0.484412\n",
      "epoch 33; iter: 200; batch classifier loss: 0.282642; batch adversarial loss: 0.469988\n",
      "epoch 34; iter: 0; batch classifier loss: 0.387179; batch adversarial loss: 0.355214\n",
      "epoch 34; iter: 200; batch classifier loss: 0.289841; batch adversarial loss: 0.441865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.344816; batch adversarial loss: 0.439063\n",
      "epoch 35; iter: 200; batch classifier loss: 0.274383; batch adversarial loss: 0.462734\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297571; batch adversarial loss: 0.339081\n",
      "epoch 36; iter: 200; batch classifier loss: 0.337678; batch adversarial loss: 0.488760\n",
      "epoch 37; iter: 0; batch classifier loss: 0.313192; batch adversarial loss: 0.377769\n",
      "epoch 37; iter: 200; batch classifier loss: 0.291868; batch adversarial loss: 0.356966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.361615; batch adversarial loss: 0.427516\n",
      "epoch 38; iter: 200; batch classifier loss: 0.300186; batch adversarial loss: 0.475510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402529; batch adversarial loss: 0.387192\n",
      "epoch 39; iter: 200; batch classifier loss: 0.217709; batch adversarial loss: 0.463431\n",
      "epoch 40; iter: 0; batch classifier loss: 0.362036; batch adversarial loss: 0.432462\n",
      "epoch 40; iter: 200; batch classifier loss: 0.311924; batch adversarial loss: 0.454405\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377213; batch adversarial loss: 0.383756\n",
      "epoch 41; iter: 200; batch classifier loss: 0.319025; batch adversarial loss: 0.433643\n",
      "epoch 42; iter: 0; batch classifier loss: 0.348778; batch adversarial loss: 0.301186\n",
      "epoch 42; iter: 200; batch classifier loss: 0.325529; batch adversarial loss: 0.362068\n",
      "epoch 43; iter: 0; batch classifier loss: 0.236396; batch adversarial loss: 0.310552\n",
      "epoch 43; iter: 200; batch classifier loss: 0.338100; batch adversarial loss: 0.418237\n",
      "epoch 44; iter: 0; batch classifier loss: 0.242698; batch adversarial loss: 0.394336\n",
      "epoch 44; iter: 200; batch classifier loss: 0.415056; batch adversarial loss: 0.469165\n",
      "epoch 45; iter: 0; batch classifier loss: 0.342104; batch adversarial loss: 0.506147\n",
      "epoch 45; iter: 200; batch classifier loss: 0.331740; batch adversarial loss: 0.443331\n",
      "epoch 46; iter: 0; batch classifier loss: 0.294201; batch adversarial loss: 0.320935\n",
      "epoch 46; iter: 200; batch classifier loss: 0.402862; batch adversarial loss: 0.373316\n",
      "epoch 47; iter: 0; batch classifier loss: 0.332013; batch adversarial loss: 0.531544\n",
      "epoch 47; iter: 200; batch classifier loss: 0.353049; batch adversarial loss: 0.248816\n",
      "epoch 48; iter: 0; batch classifier loss: 0.287348; batch adversarial loss: 0.427981\n",
      "epoch 48; iter: 200; batch classifier loss: 0.322561; batch adversarial loss: 0.312410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.300106; batch adversarial loss: 0.466683\n",
      "epoch 49; iter: 200; batch classifier loss: 0.281844; batch adversarial loss: 0.386406\n",
      "epoch 0; iter: 0; batch classifier loss: 12.218868; batch adversarial loss: 0.748286\n",
      "epoch 0; iter: 200; batch classifier loss: 4.922942; batch adversarial loss: 0.616227\n",
      "epoch 1; iter: 0; batch classifier loss: 6.529517; batch adversarial loss: 0.599865\n",
      "epoch 1; iter: 200; batch classifier loss: 1.365905; batch adversarial loss: 0.551080\n",
      "epoch 2; iter: 0; batch classifier loss: 2.058919; batch adversarial loss: 0.504558\n",
      "epoch 2; iter: 200; batch classifier loss: 2.899370; batch adversarial loss: 0.532807\n",
      "epoch 3; iter: 0; batch classifier loss: 0.486169; batch adversarial loss: 0.487855\n",
      "epoch 3; iter: 200; batch classifier loss: 1.036204; batch adversarial loss: 0.490121\n",
      "epoch 4; iter: 0; batch classifier loss: 1.715864; batch adversarial loss: 0.494127\n",
      "epoch 4; iter: 200; batch classifier loss: 0.660447; batch adversarial loss: 0.419508\n",
      "epoch 5; iter: 0; batch classifier loss: 0.639736; batch adversarial loss: 0.438309\n",
      "epoch 5; iter: 200; batch classifier loss: 0.932020; batch adversarial loss: 0.466324\n",
      "epoch 6; iter: 0; batch classifier loss: 0.450321; batch adversarial loss: 0.500915\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435366; batch adversarial loss: 0.320583\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379053; batch adversarial loss: 0.453975\n",
      "epoch 7; iter: 200; batch classifier loss: 0.570266; batch adversarial loss: 0.499591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498494; batch adversarial loss: 0.544049\n",
      "epoch 8; iter: 200; batch classifier loss: 0.582078; batch adversarial loss: 0.432139\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402287; batch adversarial loss: 0.433406\n",
      "epoch 9; iter: 200; batch classifier loss: 0.466654; batch adversarial loss: 0.421876\n",
      "epoch 10; iter: 0; batch classifier loss: 0.401729; batch adversarial loss: 0.422963\n",
      "epoch 10; iter: 200; batch classifier loss: 0.543684; batch adversarial loss: 0.421838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.356448; batch adversarial loss: 0.462318\n",
      "epoch 11; iter: 200; batch classifier loss: 0.345576; batch adversarial loss: 0.362947\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373333; batch adversarial loss: 0.387656\n",
      "epoch 12; iter: 200; batch classifier loss: 0.436877; batch adversarial loss: 0.321468\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411032; batch adversarial loss: 0.341036\n",
      "epoch 13; iter: 200; batch classifier loss: 0.429118; batch adversarial loss: 0.349080\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397633; batch adversarial loss: 0.409578\n",
      "epoch 14; iter: 200; batch classifier loss: 0.427014; batch adversarial loss: 0.454722\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336980; batch adversarial loss: 0.402514\n",
      "epoch 15; iter: 200; batch classifier loss: 0.330731; batch adversarial loss: 0.371566\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357406; batch adversarial loss: 0.425149\n",
      "epoch 16; iter: 200; batch classifier loss: 0.431153; batch adversarial loss: 0.413035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.370602; batch adversarial loss: 0.425057\n",
      "epoch 17; iter: 200; batch classifier loss: 0.405796; batch adversarial loss: 0.415653\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345976; batch adversarial loss: 0.436324\n",
      "epoch 18; iter: 200; batch classifier loss: 0.297134; batch adversarial loss: 0.387696\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331397; batch adversarial loss: 0.431699\n",
      "epoch 19; iter: 200; batch classifier loss: 0.292359; batch adversarial loss: 0.493185\n",
      "epoch 20; iter: 0; batch classifier loss: 0.352211; batch adversarial loss: 0.366223\n",
      "epoch 20; iter: 200; batch classifier loss: 0.430990; batch adversarial loss: 0.348858\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355631; batch adversarial loss: 0.448019\n",
      "epoch 21; iter: 200; batch classifier loss: 0.406392; batch adversarial loss: 0.444094\n",
      "epoch 22; iter: 0; batch classifier loss: 0.301796; batch adversarial loss: 0.456679\n",
      "epoch 22; iter: 200; batch classifier loss: 0.318729; batch adversarial loss: 0.317363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.295690; batch adversarial loss: 0.311928\n",
      "epoch 23; iter: 200; batch classifier loss: 0.319241; batch adversarial loss: 0.331334\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387670; batch adversarial loss: 0.500309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 200; batch classifier loss: 0.372163; batch adversarial loss: 0.373057\n",
      "epoch 25; iter: 0; batch classifier loss: 0.300745; batch adversarial loss: 0.407584\n",
      "epoch 25; iter: 200; batch classifier loss: 0.391823; batch adversarial loss: 0.359154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346513; batch adversarial loss: 0.331726\n",
      "epoch 26; iter: 200; batch classifier loss: 0.297764; batch adversarial loss: 0.321212\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321419; batch adversarial loss: 0.351992\n",
      "epoch 27; iter: 200; batch classifier loss: 0.356215; batch adversarial loss: 0.468239\n",
      "epoch 28; iter: 0; batch classifier loss: 0.327121; batch adversarial loss: 0.460271\n",
      "epoch 28; iter: 200; batch classifier loss: 0.417696; batch adversarial loss: 0.392631\n",
      "epoch 29; iter: 0; batch classifier loss: 0.351030; batch adversarial loss: 0.482054\n",
      "epoch 29; iter: 200; batch classifier loss: 0.332655; batch adversarial loss: 0.421476\n",
      "epoch 30; iter: 0; batch classifier loss: 0.362762; batch adversarial loss: 0.336815\n",
      "epoch 30; iter: 200; batch classifier loss: 0.401859; batch adversarial loss: 0.428031\n",
      "epoch 31; iter: 0; batch classifier loss: 0.372289; batch adversarial loss: 0.368510\n",
      "epoch 31; iter: 200; batch classifier loss: 0.371447; batch adversarial loss: 0.409745\n",
      "epoch 32; iter: 0; batch classifier loss: 0.328808; batch adversarial loss: 0.370943\n",
      "epoch 32; iter: 200; batch classifier loss: 0.261414; batch adversarial loss: 0.403251\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363492; batch adversarial loss: 0.383451\n",
      "epoch 33; iter: 200; batch classifier loss: 0.402478; batch adversarial loss: 0.482937\n",
      "epoch 34; iter: 0; batch classifier loss: 0.239033; batch adversarial loss: 0.420229\n",
      "epoch 34; iter: 200; batch classifier loss: 0.335423; batch adversarial loss: 0.445958\n",
      "epoch 35; iter: 0; batch classifier loss: 0.354634; batch adversarial loss: 0.383002\n",
      "epoch 35; iter: 200; batch classifier loss: 0.278502; batch adversarial loss: 0.505297\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343966; batch adversarial loss: 0.440673\n",
      "epoch 36; iter: 200; batch classifier loss: 0.347234; batch adversarial loss: 0.459560\n",
      "epoch 37; iter: 0; batch classifier loss: 0.331592; batch adversarial loss: 0.446837\n",
      "epoch 37; iter: 200; batch classifier loss: 0.328528; batch adversarial loss: 0.327023\n",
      "epoch 38; iter: 0; batch classifier loss: 0.357760; batch adversarial loss: 0.403748\n",
      "epoch 38; iter: 200; batch classifier loss: 0.309301; batch adversarial loss: 0.551717\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260358; batch adversarial loss: 0.333934\n",
      "epoch 39; iter: 200; batch classifier loss: 0.334487; batch adversarial loss: 0.409697\n",
      "epoch 40; iter: 0; batch classifier loss: 0.269521; batch adversarial loss: 0.319177\n",
      "epoch 40; iter: 200; batch classifier loss: 0.315123; batch adversarial loss: 0.303133\n",
      "epoch 41; iter: 0; batch classifier loss: 0.323023; batch adversarial loss: 0.384328\n",
      "epoch 41; iter: 200; batch classifier loss: 0.330508; batch adversarial loss: 0.490856\n",
      "epoch 42; iter: 0; batch classifier loss: 0.293200; batch adversarial loss: 0.345221\n",
      "epoch 42; iter: 200; batch classifier loss: 0.358146; batch adversarial loss: 0.545190\n",
      "epoch 43; iter: 0; batch classifier loss: 0.369951; batch adversarial loss: 0.458834\n",
      "epoch 43; iter: 200; batch classifier loss: 0.352338; batch adversarial loss: 0.403173\n",
      "epoch 44; iter: 0; batch classifier loss: 0.305609; batch adversarial loss: 0.413133\n",
      "epoch 44; iter: 200; batch classifier loss: 0.328396; batch adversarial loss: 0.371438\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465052; batch adversarial loss: 0.315646\n",
      "epoch 45; iter: 200; batch classifier loss: 0.402663; batch adversarial loss: 0.333219\n",
      "epoch 46; iter: 0; batch classifier loss: 0.307753; batch adversarial loss: 0.411918\n",
      "epoch 46; iter: 200; batch classifier loss: 0.296237; batch adversarial loss: 0.446981\n",
      "epoch 47; iter: 0; batch classifier loss: 0.361033; batch adversarial loss: 0.265052\n",
      "epoch 47; iter: 200; batch classifier loss: 0.387301; batch adversarial loss: 0.343807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.298269; batch adversarial loss: 0.393290\n",
      "epoch 48; iter: 200; batch classifier loss: 0.416627; batch adversarial loss: 0.334950\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399513; batch adversarial loss: 0.392953\n",
      "epoch 49; iter: 200; batch classifier loss: 0.338123; batch adversarial loss: 0.440457\n",
      "epoch 0; iter: 0; batch classifier loss: 32.053593; batch adversarial loss: 1.716721\n",
      "epoch 0; iter: 200; batch classifier loss: 2.871119; batch adversarial loss: 0.721415\n",
      "epoch 1; iter: 0; batch classifier loss: 7.544506; batch adversarial loss: 0.676137\n",
      "epoch 1; iter: 200; batch classifier loss: 2.247547; batch adversarial loss: 0.841523\n",
      "epoch 2; iter: 0; batch classifier loss: 13.320024; batch adversarial loss: 0.929894\n",
      "epoch 2; iter: 200; batch classifier loss: 1.123497; batch adversarial loss: 0.594308\n",
      "epoch 3; iter: 0; batch classifier loss: 2.445060; batch adversarial loss: 0.650833\n",
      "epoch 3; iter: 200; batch classifier loss: 2.921751; batch adversarial loss: 0.547219\n",
      "epoch 4; iter: 0; batch classifier loss: 1.509146; batch adversarial loss: 0.559246\n",
      "epoch 4; iter: 200; batch classifier loss: 0.784407; batch adversarial loss: 0.471031\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561700; batch adversarial loss: 0.473311\n",
      "epoch 5; iter: 200; batch classifier loss: 0.926673; batch adversarial loss: 0.465505\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304581; batch adversarial loss: 0.474232\n",
      "epoch 6; iter: 200; batch classifier loss: 0.729776; batch adversarial loss: 0.466635\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472899; batch adversarial loss: 0.415898\n",
      "epoch 7; iter: 200; batch classifier loss: 0.574530; batch adversarial loss: 0.425007\n",
      "epoch 8; iter: 0; batch classifier loss: 0.589396; batch adversarial loss: 0.469569\n",
      "epoch 8; iter: 200; batch classifier loss: 0.345684; batch adversarial loss: 0.403821\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516534; batch adversarial loss: 0.474233\n",
      "epoch 9; iter: 200; batch classifier loss: 0.402301; batch adversarial loss: 0.330628\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316513; batch adversarial loss: 0.481646\n",
      "epoch 10; iter: 200; batch classifier loss: 0.650061; batch adversarial loss: 0.436480\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396097; batch adversarial loss: 0.458831\n",
      "epoch 11; iter: 200; batch classifier loss: 0.447219; batch adversarial loss: 0.408297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391664; batch adversarial loss: 0.343777\n",
      "epoch 12; iter: 200; batch classifier loss: 0.303515; batch adversarial loss: 0.427217\n",
      "epoch 13; iter: 0; batch classifier loss: 0.375857; batch adversarial loss: 0.341194\n",
      "epoch 13; iter: 200; batch classifier loss: 0.447199; batch adversarial loss: 0.381414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438087; batch adversarial loss: 0.377809\n",
      "epoch 14; iter: 200; batch classifier loss: 0.327505; batch adversarial loss: 0.418601\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374260; batch adversarial loss: 0.323106\n",
      "epoch 15; iter: 200; batch classifier loss: 0.298457; batch adversarial loss: 0.400694\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335075; batch adversarial loss: 0.440530\n",
      "epoch 16; iter: 200; batch classifier loss: 0.424096; batch adversarial loss: 0.305431\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268704; batch adversarial loss: 0.437815\n",
      "epoch 17; iter: 200; batch classifier loss: 0.494148; batch adversarial loss: 0.407582\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333941; batch adversarial loss: 0.322871\n",
      "epoch 18; iter: 200; batch classifier loss: 0.415966; batch adversarial loss: 0.336797\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308259; batch adversarial loss: 0.428882\n",
      "epoch 19; iter: 200; batch classifier loss: 0.377667; batch adversarial loss: 0.398713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.280336; batch adversarial loss: 0.355920\n",
      "epoch 20; iter: 200; batch classifier loss: 0.423259; batch adversarial loss: 0.409888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543467; batch adversarial loss: 0.339356\n",
      "epoch 21; iter: 200; batch classifier loss: 0.762392; batch adversarial loss: 0.421906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.419283; batch adversarial loss: 0.408051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 200; batch classifier loss: 0.348315; batch adversarial loss: 0.365352\n",
      "epoch 23; iter: 0; batch classifier loss: 0.413303; batch adversarial loss: 0.327188\n",
      "epoch 23; iter: 200; batch classifier loss: 0.348925; batch adversarial loss: 0.388215\n",
      "epoch 24; iter: 0; batch classifier loss: 0.382804; batch adversarial loss: 0.374917\n",
      "epoch 24; iter: 200; batch classifier loss: 0.320111; batch adversarial loss: 0.407683\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266820; batch adversarial loss: 0.325402\n",
      "epoch 25; iter: 200; batch classifier loss: 0.460573; batch adversarial loss: 0.347834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.327508; batch adversarial loss: 0.482790\n",
      "epoch 26; iter: 200; batch classifier loss: 0.276309; batch adversarial loss: 0.430720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.332481; batch adversarial loss: 0.321765\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310486; batch adversarial loss: 0.405092\n",
      "epoch 28; iter: 0; batch classifier loss: 0.324484; batch adversarial loss: 0.380873\n",
      "epoch 28; iter: 200; batch classifier loss: 0.352453; batch adversarial loss: 0.441791\n",
      "epoch 29; iter: 0; batch classifier loss: 0.368606; batch adversarial loss: 0.291022\n",
      "epoch 29; iter: 200; batch classifier loss: 0.439998; batch adversarial loss: 0.371699\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324389; batch adversarial loss: 0.374239\n",
      "epoch 30; iter: 200; batch classifier loss: 0.329912; batch adversarial loss: 0.484678\n",
      "epoch 31; iter: 0; batch classifier loss: 0.376378; batch adversarial loss: 0.449164\n",
      "epoch 31; iter: 200; batch classifier loss: 0.288704; batch adversarial loss: 0.512835\n",
      "epoch 32; iter: 0; batch classifier loss: 0.338312; batch adversarial loss: 0.329586\n",
      "epoch 32; iter: 200; batch classifier loss: 0.356366; batch adversarial loss: 0.470943\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363208; batch adversarial loss: 0.367113\n",
      "epoch 33; iter: 200; batch classifier loss: 0.314408; batch adversarial loss: 0.444843\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432636; batch adversarial loss: 0.395570\n",
      "epoch 34; iter: 200; batch classifier loss: 0.363045; batch adversarial loss: 0.391034\n",
      "epoch 35; iter: 0; batch classifier loss: 0.338162; batch adversarial loss: 0.406443\n",
      "epoch 35; iter: 200; batch classifier loss: 0.319249; batch adversarial loss: 0.470529\n",
      "epoch 36; iter: 0; batch classifier loss: 0.274219; batch adversarial loss: 0.385981\n",
      "epoch 36; iter: 200; batch classifier loss: 0.249870; batch adversarial loss: 0.384072\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402950; batch adversarial loss: 0.362964\n",
      "epoch 37; iter: 200; batch classifier loss: 0.336607; batch adversarial loss: 0.388393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.303597; batch adversarial loss: 0.418840\n",
      "epoch 38; iter: 200; batch classifier loss: 0.402807; batch adversarial loss: 0.389222\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401527; batch adversarial loss: 0.426296\n",
      "epoch 39; iter: 200; batch classifier loss: 0.318260; batch adversarial loss: 0.421745\n",
      "epoch 40; iter: 0; batch classifier loss: 0.311714; batch adversarial loss: 0.350901\n",
      "epoch 40; iter: 200; batch classifier loss: 0.322273; batch adversarial loss: 0.384918\n",
      "epoch 41; iter: 0; batch classifier loss: 0.535791; batch adversarial loss: 0.460519\n",
      "epoch 41; iter: 200; batch classifier loss: 0.358159; batch adversarial loss: 0.319760\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465062; batch adversarial loss: 0.365781\n",
      "epoch 42; iter: 200; batch classifier loss: 0.472049; batch adversarial loss: 0.389110\n",
      "epoch 43; iter: 0; batch classifier loss: 0.331212; batch adversarial loss: 0.395807\n",
      "epoch 43; iter: 200; batch classifier loss: 0.374173; batch adversarial loss: 0.440032\n",
      "epoch 44; iter: 0; batch classifier loss: 0.324294; batch adversarial loss: 0.418029\n",
      "epoch 44; iter: 200; batch classifier loss: 0.343521; batch adversarial loss: 0.393339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.314693; batch adversarial loss: 0.360345\n",
      "epoch 45; iter: 200; batch classifier loss: 0.344972; batch adversarial loss: 0.344753\n",
      "epoch 46; iter: 0; batch classifier loss: 0.341865; batch adversarial loss: 0.340707\n",
      "epoch 46; iter: 200; batch classifier loss: 0.234382; batch adversarial loss: 0.435403\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247788; batch adversarial loss: 0.484414\n",
      "epoch 47; iter: 200; batch classifier loss: 0.311769; batch adversarial loss: 0.428268\n",
      "epoch 48; iter: 0; batch classifier loss: 0.378788; batch adversarial loss: 0.389068\n",
      "epoch 48; iter: 200; batch classifier loss: 0.322197; batch adversarial loss: 0.443566\n",
      "epoch 49; iter: 0; batch classifier loss: 0.271777; batch adversarial loss: 0.486087\n",
      "epoch 49; iter: 200; batch classifier loss: 0.291491; batch adversarial loss: 0.427187\n",
      "epoch 0; iter: 0; batch classifier loss: 5.674304; batch adversarial loss: 0.863280\n",
      "epoch 0; iter: 200; batch classifier loss: 7.654457; batch adversarial loss: 0.741784\n",
      "epoch 1; iter: 0; batch classifier loss: 21.222073; batch adversarial loss: 0.714080\n",
      "epoch 1; iter: 200; batch classifier loss: 2.732993; batch adversarial loss: 0.563286\n",
      "epoch 2; iter: 0; batch classifier loss: 2.005574; batch adversarial loss: 0.587393\n",
      "epoch 2; iter: 200; batch classifier loss: 0.687856; batch adversarial loss: 0.494236\n",
      "epoch 3; iter: 0; batch classifier loss: 1.358290; batch adversarial loss: 0.503263\n",
      "epoch 3; iter: 200; batch classifier loss: 0.475137; batch adversarial loss: 0.488975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.811322; batch adversarial loss: 0.476315\n",
      "epoch 4; iter: 200; batch classifier loss: 0.677093; batch adversarial loss: 0.501961\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573378; batch adversarial loss: 0.481300\n",
      "epoch 5; iter: 200; batch classifier loss: 0.432956; batch adversarial loss: 0.396684\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641482; batch adversarial loss: 0.402821\n",
      "epoch 6; iter: 200; batch classifier loss: 0.278552; batch adversarial loss: 0.367086\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460508; batch adversarial loss: 0.415165\n",
      "epoch 7; iter: 200; batch classifier loss: 0.353826; batch adversarial loss: 0.470494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340826; batch adversarial loss: 0.402404\n",
      "epoch 8; iter: 200; batch classifier loss: 0.423779; batch adversarial loss: 0.434631\n",
      "epoch 9; iter: 0; batch classifier loss: 0.368098; batch adversarial loss: 0.440463\n",
      "epoch 9; iter: 200; batch classifier loss: 0.363301; batch adversarial loss: 0.531551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507310; batch adversarial loss: 0.402594\n",
      "epoch 10; iter: 200; batch classifier loss: 0.394975; batch adversarial loss: 0.390171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.399527; batch adversarial loss: 0.407146\n",
      "epoch 11; iter: 200; batch classifier loss: 0.518114; batch adversarial loss: 0.441776\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468169; batch adversarial loss: 0.352458\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339800; batch adversarial loss: 0.423459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484782; batch adversarial loss: 0.427847\n",
      "epoch 13; iter: 200; batch classifier loss: 0.363583; batch adversarial loss: 0.314816\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340470; batch adversarial loss: 0.448367\n",
      "epoch 14; iter: 200; batch classifier loss: 0.278134; batch adversarial loss: 0.451554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.388843; batch adversarial loss: 0.413731\n",
      "epoch 15; iter: 200; batch classifier loss: 0.322096; batch adversarial loss: 0.502912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358650; batch adversarial loss: 0.382351\n",
      "epoch 16; iter: 200; batch classifier loss: 0.413197; batch adversarial loss: 0.369474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291897; batch adversarial loss: 0.346127\n",
      "epoch 17; iter: 200; batch classifier loss: 0.406944; batch adversarial loss: 0.414509\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482282; batch adversarial loss: 0.481755\n",
      "epoch 18; iter: 200; batch classifier loss: 0.419754; batch adversarial loss: 0.447148\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503814; batch adversarial loss: 0.373008\n",
      "epoch 19; iter: 200; batch classifier loss: 0.306716; batch adversarial loss: 0.291688\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387907; batch adversarial loss: 0.334290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 200; batch classifier loss: 0.260380; batch adversarial loss: 0.368042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.303252; batch adversarial loss: 0.371612\n",
      "epoch 21; iter: 200; batch classifier loss: 0.347331; batch adversarial loss: 0.397939\n",
      "epoch 22; iter: 0; batch classifier loss: 0.362010; batch adversarial loss: 0.255200\n",
      "epoch 22; iter: 200; batch classifier loss: 0.261810; batch adversarial loss: 0.336895\n",
      "epoch 23; iter: 0; batch classifier loss: 0.330085; batch adversarial loss: 0.385978\n",
      "epoch 23; iter: 200; batch classifier loss: 0.360021; batch adversarial loss: 0.495974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322548; batch adversarial loss: 0.453225\n",
      "epoch 24; iter: 200; batch classifier loss: 0.354422; batch adversarial loss: 0.391814\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309820; batch adversarial loss: 0.472345\n",
      "epoch 25; iter: 200; batch classifier loss: 0.338895; batch adversarial loss: 0.411409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258044; batch adversarial loss: 0.323977\n",
      "epoch 26; iter: 200; batch classifier loss: 0.347865; batch adversarial loss: 0.463564\n",
      "epoch 27; iter: 0; batch classifier loss: 0.328836; batch adversarial loss: 0.503381\n",
      "epoch 27; iter: 200; batch classifier loss: 0.320847; batch adversarial loss: 0.366246\n",
      "epoch 28; iter: 0; batch classifier loss: 0.335618; batch adversarial loss: 0.386318\n",
      "epoch 28; iter: 200; batch classifier loss: 0.385362; batch adversarial loss: 0.347349\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358184; batch adversarial loss: 0.553575\n",
      "epoch 29; iter: 200; batch classifier loss: 0.383628; batch adversarial loss: 0.420903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320329; batch adversarial loss: 0.384794\n",
      "epoch 30; iter: 200; batch classifier loss: 0.328306; batch adversarial loss: 0.436293\n",
      "epoch 31; iter: 0; batch classifier loss: 0.351214; batch adversarial loss: 0.328316\n",
      "epoch 31; iter: 200; batch classifier loss: 0.405718; batch adversarial loss: 0.380783\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431608; batch adversarial loss: 0.416335\n",
      "epoch 32; iter: 200; batch classifier loss: 0.356466; batch adversarial loss: 0.449841\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414709; batch adversarial loss: 0.454169\n",
      "epoch 33; iter: 200; batch classifier loss: 0.414213; batch adversarial loss: 0.318569\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327133; batch adversarial loss: 0.422906\n",
      "epoch 34; iter: 200; batch classifier loss: 0.303468; batch adversarial loss: 0.474892\n",
      "epoch 35; iter: 0; batch classifier loss: 0.357991; batch adversarial loss: 0.316281\n",
      "epoch 35; iter: 200; batch classifier loss: 0.271446; batch adversarial loss: 0.422861\n",
      "epoch 36; iter: 0; batch classifier loss: 0.354800; batch adversarial loss: 0.437828\n",
      "epoch 36; iter: 200; batch classifier loss: 0.313523; batch adversarial loss: 0.339574\n",
      "epoch 37; iter: 0; batch classifier loss: 0.308773; batch adversarial loss: 0.365368\n",
      "epoch 37; iter: 200; batch classifier loss: 0.384244; batch adversarial loss: 0.467222\n",
      "epoch 38; iter: 0; batch classifier loss: 0.351946; batch adversarial loss: 0.317450\n",
      "epoch 38; iter: 200; batch classifier loss: 0.374437; batch adversarial loss: 0.358652\n",
      "epoch 39; iter: 0; batch classifier loss: 0.311414; batch adversarial loss: 0.417957\n",
      "epoch 39; iter: 200; batch classifier loss: 0.303272; batch adversarial loss: 0.383935\n",
      "epoch 40; iter: 0; batch classifier loss: 0.355183; batch adversarial loss: 0.430810\n",
      "epoch 40; iter: 200; batch classifier loss: 0.311766; batch adversarial loss: 0.361154\n",
      "epoch 41; iter: 0; batch classifier loss: 0.345293; batch adversarial loss: 0.409877\n",
      "epoch 41; iter: 200; batch classifier loss: 0.300778; batch adversarial loss: 0.370764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383335; batch adversarial loss: 0.449053\n",
      "epoch 42; iter: 200; batch classifier loss: 0.328180; batch adversarial loss: 0.402775\n",
      "epoch 43; iter: 0; batch classifier loss: 0.346887; batch adversarial loss: 0.273412\n",
      "epoch 43; iter: 200; batch classifier loss: 0.290520; batch adversarial loss: 0.362230\n",
      "epoch 44; iter: 0; batch classifier loss: 0.340026; batch adversarial loss: 0.438455\n",
      "epoch 44; iter: 200; batch classifier loss: 0.371952; batch adversarial loss: 0.401756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.276413; batch adversarial loss: 0.444240\n",
      "epoch 45; iter: 200; batch classifier loss: 0.365692; batch adversarial loss: 0.316776\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437549; batch adversarial loss: 0.407380\n",
      "epoch 46; iter: 200; batch classifier loss: 0.293759; batch adversarial loss: 0.356183\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348916; batch adversarial loss: 0.424799\n",
      "epoch 47; iter: 200; batch classifier loss: 0.336728; batch adversarial loss: 0.505402\n",
      "epoch 48; iter: 0; batch classifier loss: 0.303837; batch adversarial loss: 0.499542\n",
      "epoch 48; iter: 200; batch classifier loss: 0.383075; batch adversarial loss: 0.459437\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394117; batch adversarial loss: 0.357658\n",
      "epoch 49; iter: 200; batch classifier loss: 0.346653; batch adversarial loss: 0.388419\n",
      "epoch 0; iter: 0; batch classifier loss: 18.134829; batch adversarial loss: 0.636429\n",
      "epoch 0; iter: 200; batch classifier loss: 9.903067; batch adversarial loss: 0.608690\n",
      "epoch 1; iter: 0; batch classifier loss: 7.579929; batch adversarial loss: 0.552579\n",
      "epoch 1; iter: 200; batch classifier loss: 4.445254; batch adversarial loss: 0.533590\n",
      "epoch 2; iter: 0; batch classifier loss: 0.734032; batch adversarial loss: 0.493802\n",
      "epoch 2; iter: 200; batch classifier loss: 3.231099; batch adversarial loss: 0.442126\n",
      "epoch 3; iter: 0; batch classifier loss: 2.693960; batch adversarial loss: 0.569325\n",
      "epoch 3; iter: 200; batch classifier loss: 3.707811; batch adversarial loss: 0.511415\n",
      "epoch 4; iter: 0; batch classifier loss: 0.934257; batch adversarial loss: 0.515974\n",
      "epoch 4; iter: 200; batch classifier loss: 0.716179; batch adversarial loss: 0.404241\n",
      "epoch 5; iter: 0; batch classifier loss: 1.146695; batch adversarial loss: 0.466780\n",
      "epoch 5; iter: 200; batch classifier loss: 0.557097; batch adversarial loss: 0.386263\n",
      "epoch 6; iter: 0; batch classifier loss: 1.681811; batch adversarial loss: 0.382656\n",
      "epoch 6; iter: 200; batch classifier loss: 0.856579; batch adversarial loss: 0.495233\n",
      "epoch 7; iter: 0; batch classifier loss: 0.756135; batch adversarial loss: 0.400686\n",
      "epoch 7; iter: 200; batch classifier loss: 0.710337; batch adversarial loss: 0.490972\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420039; batch adversarial loss: 0.365258\n",
      "epoch 8; iter: 200; batch classifier loss: 0.382490; batch adversarial loss: 0.420789\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359657; batch adversarial loss: 0.401330\n",
      "epoch 9; iter: 200; batch classifier loss: 0.425995; batch adversarial loss: 0.383417\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461398; batch adversarial loss: 0.462407\n",
      "epoch 10; iter: 200; batch classifier loss: 0.422868; batch adversarial loss: 0.337186\n",
      "epoch 11; iter: 0; batch classifier loss: 0.445589; batch adversarial loss: 0.444292\n",
      "epoch 11; iter: 200; batch classifier loss: 0.545624; batch adversarial loss: 0.383613\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385878; batch adversarial loss: 0.402543\n",
      "epoch 12; iter: 200; batch classifier loss: 0.359463; batch adversarial loss: 0.468316\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279805; batch adversarial loss: 0.423051\n",
      "epoch 13; iter: 200; batch classifier loss: 0.397089; batch adversarial loss: 0.443693\n",
      "epoch 14; iter: 0; batch classifier loss: 0.362215; batch adversarial loss: 0.486023\n",
      "epoch 14; iter: 200; batch classifier loss: 0.398645; batch adversarial loss: 0.413741\n",
      "epoch 15; iter: 0; batch classifier loss: 0.735758; batch adversarial loss: 0.361077\n",
      "epoch 15; iter: 200; batch classifier loss: 0.326084; batch adversarial loss: 0.453591\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302457; batch adversarial loss: 0.361015\n",
      "epoch 16; iter: 200; batch classifier loss: 0.559971; batch adversarial loss: 0.339048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367094; batch adversarial loss: 0.319829\n",
      "epoch 17; iter: 200; batch classifier loss: 0.347529; batch adversarial loss: 0.399491\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222079; batch adversarial loss: 0.450673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 200; batch classifier loss: 0.311985; batch adversarial loss: 0.372399\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284389; batch adversarial loss: 0.414487\n",
      "epoch 19; iter: 200; batch classifier loss: 0.301479; batch adversarial loss: 0.320359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313817; batch adversarial loss: 0.419522\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379259; batch adversarial loss: 0.532723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369089; batch adversarial loss: 0.404500\n",
      "epoch 21; iter: 200; batch classifier loss: 0.410190; batch adversarial loss: 0.506827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.388634; batch adversarial loss: 0.345454\n",
      "epoch 22; iter: 200; batch classifier loss: 0.285386; batch adversarial loss: 0.441961\n",
      "epoch 23; iter: 0; batch classifier loss: 0.338955; batch adversarial loss: 0.396951\n",
      "epoch 23; iter: 200; batch classifier loss: 0.362992; batch adversarial loss: 0.466892\n",
      "epoch 24; iter: 0; batch classifier loss: 0.334351; batch adversarial loss: 0.309431\n",
      "epoch 24; iter: 200; batch classifier loss: 0.313637; batch adversarial loss: 0.359181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.335221; batch adversarial loss: 0.377199\n",
      "epoch 25; iter: 200; batch classifier loss: 0.355618; batch adversarial loss: 0.311031\n",
      "epoch 26; iter: 0; batch classifier loss: 0.368088; batch adversarial loss: 0.388000\n",
      "epoch 26; iter: 200; batch classifier loss: 0.221970; batch adversarial loss: 0.386686\n",
      "epoch 27; iter: 0; batch classifier loss: 0.387018; batch adversarial loss: 0.385355\n",
      "epoch 27; iter: 200; batch classifier loss: 0.366542; batch adversarial loss: 0.376196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.372693; batch adversarial loss: 0.317733\n",
      "epoch 28; iter: 200; batch classifier loss: 0.340548; batch adversarial loss: 0.378310\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338374; batch adversarial loss: 0.420874\n",
      "epoch 29; iter: 200; batch classifier loss: 0.308646; batch adversarial loss: 0.376417\n",
      "epoch 30; iter: 0; batch classifier loss: 0.359220; batch adversarial loss: 0.387168\n",
      "epoch 30; iter: 200; batch classifier loss: 0.370333; batch adversarial loss: 0.432708\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284548; batch adversarial loss: 0.395729\n",
      "epoch 31; iter: 200; batch classifier loss: 0.328237; batch adversarial loss: 0.336785\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318977; batch adversarial loss: 0.401664\n",
      "epoch 32; iter: 200; batch classifier loss: 0.331120; batch adversarial loss: 0.351889\n",
      "epoch 33; iter: 0; batch classifier loss: 0.325333; batch adversarial loss: 0.358082\n",
      "epoch 33; iter: 200; batch classifier loss: 0.489474; batch adversarial loss: 0.317416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.290062; batch adversarial loss: 0.462109\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337041; batch adversarial loss: 0.345414\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390390; batch adversarial loss: 0.451358\n",
      "epoch 35; iter: 200; batch classifier loss: 0.277503; batch adversarial loss: 0.335761\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343160; batch adversarial loss: 0.413067\n",
      "epoch 36; iter: 200; batch classifier loss: 0.294812; batch adversarial loss: 0.382055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.339494; batch adversarial loss: 0.406782\n",
      "epoch 37; iter: 200; batch classifier loss: 0.379906; batch adversarial loss: 0.494934\n",
      "epoch 38; iter: 0; batch classifier loss: 0.344255; batch adversarial loss: 0.325846\n",
      "epoch 38; iter: 200; batch classifier loss: 0.284156; batch adversarial loss: 0.316453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269999; batch adversarial loss: 0.457590\n",
      "epoch 39; iter: 200; batch classifier loss: 0.336216; batch adversarial loss: 0.397788\n",
      "epoch 40; iter: 0; batch classifier loss: 0.272216; batch adversarial loss: 0.345950\n",
      "epoch 40; iter: 200; batch classifier loss: 0.310137; batch adversarial loss: 0.307429\n",
      "epoch 41; iter: 0; batch classifier loss: 0.344836; batch adversarial loss: 0.432878\n",
      "epoch 41; iter: 200; batch classifier loss: 0.218568; batch adversarial loss: 0.436830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.258148; batch adversarial loss: 0.409092\n",
      "epoch 42; iter: 200; batch classifier loss: 0.271751; batch adversarial loss: 0.387313\n",
      "epoch 43; iter: 0; batch classifier loss: 0.332315; batch adversarial loss: 0.350175\n",
      "epoch 43; iter: 200; batch classifier loss: 0.333325; batch adversarial loss: 0.509207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.356327; batch adversarial loss: 0.453313\n",
      "epoch 44; iter: 200; batch classifier loss: 0.367256; batch adversarial loss: 0.381447\n",
      "epoch 45; iter: 0; batch classifier loss: 0.361418; batch adversarial loss: 0.381246\n",
      "epoch 45; iter: 200; batch classifier loss: 0.283470; batch adversarial loss: 0.342061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442580; batch adversarial loss: 0.401446\n",
      "epoch 46; iter: 200; batch classifier loss: 0.332490; batch adversarial loss: 0.340473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399535; batch adversarial loss: 0.490370\n",
      "epoch 47; iter: 200; batch classifier loss: 0.341251; batch adversarial loss: 0.380243\n",
      "epoch 48; iter: 0; batch classifier loss: 0.349416; batch adversarial loss: 0.404523\n",
      "epoch 48; iter: 200; batch classifier loss: 0.354782; batch adversarial loss: 0.545166\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442364; batch adversarial loss: 0.383368\n",
      "epoch 49; iter: 200; batch classifier loss: 0.366881; batch adversarial loss: 0.467899\n",
      "epoch 0; iter: 0; batch classifier loss: 18.172865; batch adversarial loss: 0.615537\n",
      "epoch 0; iter: 200; batch classifier loss: 8.128878; batch adversarial loss: 0.601956\n",
      "epoch 1; iter: 0; batch classifier loss: 0.732907; batch adversarial loss: 0.563940\n",
      "epoch 1; iter: 200; batch classifier loss: 3.800556; batch adversarial loss: 0.542541\n",
      "epoch 2; iter: 0; batch classifier loss: 1.162528; batch adversarial loss: 0.529382\n",
      "epoch 2; iter: 200; batch classifier loss: 3.405328; batch adversarial loss: 0.498507\n",
      "epoch 3; iter: 0; batch classifier loss: 4.243818; batch adversarial loss: 0.485962\n",
      "epoch 3; iter: 200; batch classifier loss: 1.274638; batch adversarial loss: 0.448428\n",
      "epoch 4; iter: 0; batch classifier loss: 3.482599; batch adversarial loss: 0.454618\n",
      "epoch 4; iter: 200; batch classifier loss: 4.206916; batch adversarial loss: 0.397161\n",
      "epoch 5; iter: 0; batch classifier loss: 0.815524; batch adversarial loss: 0.428419\n",
      "epoch 5; iter: 200; batch classifier loss: 0.970196; batch adversarial loss: 0.413263\n",
      "epoch 6; iter: 0; batch classifier loss: 1.011833; batch adversarial loss: 0.412369\n",
      "epoch 6; iter: 200; batch classifier loss: 0.409550; batch adversarial loss: 0.519001\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338106; batch adversarial loss: 0.309501\n",
      "epoch 7; iter: 200; batch classifier loss: 0.581132; batch adversarial loss: 0.378878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.510106; batch adversarial loss: 0.442014\n",
      "epoch 8; iter: 200; batch classifier loss: 0.472059; batch adversarial loss: 0.486767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.415145; batch adversarial loss: 0.436396\n",
      "epoch 9; iter: 200; batch classifier loss: 0.286637; batch adversarial loss: 0.511817\n",
      "epoch 10; iter: 0; batch classifier loss: 0.640136; batch adversarial loss: 0.462958\n",
      "epoch 10; iter: 200; batch classifier loss: 0.469235; batch adversarial loss: 0.396254\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425504; batch adversarial loss: 0.405982\n",
      "epoch 11; iter: 200; batch classifier loss: 0.396657; batch adversarial loss: 0.403071\n",
      "epoch 12; iter: 0; batch classifier loss: 0.419583; batch adversarial loss: 0.250924\n",
      "epoch 12; iter: 200; batch classifier loss: 0.396263; batch adversarial loss: 0.425262\n",
      "epoch 13; iter: 0; batch classifier loss: 0.413885; batch adversarial loss: 0.380553\n",
      "epoch 13; iter: 200; batch classifier loss: 0.486152; batch adversarial loss: 0.445442\n",
      "epoch 14; iter: 0; batch classifier loss: 0.424477; batch adversarial loss: 0.429480\n",
      "epoch 14; iter: 200; batch classifier loss: 0.283826; batch adversarial loss: 0.401103\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473704; batch adversarial loss: 0.460087\n",
      "epoch 15; iter: 200; batch classifier loss: 0.477267; batch adversarial loss: 0.400678\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408401; batch adversarial loss: 0.340964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 200; batch classifier loss: 0.498852; batch adversarial loss: 0.416481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363910; batch adversarial loss: 0.483675\n",
      "epoch 17; iter: 200; batch classifier loss: 0.367274; batch adversarial loss: 0.385080\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430218; batch adversarial loss: 0.581949\n",
      "epoch 18; iter: 200; batch classifier loss: 0.542023; batch adversarial loss: 0.351700\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445347; batch adversarial loss: 0.375560\n",
      "epoch 19; iter: 200; batch classifier loss: 0.394718; batch adversarial loss: 0.373724\n",
      "epoch 20; iter: 0; batch classifier loss: 0.355979; batch adversarial loss: 0.374033\n",
      "epoch 20; iter: 200; batch classifier loss: 0.394842; batch adversarial loss: 0.338979\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289139; batch adversarial loss: 0.459683\n",
      "epoch 21; iter: 200; batch classifier loss: 0.317775; batch adversarial loss: 0.407746\n",
      "epoch 22; iter: 0; batch classifier loss: 0.376881; batch adversarial loss: 0.464630\n",
      "epoch 22; iter: 200; batch classifier loss: 0.414476; batch adversarial loss: 0.435955\n",
      "epoch 23; iter: 0; batch classifier loss: 0.302213; batch adversarial loss: 0.325548\n",
      "epoch 23; iter: 200; batch classifier loss: 0.384967; batch adversarial loss: 0.416717\n",
      "epoch 24; iter: 0; batch classifier loss: 0.319923; batch adversarial loss: 0.433479\n",
      "epoch 24; iter: 200; batch classifier loss: 0.300080; batch adversarial loss: 0.331685\n",
      "epoch 25; iter: 0; batch classifier loss: 0.390329; batch adversarial loss: 0.431187\n",
      "epoch 25; iter: 200; batch classifier loss: 0.368295; batch adversarial loss: 0.399543\n",
      "epoch 26; iter: 0; batch classifier loss: 0.358726; batch adversarial loss: 0.528443\n",
      "epoch 26; iter: 200; batch classifier loss: 0.405796; batch adversarial loss: 0.343254\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428499; batch adversarial loss: 0.433742\n",
      "epoch 27; iter: 200; batch classifier loss: 0.260289; batch adversarial loss: 0.446090\n",
      "epoch 28; iter: 0; batch classifier loss: 0.374388; batch adversarial loss: 0.486352\n",
      "epoch 28; iter: 200; batch classifier loss: 0.339469; batch adversarial loss: 0.390354\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388985; batch adversarial loss: 0.275854\n",
      "epoch 29; iter: 200; batch classifier loss: 0.377656; batch adversarial loss: 0.417447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.321165; batch adversarial loss: 0.478807\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386201; batch adversarial loss: 0.502607\n",
      "epoch 31; iter: 0; batch classifier loss: 0.326599; batch adversarial loss: 0.282546\n",
      "epoch 31; iter: 200; batch classifier loss: 0.313540; batch adversarial loss: 0.444976\n",
      "epoch 32; iter: 0; batch classifier loss: 0.505356; batch adversarial loss: 0.478986\n",
      "epoch 32; iter: 200; batch classifier loss: 0.300210; batch adversarial loss: 0.345299\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272541; batch adversarial loss: 0.468108\n",
      "epoch 33; iter: 200; batch classifier loss: 0.320126; batch adversarial loss: 0.422510\n",
      "epoch 34; iter: 0; batch classifier loss: 0.321313; batch adversarial loss: 0.340898\n",
      "epoch 34; iter: 200; batch classifier loss: 0.326869; batch adversarial loss: 0.444810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.373383; batch adversarial loss: 0.463303\n",
      "epoch 35; iter: 200; batch classifier loss: 0.294050; batch adversarial loss: 0.471634\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353531; batch adversarial loss: 0.444883\n",
      "epoch 36; iter: 200; batch classifier loss: 0.428752; batch adversarial loss: 0.438241\n",
      "epoch 37; iter: 0; batch classifier loss: 0.269708; batch adversarial loss: 0.355346\n",
      "epoch 37; iter: 200; batch classifier loss: 0.316915; batch adversarial loss: 0.406569\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392067; batch adversarial loss: 0.440039\n",
      "epoch 38; iter: 200; batch classifier loss: 0.282605; batch adversarial loss: 0.454013\n",
      "epoch 39; iter: 0; batch classifier loss: 0.317080; batch adversarial loss: 0.405293\n",
      "epoch 39; iter: 200; batch classifier loss: 0.421807; batch adversarial loss: 0.361001\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375239; batch adversarial loss: 0.394303\n",
      "epoch 40; iter: 200; batch classifier loss: 0.294394; batch adversarial loss: 0.373768\n",
      "epoch 41; iter: 0; batch classifier loss: 0.306456; batch adversarial loss: 0.402853\n",
      "epoch 41; iter: 200; batch classifier loss: 0.350450; batch adversarial loss: 0.480535\n",
      "epoch 42; iter: 0; batch classifier loss: 0.254680; batch adversarial loss: 0.385446\n",
      "epoch 42; iter: 200; batch classifier loss: 0.273080; batch adversarial loss: 0.452379\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386142; batch adversarial loss: 0.455892\n",
      "epoch 43; iter: 200; batch classifier loss: 0.365961; batch adversarial loss: 0.377481\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405654; batch adversarial loss: 0.377028\n",
      "epoch 44; iter: 200; batch classifier loss: 0.322043; batch adversarial loss: 0.421281\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423484; batch adversarial loss: 0.505084\n",
      "epoch 45; iter: 200; batch classifier loss: 0.441656; batch adversarial loss: 0.479231\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430005; batch adversarial loss: 0.460126\n",
      "epoch 46; iter: 200; batch classifier loss: 0.409640; batch adversarial loss: 0.385175\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471340; batch adversarial loss: 0.443123\n",
      "epoch 47; iter: 200; batch classifier loss: 0.259219; batch adversarial loss: 0.385722\n",
      "epoch 48; iter: 0; batch classifier loss: 0.612811; batch adversarial loss: 0.339127\n",
      "epoch 48; iter: 200; batch classifier loss: 0.332819; batch adversarial loss: 0.467870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465549; batch adversarial loss: 0.424949\n",
      "epoch 49; iter: 200; batch classifier loss: 0.415282; batch adversarial loss: 0.383140\n",
      "epoch 0; iter: 0; batch classifier loss: 87.847305; batch adversarial loss: 0.684559\n",
      "epoch 0; iter: 200; batch classifier loss: 20.611456; batch adversarial loss: 0.558769\n",
      "epoch 1; iter: 0; batch classifier loss: 1.774879; batch adversarial loss: 0.602807\n",
      "epoch 1; iter: 200; batch classifier loss: 2.589869; batch adversarial loss: 0.530659\n",
      "epoch 2; iter: 0; batch classifier loss: 6.828609; batch adversarial loss: 0.553035\n",
      "epoch 2; iter: 200; batch classifier loss: 1.904325; batch adversarial loss: 0.507981\n",
      "epoch 3; iter: 0; batch classifier loss: 3.761299; batch adversarial loss: 0.475288\n",
      "epoch 3; iter: 200; batch classifier loss: 1.307141; batch adversarial loss: 0.459669\n",
      "epoch 4; iter: 0; batch classifier loss: 0.928516; batch adversarial loss: 0.459854\n",
      "epoch 4; iter: 200; batch classifier loss: 2.057862; batch adversarial loss: 0.436148\n",
      "epoch 5; iter: 0; batch classifier loss: 3.860310; batch adversarial loss: 0.453560\n",
      "epoch 5; iter: 200; batch classifier loss: 0.858319; batch adversarial loss: 0.402623\n",
      "epoch 6; iter: 0; batch classifier loss: 2.077754; batch adversarial loss: 0.438879\n",
      "epoch 6; iter: 200; batch classifier loss: 0.781699; batch adversarial loss: 0.408017\n",
      "epoch 7; iter: 0; batch classifier loss: 0.794147; batch adversarial loss: 0.390012\n",
      "epoch 7; iter: 200; batch classifier loss: 0.406301; batch adversarial loss: 0.410860\n",
      "epoch 8; iter: 0; batch classifier loss: 0.778076; batch adversarial loss: 0.516081\n",
      "epoch 8; iter: 200; batch classifier loss: 0.728474; batch adversarial loss: 0.393831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.826253; batch adversarial loss: 0.349173\n",
      "epoch 9; iter: 200; batch classifier loss: 0.344761; batch adversarial loss: 0.479970\n",
      "epoch 10; iter: 0; batch classifier loss: 1.937809; batch adversarial loss: 0.371449\n",
      "epoch 10; iter: 200; batch classifier loss: 0.463461; batch adversarial loss: 0.410239\n",
      "epoch 11; iter: 0; batch classifier loss: 0.581540; batch adversarial loss: 0.457566\n",
      "epoch 11; iter: 200; batch classifier loss: 0.608577; batch adversarial loss: 0.449483\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466745; batch adversarial loss: 0.443703\n",
      "epoch 12; iter: 200; batch classifier loss: 0.404383; batch adversarial loss: 0.351085\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478641; batch adversarial loss: 0.407519\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396324; batch adversarial loss: 0.327830\n",
      "epoch 14; iter: 0; batch classifier loss: 0.417442; batch adversarial loss: 0.441315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 200; batch classifier loss: 0.404227; batch adversarial loss: 0.357855\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337917; batch adversarial loss: 0.358124\n",
      "epoch 15; iter: 200; batch classifier loss: 0.343510; batch adversarial loss: 0.429948\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403162; batch adversarial loss: 0.395869\n",
      "epoch 16; iter: 200; batch classifier loss: 0.295047; batch adversarial loss: 0.431674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300823; batch adversarial loss: 0.463852\n",
      "epoch 17; iter: 200; batch classifier loss: 0.318214; batch adversarial loss: 0.463803\n",
      "epoch 18; iter: 0; batch classifier loss: 0.433690; batch adversarial loss: 0.549926\n",
      "epoch 18; iter: 200; batch classifier loss: 0.386634; batch adversarial loss: 0.373046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.432376; batch adversarial loss: 0.363126\n",
      "epoch 19; iter: 200; batch classifier loss: 0.425353; batch adversarial loss: 0.395887\n",
      "epoch 20; iter: 0; batch classifier loss: 0.403884; batch adversarial loss: 0.455575\n",
      "epoch 20; iter: 200; batch classifier loss: 0.414055; batch adversarial loss: 0.354355\n",
      "epoch 21; iter: 0; batch classifier loss: 0.373896; batch adversarial loss: 0.334610\n",
      "epoch 21; iter: 200; batch classifier loss: 0.420007; batch adversarial loss: 0.386963\n",
      "epoch 22; iter: 0; batch classifier loss: 0.326496; batch adversarial loss: 0.366527\n",
      "epoch 22; iter: 200; batch classifier loss: 0.276224; batch adversarial loss: 0.376884\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457057; batch adversarial loss: 0.417649\n",
      "epoch 23; iter: 200; batch classifier loss: 0.291737; batch adversarial loss: 0.358200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.384661; batch adversarial loss: 0.405226\n",
      "epoch 24; iter: 200; batch classifier loss: 0.334308; batch adversarial loss: 0.365994\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457363; batch adversarial loss: 0.359856\n",
      "epoch 25; iter: 200; batch classifier loss: 0.350372; batch adversarial loss: 0.376787\n",
      "epoch 26; iter: 0; batch classifier loss: 0.310028; batch adversarial loss: 0.414751\n",
      "epoch 26; iter: 200; batch classifier loss: 0.337764; batch adversarial loss: 0.472733\n",
      "epoch 27; iter: 0; batch classifier loss: 0.369643; batch adversarial loss: 0.419726\n",
      "epoch 27; iter: 200; batch classifier loss: 0.325279; batch adversarial loss: 0.450559\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414249; batch adversarial loss: 0.414632\n",
      "epoch 28; iter: 200; batch classifier loss: 0.418992; batch adversarial loss: 0.392599\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338342; batch adversarial loss: 0.378292\n",
      "epoch 29; iter: 200; batch classifier loss: 0.369693; batch adversarial loss: 0.352593\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394262; batch adversarial loss: 0.343523\n",
      "epoch 30; iter: 200; batch classifier loss: 0.356750; batch adversarial loss: 0.424475\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276810; batch adversarial loss: 0.467909\n",
      "epoch 31; iter: 200; batch classifier loss: 0.436011; batch adversarial loss: 0.380100\n",
      "epoch 32; iter: 0; batch classifier loss: 0.357017; batch adversarial loss: 0.404703\n",
      "epoch 32; iter: 200; batch classifier loss: 0.287272; batch adversarial loss: 0.453918\n",
      "epoch 33; iter: 0; batch classifier loss: 0.327074; batch adversarial loss: 0.382894\n",
      "epoch 33; iter: 200; batch classifier loss: 0.346434; batch adversarial loss: 0.476394\n",
      "epoch 34; iter: 0; batch classifier loss: 0.354848; batch adversarial loss: 0.398563\n",
      "epoch 34; iter: 200; batch classifier loss: 0.334205; batch adversarial loss: 0.335754\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395956; batch adversarial loss: 0.551543\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347175; batch adversarial loss: 0.358078\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424048; batch adversarial loss: 0.374093\n",
      "epoch 36; iter: 200; batch classifier loss: 0.348828; batch adversarial loss: 0.420993\n",
      "epoch 37; iter: 0; batch classifier loss: 0.368013; batch adversarial loss: 0.453644\n",
      "epoch 37; iter: 200; batch classifier loss: 0.271081; batch adversarial loss: 0.492078\n",
      "epoch 38; iter: 0; batch classifier loss: 0.322667; batch adversarial loss: 0.377411\n",
      "epoch 38; iter: 200; batch classifier loss: 0.275275; batch adversarial loss: 0.381723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419658; batch adversarial loss: 0.319200\n",
      "epoch 39; iter: 200; batch classifier loss: 0.424616; batch adversarial loss: 0.347531\n",
      "epoch 40; iter: 0; batch classifier loss: 0.340483; batch adversarial loss: 0.359369\n",
      "epoch 40; iter: 200; batch classifier loss: 0.424503; batch adversarial loss: 0.469125\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411730; batch adversarial loss: 0.332188\n",
      "epoch 41; iter: 200; batch classifier loss: 0.267425; batch adversarial loss: 0.360078\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380423; batch adversarial loss: 0.406003\n",
      "epoch 42; iter: 200; batch classifier loss: 0.397204; batch adversarial loss: 0.440581\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328215; batch adversarial loss: 0.446117\n",
      "epoch 43; iter: 200; batch classifier loss: 0.281429; batch adversarial loss: 0.472174\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263421; batch adversarial loss: 0.405742\n",
      "epoch 44; iter: 200; batch classifier loss: 0.211017; batch adversarial loss: 0.411344\n",
      "epoch 45; iter: 0; batch classifier loss: 0.325631; batch adversarial loss: 0.338102\n",
      "epoch 45; iter: 200; batch classifier loss: 0.398542; batch adversarial loss: 0.353208\n",
      "epoch 46; iter: 0; batch classifier loss: 0.284699; batch adversarial loss: 0.377299\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386859; batch adversarial loss: 0.364684\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341318; batch adversarial loss: 0.328954\n",
      "epoch 47; iter: 200; batch classifier loss: 0.317802; batch adversarial loss: 0.455591\n",
      "epoch 48; iter: 0; batch classifier loss: 0.362107; batch adversarial loss: 0.418488\n",
      "epoch 48; iter: 200; batch classifier loss: 0.412774; batch adversarial loss: 0.451681\n",
      "epoch 49; iter: 0; batch classifier loss: 0.305064; batch adversarial loss: 0.391028\n",
      "epoch 49; iter: 200; batch classifier loss: 0.390971; batch adversarial loss: 0.332356\n",
      "epoch 0; iter: 0; batch classifier loss: 42.494766; batch adversarial loss: 0.470191\n",
      "epoch 0; iter: 200; batch classifier loss: 2.382740; batch adversarial loss: 0.589233\n",
      "epoch 1; iter: 0; batch classifier loss: 3.229476; batch adversarial loss: 0.602842\n",
      "epoch 1; iter: 200; batch classifier loss: 3.332904; batch adversarial loss: 0.514400\n",
      "epoch 2; iter: 0; batch classifier loss: 6.280893; batch adversarial loss: 0.433515\n",
      "epoch 2; iter: 200; batch classifier loss: 14.894532; batch adversarial loss: 0.468321\n",
      "epoch 3; iter: 0; batch classifier loss: 1.131031; batch adversarial loss: 0.413605\n",
      "epoch 3; iter: 200; batch classifier loss: 1.822114; batch adversarial loss: 0.459915\n",
      "epoch 4; iter: 0; batch classifier loss: 2.742624; batch adversarial loss: 0.401176\n",
      "epoch 4; iter: 200; batch classifier loss: 0.900253; batch adversarial loss: 0.452662\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460251; batch adversarial loss: 0.460676\n",
      "epoch 5; iter: 200; batch classifier loss: 0.846448; batch adversarial loss: 0.461855\n",
      "epoch 6; iter: 0; batch classifier loss: 0.398007; batch adversarial loss: 0.419461\n",
      "epoch 6; iter: 200; batch classifier loss: 0.450708; batch adversarial loss: 0.418787\n",
      "epoch 7; iter: 0; batch classifier loss: 0.919395; batch adversarial loss: 0.389809\n",
      "epoch 7; iter: 200; batch classifier loss: 0.826101; batch adversarial loss: 0.474918\n",
      "epoch 8; iter: 0; batch classifier loss: 1.375147; batch adversarial loss: 0.368940\n",
      "epoch 8; iter: 200; batch classifier loss: 0.455389; batch adversarial loss: 0.378398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379456; batch adversarial loss: 0.404105\n",
      "epoch 9; iter: 200; batch classifier loss: 1.319043; batch adversarial loss: 0.439734\n",
      "epoch 10; iter: 0; batch classifier loss: 0.410190; batch adversarial loss: 0.471792\n",
      "epoch 10; iter: 200; batch classifier loss: 0.669193; batch adversarial loss: 0.388337\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326184; batch adversarial loss: 0.403030\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412583; batch adversarial loss: 0.362441\n",
      "epoch 12; iter: 0; batch classifier loss: 0.409677; batch adversarial loss: 0.364221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 200; batch classifier loss: 0.414487; batch adversarial loss: 0.380285\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305574; batch adversarial loss: 0.385314\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440313; batch adversarial loss: 0.391143\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409540; batch adversarial loss: 0.387303\n",
      "epoch 14; iter: 200; batch classifier loss: 0.301175; batch adversarial loss: 0.396913\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345091; batch adversarial loss: 0.493888\n",
      "epoch 15; iter: 200; batch classifier loss: 0.336915; batch adversarial loss: 0.431500\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349520; batch adversarial loss: 0.292399\n",
      "epoch 16; iter: 200; batch classifier loss: 0.391407; batch adversarial loss: 0.456809\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459891; batch adversarial loss: 0.425709\n",
      "epoch 17; iter: 200; batch classifier loss: 0.361005; batch adversarial loss: 0.304301\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550820; batch adversarial loss: 0.502868\n",
      "epoch 18; iter: 200; batch classifier loss: 0.427054; batch adversarial loss: 0.408698\n",
      "epoch 19; iter: 0; batch classifier loss: 0.371410; batch adversarial loss: 0.440268\n",
      "epoch 19; iter: 200; batch classifier loss: 0.442093; batch adversarial loss: 0.431583\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327753; batch adversarial loss: 0.379483\n",
      "epoch 20; iter: 200; batch classifier loss: 0.315109; batch adversarial loss: 0.326511\n",
      "epoch 21; iter: 0; batch classifier loss: 0.277221; batch adversarial loss: 0.462330\n",
      "epoch 21; iter: 200; batch classifier loss: 0.293712; batch adversarial loss: 0.376664\n",
      "epoch 22; iter: 0; batch classifier loss: 0.306807; batch adversarial loss: 0.465480\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351421; batch adversarial loss: 0.406720\n",
      "epoch 23; iter: 0; batch classifier loss: 0.371960; batch adversarial loss: 0.488141\n",
      "epoch 23; iter: 200; batch classifier loss: 0.395264; batch adversarial loss: 0.411119\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302776; batch adversarial loss: 0.420726\n",
      "epoch 24; iter: 200; batch classifier loss: 0.366208; batch adversarial loss: 0.427501\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288254; batch adversarial loss: 0.475030\n",
      "epoch 25; iter: 200; batch classifier loss: 0.393291; batch adversarial loss: 0.363600\n",
      "epoch 26; iter: 0; batch classifier loss: 0.385307; batch adversarial loss: 0.349273\n",
      "epoch 26; iter: 200; batch classifier loss: 0.350063; batch adversarial loss: 0.412486\n",
      "epoch 27; iter: 0; batch classifier loss: 0.261619; batch adversarial loss: 0.401289\n",
      "epoch 27; iter: 200; batch classifier loss: 0.292363; batch adversarial loss: 0.443723\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345997; batch adversarial loss: 0.435834\n",
      "epoch 28; iter: 200; batch classifier loss: 0.297942; batch adversarial loss: 0.432052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322610; batch adversarial loss: 0.362499\n",
      "epoch 29; iter: 200; batch classifier loss: 0.387465; batch adversarial loss: 0.408958\n",
      "epoch 30; iter: 0; batch classifier loss: 0.302395; batch adversarial loss: 0.391555\n",
      "epoch 30; iter: 200; batch classifier loss: 0.288407; batch adversarial loss: 0.477372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352382; batch adversarial loss: 0.335184\n",
      "epoch 31; iter: 200; batch classifier loss: 0.291192; batch adversarial loss: 0.444442\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457600; batch adversarial loss: 0.359528\n",
      "epoch 32; iter: 200; batch classifier loss: 0.277199; batch adversarial loss: 0.447998\n",
      "epoch 33; iter: 0; batch classifier loss: 0.371207; batch adversarial loss: 0.351679\n",
      "epoch 33; iter: 200; batch classifier loss: 0.299760; batch adversarial loss: 0.432485\n",
      "epoch 34; iter: 0; batch classifier loss: 0.606483; batch adversarial loss: 0.343117\n",
      "epoch 34; iter: 200; batch classifier loss: 0.302943; batch adversarial loss: 0.320720\n",
      "epoch 35; iter: 0; batch classifier loss: 0.292667; batch adversarial loss: 0.385612\n",
      "epoch 35; iter: 200; batch classifier loss: 0.327770; batch adversarial loss: 0.400654\n",
      "epoch 36; iter: 0; batch classifier loss: 0.298445; batch adversarial loss: 0.370357\n",
      "epoch 36; iter: 200; batch classifier loss: 0.249429; batch adversarial loss: 0.441989\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378526; batch adversarial loss: 0.421488\n",
      "epoch 37; iter: 200; batch classifier loss: 0.301797; batch adversarial loss: 0.421842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342593; batch adversarial loss: 0.361890\n",
      "epoch 38; iter: 200; batch classifier loss: 0.335061; batch adversarial loss: 0.263163\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243987; batch adversarial loss: 0.412497\n",
      "epoch 39; iter: 200; batch classifier loss: 0.299017; batch adversarial loss: 0.428406\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409742; batch adversarial loss: 0.456515\n",
      "epoch 40; iter: 200; batch classifier loss: 0.295220; batch adversarial loss: 0.366130\n",
      "epoch 41; iter: 0; batch classifier loss: 0.302742; batch adversarial loss: 0.337481\n",
      "epoch 41; iter: 200; batch classifier loss: 0.272286; batch adversarial loss: 0.382671\n",
      "epoch 42; iter: 0; batch classifier loss: 0.327027; batch adversarial loss: 0.384977\n",
      "epoch 42; iter: 200; batch classifier loss: 0.292231; batch adversarial loss: 0.401565\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406614; batch adversarial loss: 0.447812\n",
      "epoch 43; iter: 200; batch classifier loss: 0.272019; batch adversarial loss: 0.435035\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321730; batch adversarial loss: 0.415032\n",
      "epoch 44; iter: 200; batch classifier loss: 0.267779; batch adversarial loss: 0.461800\n",
      "epoch 45; iter: 0; batch classifier loss: 0.334940; batch adversarial loss: 0.365465\n",
      "epoch 45; iter: 200; batch classifier loss: 0.228154; batch adversarial loss: 0.394231\n",
      "epoch 46; iter: 0; batch classifier loss: 0.319064; batch adversarial loss: 0.422332\n",
      "epoch 46; iter: 200; batch classifier loss: 0.275381; batch adversarial loss: 0.419675\n",
      "epoch 47; iter: 0; batch classifier loss: 0.351767; batch adversarial loss: 0.414993\n",
      "epoch 47; iter: 200; batch classifier loss: 0.400295; batch adversarial loss: 0.424825\n",
      "epoch 48; iter: 0; batch classifier loss: 0.362439; batch adversarial loss: 0.278567\n",
      "epoch 48; iter: 200; batch classifier loss: 0.246567; batch adversarial loss: 0.449776\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391032; batch adversarial loss: 0.433090\n",
      "epoch 49; iter: 200; batch classifier loss: 0.381345; batch adversarial loss: 0.514514\n",
      "epoch 0; iter: 0; batch classifier loss: 17.943745; batch adversarial loss: 0.813197\n",
      "epoch 0; iter: 200; batch classifier loss: 7.824130; batch adversarial loss: 0.641995\n",
      "epoch 1; iter: 0; batch classifier loss: 3.307671; batch adversarial loss: 0.623907\n",
      "epoch 1; iter: 200; batch classifier loss: 7.491189; batch adversarial loss: 0.551682\n",
      "epoch 2; iter: 0; batch classifier loss: 1.313415; batch adversarial loss: 0.573287\n",
      "epoch 2; iter: 200; batch classifier loss: 1.574328; batch adversarial loss: 0.528324\n",
      "epoch 3; iter: 0; batch classifier loss: 18.242680; batch adversarial loss: 0.490694\n",
      "epoch 3; iter: 200; batch classifier loss: 2.458685; batch adversarial loss: 0.426969\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469293; batch adversarial loss: 0.446440\n",
      "epoch 4; iter: 200; batch classifier loss: 3.020398; batch adversarial loss: 0.429193\n",
      "epoch 5; iter: 0; batch classifier loss: 0.852023; batch adversarial loss: 0.433918\n",
      "epoch 5; iter: 200; batch classifier loss: 0.989981; batch adversarial loss: 0.410924\n",
      "epoch 6; iter: 0; batch classifier loss: 1.463851; batch adversarial loss: 0.460128\n",
      "epoch 6; iter: 200; batch classifier loss: 0.811765; batch adversarial loss: 0.500290\n",
      "epoch 7; iter: 0; batch classifier loss: 0.896404; batch adversarial loss: 0.420099\n",
      "epoch 7; iter: 200; batch classifier loss: 0.696615; batch adversarial loss: 0.389005\n",
      "epoch 8; iter: 0; batch classifier loss: 2.254717; batch adversarial loss: 0.390016\n",
      "epoch 8; iter: 200; batch classifier loss: 0.726783; batch adversarial loss: 0.405118\n",
      "epoch 9; iter: 0; batch classifier loss: 0.626120; batch adversarial loss: 0.398680\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320208; batch adversarial loss: 0.407898\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517418; batch adversarial loss: 0.405485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 200; batch classifier loss: 0.480698; batch adversarial loss: 0.471197\n",
      "epoch 11; iter: 0; batch classifier loss: 0.365031; batch adversarial loss: 0.411499\n",
      "epoch 11; iter: 200; batch classifier loss: 0.350276; batch adversarial loss: 0.398122\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418294; batch adversarial loss: 0.359156\n",
      "epoch 12; iter: 200; batch classifier loss: 0.354294; batch adversarial loss: 0.456483\n",
      "epoch 13; iter: 0; batch classifier loss: 0.424236; batch adversarial loss: 0.459486\n",
      "epoch 13; iter: 200; batch classifier loss: 0.439383; batch adversarial loss: 0.576903\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393438; batch adversarial loss: 0.504667\n",
      "epoch 14; iter: 200; batch classifier loss: 0.694845; batch adversarial loss: 0.398135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373941; batch adversarial loss: 0.344724\n",
      "epoch 15; iter: 200; batch classifier loss: 0.402266; batch adversarial loss: 0.514799\n",
      "epoch 16; iter: 0; batch classifier loss: 0.375403; batch adversarial loss: 0.459539\n",
      "epoch 16; iter: 200; batch classifier loss: 0.446927; batch adversarial loss: 0.411128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.613232; batch adversarial loss: 0.458095\n",
      "epoch 17; iter: 200; batch classifier loss: 0.415440; batch adversarial loss: 0.412934\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385810; batch adversarial loss: 0.317634\n",
      "epoch 18; iter: 200; batch classifier loss: 0.413234; batch adversarial loss: 0.373810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400565; batch adversarial loss: 0.459972\n",
      "epoch 19; iter: 200; batch classifier loss: 0.296813; batch adversarial loss: 0.400446\n",
      "epoch 20; iter: 0; batch classifier loss: 0.410003; batch adversarial loss: 0.368963\n",
      "epoch 20; iter: 200; batch classifier loss: 0.377553; batch adversarial loss: 0.414796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.325270; batch adversarial loss: 0.426956\n",
      "epoch 21; iter: 200; batch classifier loss: 0.437502; batch adversarial loss: 0.352621\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447554; batch adversarial loss: 0.399346\n",
      "epoch 22; iter: 200; batch classifier loss: 0.302837; batch adversarial loss: 0.504420\n",
      "epoch 23; iter: 0; batch classifier loss: 0.390628; batch adversarial loss: 0.385285\n",
      "epoch 23; iter: 200; batch classifier loss: 0.414125; batch adversarial loss: 0.389905\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422291; batch adversarial loss: 0.344090\n",
      "epoch 24; iter: 200; batch classifier loss: 0.366782; batch adversarial loss: 0.408184\n",
      "epoch 25; iter: 0; batch classifier loss: 0.383010; batch adversarial loss: 0.431434\n",
      "epoch 25; iter: 200; batch classifier loss: 0.399262; batch adversarial loss: 0.422977\n",
      "epoch 26; iter: 0; batch classifier loss: 0.358988; batch adversarial loss: 0.340974\n",
      "epoch 26; iter: 200; batch classifier loss: 0.309958; batch adversarial loss: 0.459935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.406921; batch adversarial loss: 0.442020\n",
      "epoch 27; iter: 200; batch classifier loss: 0.416186; batch adversarial loss: 0.450746\n",
      "epoch 28; iter: 0; batch classifier loss: 0.296799; batch adversarial loss: 0.415628\n",
      "epoch 28; iter: 200; batch classifier loss: 0.327934; batch adversarial loss: 0.509783\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376319; batch adversarial loss: 0.389947\n",
      "epoch 29; iter: 200; batch classifier loss: 0.329941; batch adversarial loss: 0.420286\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272405; batch adversarial loss: 0.436460\n",
      "epoch 30; iter: 200; batch classifier loss: 0.285765; batch adversarial loss: 0.437620\n",
      "epoch 31; iter: 0; batch classifier loss: 0.305146; batch adversarial loss: 0.502218\n",
      "epoch 31; iter: 200; batch classifier loss: 0.356554; batch adversarial loss: 0.370771\n",
      "epoch 32; iter: 0; batch classifier loss: 0.336296; batch adversarial loss: 0.308410\n",
      "epoch 32; iter: 200; batch classifier loss: 0.383047; batch adversarial loss: 0.446452\n",
      "epoch 33; iter: 0; batch classifier loss: 0.329238; batch adversarial loss: 0.428851\n",
      "epoch 33; iter: 200; batch classifier loss: 0.336031; batch adversarial loss: 0.378221\n",
      "epoch 34; iter: 0; batch classifier loss: 0.322196; batch adversarial loss: 0.430075\n",
      "epoch 34; iter: 200; batch classifier loss: 0.371540; batch adversarial loss: 0.374895\n",
      "epoch 35; iter: 0; batch classifier loss: 0.342744; batch adversarial loss: 0.505750\n",
      "epoch 35; iter: 200; batch classifier loss: 0.297156; batch adversarial loss: 0.418939\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268907; batch adversarial loss: 0.433028\n",
      "epoch 36; iter: 200; batch classifier loss: 0.283401; batch adversarial loss: 0.393329\n",
      "epoch 37; iter: 0; batch classifier loss: 0.342888; batch adversarial loss: 0.449471\n",
      "epoch 37; iter: 200; batch classifier loss: 0.330303; batch adversarial loss: 0.456178\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288565; batch adversarial loss: 0.381343\n",
      "epoch 38; iter: 200; batch classifier loss: 0.347906; batch adversarial loss: 0.270438\n",
      "epoch 39; iter: 0; batch classifier loss: 0.277602; batch adversarial loss: 0.370744\n",
      "epoch 39; iter: 200; batch classifier loss: 0.344942; batch adversarial loss: 0.340047\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350263; batch adversarial loss: 0.409898\n",
      "epoch 40; iter: 200; batch classifier loss: 0.435063; batch adversarial loss: 0.404287\n",
      "epoch 41; iter: 0; batch classifier loss: 0.308211; batch adversarial loss: 0.368023\n",
      "epoch 41; iter: 200; batch classifier loss: 0.337041; batch adversarial loss: 0.363720\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445823; batch adversarial loss: 0.475566\n",
      "epoch 42; iter: 200; batch classifier loss: 0.378335; batch adversarial loss: 0.451053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362737; batch adversarial loss: 0.436460\n",
      "epoch 43; iter: 200; batch classifier loss: 0.457668; batch adversarial loss: 0.429186\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372754; batch adversarial loss: 0.459485\n",
      "epoch 44; iter: 200; batch classifier loss: 0.314938; batch adversarial loss: 0.519707\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389774; batch adversarial loss: 0.486928\n",
      "epoch 45; iter: 200; batch classifier loss: 0.306486; batch adversarial loss: 0.454532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.272000; batch adversarial loss: 0.414020\n",
      "epoch 46; iter: 200; batch classifier loss: 0.292078; batch adversarial loss: 0.421282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.279190; batch adversarial loss: 0.380364\n",
      "epoch 47; iter: 200; batch classifier loss: 0.635452; batch adversarial loss: 0.371333\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413100; batch adversarial loss: 0.432016\n",
      "epoch 48; iter: 200; batch classifier loss: 0.326187; batch adversarial loss: 0.322917\n",
      "epoch 49; iter: 0; batch classifier loss: 0.274663; batch adversarial loss: 0.457336\n",
      "epoch 49; iter: 200; batch classifier loss: 0.389724; batch adversarial loss: 0.291308\n",
      "epoch 0; iter: 0; batch classifier loss: 14.626712; batch adversarial loss: 0.742753\n",
      "epoch 0; iter: 200; batch classifier loss: 13.537501; batch adversarial loss: 0.669036\n",
      "epoch 1; iter: 0; batch classifier loss: 3.374038; batch adversarial loss: 0.641887\n",
      "epoch 1; iter: 200; batch classifier loss: 10.375280; batch adversarial loss: 0.607526\n",
      "epoch 2; iter: 0; batch classifier loss: 6.076689; batch adversarial loss: 0.582045\n",
      "epoch 2; iter: 200; batch classifier loss: 2.224067; batch adversarial loss: 0.532103\n",
      "epoch 3; iter: 0; batch classifier loss: 6.166950; batch adversarial loss: 0.501906\n",
      "epoch 3; iter: 200; batch classifier loss: 2.058147; batch adversarial loss: 0.483043\n",
      "epoch 4; iter: 0; batch classifier loss: 3.516050; batch adversarial loss: 0.464573\n",
      "epoch 4; iter: 200; batch classifier loss: 1.664115; batch adversarial loss: 0.460180\n",
      "epoch 5; iter: 0; batch classifier loss: 3.134701; batch adversarial loss: 0.457478\n",
      "epoch 5; iter: 200; batch classifier loss: 2.212217; batch adversarial loss: 0.397378\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558694; batch adversarial loss: 0.440805\n",
      "epoch 6; iter: 200; batch classifier loss: 0.627408; batch adversarial loss: 0.403742\n",
      "epoch 7; iter: 0; batch classifier loss: 0.722127; batch adversarial loss: 0.346141\n",
      "epoch 7; iter: 200; batch classifier loss: 0.381936; batch adversarial loss: 0.412267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.809992; batch adversarial loss: 0.450655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 200; batch classifier loss: 1.357438; batch adversarial loss: 0.346325\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570448; batch adversarial loss: 0.369236\n",
      "epoch 9; iter: 200; batch classifier loss: 0.862507; batch adversarial loss: 0.481436\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522778; batch adversarial loss: 0.420725\n",
      "epoch 10; iter: 200; batch classifier loss: 0.373729; batch adversarial loss: 0.418379\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389506; batch adversarial loss: 0.309244\n",
      "epoch 11; iter: 200; batch classifier loss: 0.405325; batch adversarial loss: 0.457257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.409589; batch adversarial loss: 0.340899\n",
      "epoch 12; iter: 200; batch classifier loss: 0.357773; batch adversarial loss: 0.457539\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304432; batch adversarial loss: 0.463023\n",
      "epoch 13; iter: 200; batch classifier loss: 0.730419; batch adversarial loss: 0.442870\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431094; batch adversarial loss: 0.419645\n",
      "epoch 14; iter: 200; batch classifier loss: 0.309169; batch adversarial loss: 0.377065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422172; batch adversarial loss: 0.404495\n",
      "epoch 15; iter: 200; batch classifier loss: 0.325056; batch adversarial loss: 0.329962\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482576; batch adversarial loss: 0.309991\n",
      "epoch 16; iter: 200; batch classifier loss: 0.591427; batch adversarial loss: 0.448463\n",
      "epoch 17; iter: 0; batch classifier loss: 0.584490; batch adversarial loss: 0.381517\n",
      "epoch 17; iter: 200; batch classifier loss: 0.502008; batch adversarial loss: 0.377152\n",
      "epoch 18; iter: 0; batch classifier loss: 0.427457; batch adversarial loss: 0.402674\n",
      "epoch 18; iter: 200; batch classifier loss: 0.632610; batch adversarial loss: 0.456908\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514369; batch adversarial loss: 0.319434\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376113; batch adversarial loss: 0.422128\n",
      "epoch 20; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.326013\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379312; batch adversarial loss: 0.533895\n",
      "epoch 21; iter: 0; batch classifier loss: 0.348376; batch adversarial loss: 0.369835\n",
      "epoch 21; iter: 200; batch classifier loss: 0.323650; batch adversarial loss: 0.417095\n",
      "epoch 22; iter: 0; batch classifier loss: 0.534691; batch adversarial loss: 0.361776\n",
      "epoch 22; iter: 200; batch classifier loss: 0.436195; batch adversarial loss: 0.433408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486123; batch adversarial loss: 0.421822\n",
      "epoch 23; iter: 200; batch classifier loss: 0.357484; batch adversarial loss: 0.379377\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302855; batch adversarial loss: 0.470573\n",
      "epoch 24; iter: 200; batch classifier loss: 0.323094; batch adversarial loss: 0.377270\n",
      "epoch 25; iter: 0; batch classifier loss: 0.296282; batch adversarial loss: 0.432605\n",
      "epoch 25; iter: 200; batch classifier loss: 0.443891; batch adversarial loss: 0.293323\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259386; batch adversarial loss: 0.390028\n",
      "epoch 26; iter: 200; batch classifier loss: 0.384403; batch adversarial loss: 0.469926\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325855; batch adversarial loss: 0.321670\n",
      "epoch 27; iter: 200; batch classifier loss: 0.339704; batch adversarial loss: 0.431252\n",
      "epoch 28; iter: 0; batch classifier loss: 0.288507; batch adversarial loss: 0.510201\n",
      "epoch 28; iter: 200; batch classifier loss: 0.317173; batch adversarial loss: 0.601746\n",
      "epoch 29; iter: 0; batch classifier loss: 0.282409; batch adversarial loss: 0.527283\n",
      "epoch 29; iter: 200; batch classifier loss: 0.327999; batch adversarial loss: 0.375067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.367737; batch adversarial loss: 0.377239\n",
      "epoch 30; iter: 200; batch classifier loss: 0.278114; batch adversarial loss: 0.356846\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398894; batch adversarial loss: 0.308543\n",
      "epoch 31; iter: 200; batch classifier loss: 0.369735; batch adversarial loss: 0.441972\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291549; batch adversarial loss: 0.370606\n",
      "epoch 32; iter: 200; batch classifier loss: 0.339861; batch adversarial loss: 0.385072\n",
      "epoch 33; iter: 0; batch classifier loss: 0.341927; batch adversarial loss: 0.321335\n",
      "epoch 33; iter: 200; batch classifier loss: 0.310894; batch adversarial loss: 0.270845\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363442; batch adversarial loss: 0.294548\n",
      "epoch 34; iter: 200; batch classifier loss: 0.364244; batch adversarial loss: 0.344363\n",
      "epoch 35; iter: 0; batch classifier loss: 0.281569; batch adversarial loss: 0.398541\n",
      "epoch 35; iter: 200; batch classifier loss: 0.322982; batch adversarial loss: 0.412364\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365690; batch adversarial loss: 0.333130\n",
      "epoch 36; iter: 200; batch classifier loss: 0.281503; batch adversarial loss: 0.359831\n",
      "epoch 37; iter: 0; batch classifier loss: 0.305072; batch adversarial loss: 0.559434\n",
      "epoch 37; iter: 200; batch classifier loss: 0.384955; batch adversarial loss: 0.384403\n",
      "epoch 38; iter: 0; batch classifier loss: 0.364318; batch adversarial loss: 0.404921\n",
      "epoch 38; iter: 200; batch classifier loss: 0.314216; batch adversarial loss: 0.431583\n",
      "epoch 39; iter: 0; batch classifier loss: 0.254290; batch adversarial loss: 0.450589\n",
      "epoch 39; iter: 200; batch classifier loss: 0.444372; batch adversarial loss: 0.399228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.290072; batch adversarial loss: 0.395996\n",
      "epoch 40; iter: 200; batch classifier loss: 0.363650; batch adversarial loss: 0.377637\n",
      "epoch 41; iter: 0; batch classifier loss: 0.399090; batch adversarial loss: 0.424632\n",
      "epoch 41; iter: 200; batch classifier loss: 0.336973; batch adversarial loss: 0.396365\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403237; batch adversarial loss: 0.348457\n",
      "epoch 42; iter: 200; batch classifier loss: 0.363686; batch adversarial loss: 0.399046\n",
      "epoch 43; iter: 0; batch classifier loss: 0.313523; batch adversarial loss: 0.370286\n",
      "epoch 43; iter: 200; batch classifier loss: 0.369829; batch adversarial loss: 0.407929\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391321; batch adversarial loss: 0.371180\n",
      "epoch 44; iter: 200; batch classifier loss: 0.317941; batch adversarial loss: 0.477437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.349887; batch adversarial loss: 0.376518\n",
      "epoch 45; iter: 200; batch classifier loss: 0.332120; batch adversarial loss: 0.332822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349567; batch adversarial loss: 0.388803\n",
      "epoch 46; iter: 200; batch classifier loss: 0.312836; batch adversarial loss: 0.436990\n",
      "epoch 47; iter: 0; batch classifier loss: 0.351082; batch adversarial loss: 0.386156\n",
      "epoch 47; iter: 200; batch classifier loss: 0.303017; batch adversarial loss: 0.425670\n",
      "epoch 48; iter: 0; batch classifier loss: 0.343257; batch adversarial loss: 0.409538\n",
      "epoch 48; iter: 200; batch classifier loss: 0.341793; batch adversarial loss: 0.411179\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400219; batch adversarial loss: 0.341999\n",
      "epoch 49; iter: 200; batch classifier loss: 0.371986; batch adversarial loss: 0.434376\n",
      "epoch 0; iter: 0; batch classifier loss: 34.444729; batch adversarial loss: 0.775325\n",
      "epoch 0; iter: 200; batch classifier loss: 4.318632; batch adversarial loss: 0.651665\n",
      "epoch 1; iter: 0; batch classifier loss: 9.302186; batch adversarial loss: 0.613344\n",
      "epoch 1; iter: 200; batch classifier loss: 3.026622; batch adversarial loss: 0.548952\n",
      "epoch 2; iter: 0; batch classifier loss: 7.660951; batch adversarial loss: 0.556071\n",
      "epoch 2; iter: 200; batch classifier loss: 10.702326; batch adversarial loss: 0.507300\n",
      "epoch 3; iter: 0; batch classifier loss: 2.039829; batch adversarial loss: 0.509509\n",
      "epoch 3; iter: 200; batch classifier loss: 1.059386; batch adversarial loss: 0.457492\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529053; batch adversarial loss: 0.470046\n",
      "epoch 4; iter: 200; batch classifier loss: 13.700108; batch adversarial loss: 0.500617\n",
      "epoch 5; iter: 0; batch classifier loss: 0.676457; batch adversarial loss: 0.459989\n",
      "epoch 5; iter: 200; batch classifier loss: 2.642422; batch adversarial loss: 0.422878\n",
      "epoch 6; iter: 0; batch classifier loss: 3.126692; batch adversarial loss: 0.479555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 200; batch classifier loss: 1.189098; batch adversarial loss: 0.360471\n",
      "epoch 7; iter: 0; batch classifier loss: 1.941715; batch adversarial loss: 0.528179\n",
      "epoch 7; iter: 200; batch classifier loss: 1.911253; batch adversarial loss: 0.395282\n",
      "epoch 8; iter: 0; batch classifier loss: 1.268459; batch adversarial loss: 0.380777\n",
      "epoch 8; iter: 200; batch classifier loss: 0.771042; batch adversarial loss: 0.420907\n",
      "epoch 9; iter: 0; batch classifier loss: 1.041976; batch adversarial loss: 0.427602\n",
      "epoch 9; iter: 200; batch classifier loss: 0.813012; batch adversarial loss: 0.364965\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474564; batch adversarial loss: 0.434667\n",
      "epoch 10; iter: 200; batch classifier loss: 0.531462; batch adversarial loss: 0.348332\n",
      "epoch 11; iter: 0; batch classifier loss: 0.644241; batch adversarial loss: 0.496772\n",
      "epoch 11; iter: 200; batch classifier loss: 2.794575; batch adversarial loss: 0.447497\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418283; batch adversarial loss: 0.420825\n",
      "epoch 12; iter: 200; batch classifier loss: 0.324437; batch adversarial loss: 0.427517\n",
      "epoch 13; iter: 0; batch classifier loss: 0.868183; batch adversarial loss: 0.347405\n",
      "epoch 13; iter: 200; batch classifier loss: 0.392886; batch adversarial loss: 0.464941\n",
      "epoch 14; iter: 0; batch classifier loss: 0.640738; batch adversarial loss: 0.382235\n",
      "epoch 14; iter: 200; batch classifier loss: 0.382902; batch adversarial loss: 0.433444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359590; batch adversarial loss: 0.398945\n",
      "epoch 15; iter: 200; batch classifier loss: 0.312402; batch adversarial loss: 0.380506\n",
      "epoch 16; iter: 0; batch classifier loss: 0.360565; batch adversarial loss: 0.326685\n",
      "epoch 16; iter: 200; batch classifier loss: 0.469750; batch adversarial loss: 0.416139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562134; batch adversarial loss: 0.441039\n",
      "epoch 17; iter: 200; batch classifier loss: 0.352327; batch adversarial loss: 0.484647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370559; batch adversarial loss: 0.386849\n",
      "epoch 18; iter: 200; batch classifier loss: 0.378477; batch adversarial loss: 0.409433\n",
      "epoch 19; iter: 0; batch classifier loss: 0.316019; batch adversarial loss: 0.450482\n",
      "epoch 19; iter: 200; batch classifier loss: 0.491117; batch adversarial loss: 0.357827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502779; batch adversarial loss: 0.392481\n",
      "epoch 20; iter: 200; batch classifier loss: 0.384477; batch adversarial loss: 0.445475\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369403; batch adversarial loss: 0.344630\n",
      "epoch 21; iter: 200; batch classifier loss: 0.641614; batch adversarial loss: 0.313453\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392557; batch adversarial loss: 0.391947\n",
      "epoch 22; iter: 200; batch classifier loss: 0.342275; batch adversarial loss: 0.343618\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488432; batch adversarial loss: 0.404746\n",
      "epoch 23; iter: 200; batch classifier loss: 0.418323; batch adversarial loss: 0.486774\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343854; batch adversarial loss: 0.492410\n",
      "epoch 24; iter: 200; batch classifier loss: 0.366884; batch adversarial loss: 0.353561\n",
      "epoch 25; iter: 0; batch classifier loss: 0.340312; batch adversarial loss: 0.420086\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384735; batch adversarial loss: 0.343886\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334776; batch adversarial loss: 0.404675\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389849; batch adversarial loss: 0.453774\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427523; batch adversarial loss: 0.388846\n",
      "epoch 27; iter: 200; batch classifier loss: 0.314522; batch adversarial loss: 0.386779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.279122; batch adversarial loss: 0.421997\n",
      "epoch 28; iter: 200; batch classifier loss: 0.325524; batch adversarial loss: 0.473940\n",
      "epoch 29; iter: 0; batch classifier loss: 0.360971; batch adversarial loss: 0.384898\n",
      "epoch 29; iter: 200; batch classifier loss: 0.261702; batch adversarial loss: 0.481569\n",
      "epoch 30; iter: 0; batch classifier loss: 0.334415; batch adversarial loss: 0.395968\n",
      "epoch 30; iter: 200; batch classifier loss: 0.390823; batch adversarial loss: 0.466526\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390500; batch adversarial loss: 0.447328\n",
      "epoch 31; iter: 200; batch classifier loss: 0.388265; batch adversarial loss: 0.425471\n",
      "epoch 32; iter: 0; batch classifier loss: 0.301321; batch adversarial loss: 0.419434\n",
      "epoch 32; iter: 200; batch classifier loss: 0.447306; batch adversarial loss: 0.383208\n",
      "epoch 33; iter: 0; batch classifier loss: 0.341782; batch adversarial loss: 0.423961\n",
      "epoch 33; iter: 200; batch classifier loss: 0.388498; batch adversarial loss: 0.341442\n",
      "epoch 34; iter: 0; batch classifier loss: 0.359182; batch adversarial loss: 0.412121\n",
      "epoch 34; iter: 200; batch classifier loss: 0.321474; batch adversarial loss: 0.370111\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301289; batch adversarial loss: 0.366774\n",
      "epoch 35; iter: 200; batch classifier loss: 0.379657; batch adversarial loss: 0.479377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344293; batch adversarial loss: 0.437091\n",
      "epoch 36; iter: 200; batch classifier loss: 0.354470; batch adversarial loss: 0.375817\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346123; batch adversarial loss: 0.316446\n",
      "epoch 37; iter: 200; batch classifier loss: 0.331697; batch adversarial loss: 0.364472\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416653; batch adversarial loss: 0.428860\n",
      "epoch 38; iter: 200; batch classifier loss: 0.355816; batch adversarial loss: 0.384186\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328413; batch adversarial loss: 0.383897\n",
      "epoch 39; iter: 200; batch classifier loss: 0.380583; batch adversarial loss: 0.345633\n",
      "epoch 40; iter: 0; batch classifier loss: 0.317124; batch adversarial loss: 0.408987\n",
      "epoch 40; iter: 200; batch classifier loss: 0.228787; batch adversarial loss: 0.513606\n",
      "epoch 41; iter: 0; batch classifier loss: 0.263219; batch adversarial loss: 0.375109\n",
      "epoch 41; iter: 200; batch classifier loss: 0.408906; batch adversarial loss: 0.364882\n",
      "epoch 42; iter: 0; batch classifier loss: 0.338616; batch adversarial loss: 0.289510\n",
      "epoch 42; iter: 200; batch classifier loss: 0.214517; batch adversarial loss: 0.445788\n",
      "epoch 43; iter: 0; batch classifier loss: 0.257832; batch adversarial loss: 0.458446\n",
      "epoch 43; iter: 200; batch classifier loss: 0.366655; batch adversarial loss: 0.521610\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396258; batch adversarial loss: 0.419259\n",
      "epoch 44; iter: 200; batch classifier loss: 0.356189; batch adversarial loss: 0.328572\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371472; batch adversarial loss: 0.425745\n",
      "epoch 45; iter: 200; batch classifier loss: 0.310424; batch adversarial loss: 0.390540\n",
      "epoch 46; iter: 0; batch classifier loss: 0.289520; batch adversarial loss: 0.363430\n",
      "epoch 46; iter: 200; batch classifier loss: 0.405236; batch adversarial loss: 0.439529\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261857; batch adversarial loss: 0.403201\n",
      "epoch 47; iter: 200; batch classifier loss: 0.357241; batch adversarial loss: 0.398871\n",
      "epoch 48; iter: 0; batch classifier loss: 0.349098; batch adversarial loss: 0.441994\n",
      "epoch 48; iter: 200; batch classifier loss: 0.301666; batch adversarial loss: 0.415430\n",
      "epoch 49; iter: 0; batch classifier loss: 0.297202; batch adversarial loss: 0.409788\n",
      "epoch 49; iter: 200; batch classifier loss: 0.355139; batch adversarial loss: 0.403224\n",
      "epoch 0; iter: 0; batch classifier loss: 6.302079; batch adversarial loss: 0.495189\n",
      "epoch 0; iter: 200; batch classifier loss: 5.260241; batch adversarial loss: 0.558145\n",
      "epoch 1; iter: 0; batch classifier loss: 4.143225; batch adversarial loss: 0.477022\n",
      "epoch 1; iter: 200; batch classifier loss: 3.215956; batch adversarial loss: 0.499631\n",
      "epoch 2; iter: 0; batch classifier loss: 4.225435; batch adversarial loss: 0.533569\n",
      "epoch 2; iter: 200; batch classifier loss: 6.776390; batch adversarial loss: 0.504066\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581262; batch adversarial loss: 0.460106\n",
      "epoch 3; iter: 200; batch classifier loss: 0.565519; batch adversarial loss: 0.416371\n",
      "epoch 4; iter: 0; batch classifier loss: 3.078074; batch adversarial loss: 0.428797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 200; batch classifier loss: 0.670600; batch adversarial loss: 0.469174\n",
      "epoch 5; iter: 0; batch classifier loss: 0.923448; batch adversarial loss: 0.496715\n",
      "epoch 5; iter: 200; batch classifier loss: 0.415677; batch adversarial loss: 0.450612\n",
      "epoch 6; iter: 0; batch classifier loss: 2.494823; batch adversarial loss: 0.309492\n",
      "epoch 6; iter: 200; batch classifier loss: 0.533860; batch adversarial loss: 0.478045\n",
      "epoch 7; iter: 0; batch classifier loss: 0.787063; batch adversarial loss: 0.355022\n",
      "epoch 7; iter: 200; batch classifier loss: 0.807467; batch adversarial loss: 0.381915\n",
      "epoch 8; iter: 0; batch classifier loss: 0.891738; batch adversarial loss: 0.373431\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474663; batch adversarial loss: 0.457973\n",
      "epoch 9; iter: 0; batch classifier loss: 0.424917; batch adversarial loss: 0.371413\n",
      "epoch 9; iter: 200; batch classifier loss: 0.518040; batch adversarial loss: 0.446461\n",
      "epoch 10; iter: 0; batch classifier loss: 0.425538; batch adversarial loss: 0.381905\n",
      "epoch 10; iter: 200; batch classifier loss: 0.853861; batch adversarial loss: 0.420835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.453449; batch adversarial loss: 0.441333\n",
      "epoch 11; iter: 200; batch classifier loss: 0.407085; batch adversarial loss: 0.480624\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331364; batch adversarial loss: 0.463442\n",
      "epoch 12; iter: 200; batch classifier loss: 0.360941; batch adversarial loss: 0.434668\n",
      "epoch 13; iter: 0; batch classifier loss: 0.893164; batch adversarial loss: 0.357862\n",
      "epoch 13; iter: 200; batch classifier loss: 0.234859; batch adversarial loss: 0.334497\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408636; batch adversarial loss: 0.487267\n",
      "epoch 14; iter: 200; batch classifier loss: 0.567188; batch adversarial loss: 0.389307\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355984; batch adversarial loss: 0.437133\n",
      "epoch 15; iter: 200; batch classifier loss: 0.361990; batch adversarial loss: 0.509413\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256652; batch adversarial loss: 0.483968\n",
      "epoch 16; iter: 200; batch classifier loss: 0.424903; batch adversarial loss: 0.499906\n",
      "epoch 17; iter: 0; batch classifier loss: 0.408689; batch adversarial loss: 0.353946\n",
      "epoch 17; iter: 200; batch classifier loss: 0.314599; batch adversarial loss: 0.455973\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335388; batch adversarial loss: 0.417783\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326747; batch adversarial loss: 0.452531\n",
      "epoch 19; iter: 0; batch classifier loss: 0.384098; batch adversarial loss: 0.446440\n",
      "epoch 19; iter: 200; batch classifier loss: 0.330166; batch adversarial loss: 0.387787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328662; batch adversarial loss: 0.377010\n",
      "epoch 20; iter: 200; batch classifier loss: 0.401209; batch adversarial loss: 0.332614\n",
      "epoch 21; iter: 0; batch classifier loss: 0.273079; batch adversarial loss: 0.369635\n",
      "epoch 21; iter: 200; batch classifier loss: 0.296320; batch adversarial loss: 0.461598\n",
      "epoch 22; iter: 0; batch classifier loss: 0.387443; batch adversarial loss: 0.347439\n",
      "epoch 22; iter: 200; batch classifier loss: 0.406361; batch adversarial loss: 0.385692\n",
      "epoch 23; iter: 0; batch classifier loss: 0.387996; batch adversarial loss: 0.387941\n",
      "epoch 23; iter: 200; batch classifier loss: 0.331396; batch adversarial loss: 0.424879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326410; batch adversarial loss: 0.321350\n",
      "epoch 24; iter: 200; batch classifier loss: 0.354592; batch adversarial loss: 0.469764\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311615; batch adversarial loss: 0.409480\n",
      "epoch 25; iter: 200; batch classifier loss: 0.377414; batch adversarial loss: 0.444232\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319630; batch adversarial loss: 0.398564\n",
      "epoch 26; iter: 200; batch classifier loss: 0.396670; batch adversarial loss: 0.365752\n",
      "epoch 27; iter: 0; batch classifier loss: 0.400952; batch adversarial loss: 0.478264\n",
      "epoch 27; iter: 200; batch classifier loss: 0.313800; batch adversarial loss: 0.619965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391374; batch adversarial loss: 0.316508\n",
      "epoch 28; iter: 200; batch classifier loss: 0.305696; batch adversarial loss: 0.422652\n",
      "epoch 29; iter: 0; batch classifier loss: 0.408739; batch adversarial loss: 0.451536\n",
      "epoch 29; iter: 200; batch classifier loss: 0.302016; batch adversarial loss: 0.457447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.355226; batch adversarial loss: 0.410321\n",
      "epoch 30; iter: 200; batch classifier loss: 0.317649; batch adversarial loss: 0.389658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.280532; batch adversarial loss: 0.475228\n",
      "epoch 31; iter: 200; batch classifier loss: 0.359126; batch adversarial loss: 0.335601\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502062; batch adversarial loss: 0.438382\n",
      "epoch 32; iter: 200; batch classifier loss: 0.312100; batch adversarial loss: 0.303426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.309307; batch adversarial loss: 0.397141\n",
      "epoch 33; iter: 200; batch classifier loss: 0.322575; batch adversarial loss: 0.466636\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410883; batch adversarial loss: 0.475521\n",
      "epoch 34; iter: 200; batch classifier loss: 0.371455; batch adversarial loss: 0.415297\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367911; batch adversarial loss: 0.381311\n",
      "epoch 35; iter: 200; batch classifier loss: 0.282097; batch adversarial loss: 0.449320\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406239; batch adversarial loss: 0.418102\n",
      "epoch 36; iter: 200; batch classifier loss: 0.363184; batch adversarial loss: 0.448575\n",
      "epoch 37; iter: 0; batch classifier loss: 0.336534; batch adversarial loss: 0.509523\n",
      "epoch 37; iter: 200; batch classifier loss: 0.396052; batch adversarial loss: 0.417052\n",
      "epoch 38; iter: 0; batch classifier loss: 0.329271; batch adversarial loss: 0.327611\n",
      "epoch 38; iter: 200; batch classifier loss: 0.312668; batch adversarial loss: 0.408005\n",
      "epoch 39; iter: 0; batch classifier loss: 0.258474; batch adversarial loss: 0.386235\n",
      "epoch 39; iter: 200; batch classifier loss: 0.334143; batch adversarial loss: 0.422566\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412062; batch adversarial loss: 0.480045\n",
      "epoch 40; iter: 200; batch classifier loss: 0.345217; batch adversarial loss: 0.399206\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230081; batch adversarial loss: 0.301653\n",
      "epoch 41; iter: 200; batch classifier loss: 0.428654; batch adversarial loss: 0.430002\n",
      "epoch 42; iter: 0; batch classifier loss: 0.320888; batch adversarial loss: 0.540726\n",
      "epoch 42; iter: 200; batch classifier loss: 0.383879; batch adversarial loss: 0.329476\n",
      "epoch 43; iter: 0; batch classifier loss: 0.347815; batch adversarial loss: 0.436002\n",
      "epoch 43; iter: 200; batch classifier loss: 0.386538; batch adversarial loss: 0.404979\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430751; batch adversarial loss: 0.484266\n",
      "epoch 44; iter: 200; batch classifier loss: 0.307353; batch adversarial loss: 0.366803\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446077; batch adversarial loss: 0.364599\n",
      "epoch 45; iter: 200; batch classifier loss: 0.310562; batch adversarial loss: 0.420536\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317908; batch adversarial loss: 0.349113\n",
      "epoch 46; iter: 200; batch classifier loss: 0.340373; batch adversarial loss: 0.328846\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340560; batch adversarial loss: 0.437637\n",
      "epoch 47; iter: 200; batch classifier loss: 0.314386; batch adversarial loss: 0.394804\n",
      "epoch 48; iter: 0; batch classifier loss: 0.292252; batch adversarial loss: 0.384174\n",
      "epoch 48; iter: 200; batch classifier loss: 0.365934; batch adversarial loss: 0.461156\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412299; batch adversarial loss: 0.409486\n",
      "epoch 49; iter: 200; batch classifier loss: 0.333582; batch adversarial loss: 0.397878\n",
      "epoch 0; iter: 0; batch classifier loss: 14.892906; batch adversarial loss: 1.337332\n",
      "epoch 0; iter: 200; batch classifier loss: 4.265629; batch adversarial loss: 0.911365\n",
      "epoch 1; iter: 0; batch classifier loss: 20.423288; batch adversarial loss: 0.867579\n",
      "epoch 1; iter: 200; batch classifier loss: 4.517181; batch adversarial loss: 0.566793\n",
      "epoch 2; iter: 0; batch classifier loss: 7.107878; batch adversarial loss: 0.672113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 200; batch classifier loss: 11.996395; batch adversarial loss: 0.580438\n",
      "epoch 3; iter: 0; batch classifier loss: 1.880728; batch adversarial loss: 0.550961\n",
      "epoch 3; iter: 200; batch classifier loss: 1.629515; batch adversarial loss: 0.433547\n",
      "epoch 4; iter: 0; batch classifier loss: 5.742574; batch adversarial loss: 0.511901\n",
      "epoch 4; iter: 200; batch classifier loss: 1.285036; batch adversarial loss: 0.428534\n",
      "epoch 5; iter: 0; batch classifier loss: 1.638271; batch adversarial loss: 0.500204\n",
      "epoch 5; iter: 200; batch classifier loss: 3.124608; batch adversarial loss: 0.427560\n",
      "epoch 6; iter: 0; batch classifier loss: 1.472153; batch adversarial loss: 0.480381\n",
      "epoch 6; iter: 200; batch classifier loss: 3.251405; batch adversarial loss: 0.416129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.951004; batch adversarial loss: 0.528275\n",
      "epoch 7; iter: 200; batch classifier loss: 0.420186; batch adversarial loss: 0.345917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416968; batch adversarial loss: 0.467191\n",
      "epoch 8; iter: 200; batch classifier loss: 0.562211; batch adversarial loss: 0.404440\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367643; batch adversarial loss: 0.423520\n",
      "epoch 9; iter: 200; batch classifier loss: 0.389346; batch adversarial loss: 0.423585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550950; batch adversarial loss: 0.407416\n",
      "epoch 10; iter: 200; batch classifier loss: 0.644147; batch adversarial loss: 0.448582\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530117; batch adversarial loss: 0.372610\n",
      "epoch 11; iter: 200; batch classifier loss: 0.405430; batch adversarial loss: 0.388982\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504095; batch adversarial loss: 0.418402\n",
      "epoch 12; iter: 200; batch classifier loss: 0.565501; batch adversarial loss: 0.422529\n",
      "epoch 13; iter: 0; batch classifier loss: 0.585384; batch adversarial loss: 0.366391\n",
      "epoch 13; iter: 200; batch classifier loss: 0.449002; batch adversarial loss: 0.415040\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387210; batch adversarial loss: 0.483412\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379676; batch adversarial loss: 0.387887\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374131; batch adversarial loss: 0.428081\n",
      "epoch 15; iter: 200; batch classifier loss: 0.463155; batch adversarial loss: 0.493717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413568; batch adversarial loss: 0.420925\n",
      "epoch 16; iter: 200; batch classifier loss: 0.334009; batch adversarial loss: 0.369148\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496492; batch adversarial loss: 0.445600\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346221; batch adversarial loss: 0.415605\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477212; batch adversarial loss: 0.345382\n",
      "epoch 18; iter: 200; batch classifier loss: 0.406459; batch adversarial loss: 0.382081\n",
      "epoch 19; iter: 0; batch classifier loss: 0.423399; batch adversarial loss: 0.348243\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350210; batch adversarial loss: 0.438159\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494177; batch adversarial loss: 0.337209\n",
      "epoch 20; iter: 200; batch classifier loss: 0.322471; batch adversarial loss: 0.394753\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431454; batch adversarial loss: 0.466096\n",
      "epoch 21; iter: 200; batch classifier loss: 0.331073; batch adversarial loss: 0.383535\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332080; batch adversarial loss: 0.386951\n",
      "epoch 22; iter: 200; batch classifier loss: 0.424346; batch adversarial loss: 0.323706\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280927; batch adversarial loss: 0.473223\n",
      "epoch 23; iter: 200; batch classifier loss: 0.340972; batch adversarial loss: 0.396089\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381233; batch adversarial loss: 0.454603\n",
      "epoch 24; iter: 200; batch classifier loss: 0.465759; batch adversarial loss: 0.463080\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371495; batch adversarial loss: 0.422889\n",
      "epoch 25; iter: 200; batch classifier loss: 0.269596; batch adversarial loss: 0.537960\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439041; batch adversarial loss: 0.327040\n",
      "epoch 26; iter: 200; batch classifier loss: 0.422355; batch adversarial loss: 0.401576\n",
      "epoch 27; iter: 0; batch classifier loss: 0.375097; batch adversarial loss: 0.479848\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328204; batch adversarial loss: 0.406750\n",
      "epoch 28; iter: 0; batch classifier loss: 0.349092; batch adversarial loss: 0.371300\n",
      "epoch 28; iter: 200; batch classifier loss: 0.298339; batch adversarial loss: 0.408055\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313859; batch adversarial loss: 0.361388\n",
      "epoch 29; iter: 200; batch classifier loss: 0.294757; batch adversarial loss: 0.468770\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329788; batch adversarial loss: 0.448369\n",
      "epoch 30; iter: 200; batch classifier loss: 0.461832; batch adversarial loss: 0.397478\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446117; batch adversarial loss: 0.471468\n",
      "epoch 31; iter: 200; batch classifier loss: 0.353867; batch adversarial loss: 0.443871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.399893; batch adversarial loss: 0.464467\n",
      "epoch 32; iter: 200; batch classifier loss: 0.391569; batch adversarial loss: 0.367444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348576; batch adversarial loss: 0.387722\n",
      "epoch 33; iter: 200; batch classifier loss: 0.320165; batch adversarial loss: 0.432094\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389325; batch adversarial loss: 0.315413\n",
      "epoch 34; iter: 200; batch classifier loss: 0.277984; batch adversarial loss: 0.374024\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319890; batch adversarial loss: 0.524191\n",
      "epoch 35; iter: 200; batch classifier loss: 0.300301; batch adversarial loss: 0.335925\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343381; batch adversarial loss: 0.427581\n",
      "epoch 36; iter: 200; batch classifier loss: 0.366562; batch adversarial loss: 0.461920\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405348; batch adversarial loss: 0.362628\n",
      "epoch 37; iter: 200; batch classifier loss: 0.376166; batch adversarial loss: 0.345990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.318568; batch adversarial loss: 0.445606\n",
      "epoch 38; iter: 200; batch classifier loss: 0.378791; batch adversarial loss: 0.414416\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399381; batch adversarial loss: 0.373302\n",
      "epoch 39; iter: 200; batch classifier loss: 0.327749; batch adversarial loss: 0.358808\n",
      "epoch 40; iter: 0; batch classifier loss: 0.336272; batch adversarial loss: 0.472988\n",
      "epoch 40; iter: 200; batch classifier loss: 0.336628; batch adversarial loss: 0.343698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267559; batch adversarial loss: 0.371946\n",
      "epoch 41; iter: 200; batch classifier loss: 0.385828; batch adversarial loss: 0.342683\n",
      "epoch 42; iter: 0; batch classifier loss: 0.309943; batch adversarial loss: 0.384366\n",
      "epoch 42; iter: 200; batch classifier loss: 0.384991; batch adversarial loss: 0.421847\n",
      "epoch 43; iter: 0; batch classifier loss: 0.304102; batch adversarial loss: 0.317341\n",
      "epoch 43; iter: 200; batch classifier loss: 0.368022; batch adversarial loss: 0.436034\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378193; batch adversarial loss: 0.403263\n",
      "epoch 44; iter: 200; batch classifier loss: 0.463321; batch adversarial loss: 0.321573\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455307; batch adversarial loss: 0.473989\n",
      "epoch 45; iter: 200; batch classifier loss: 0.286121; batch adversarial loss: 0.403395\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433413; batch adversarial loss: 0.397097\n",
      "epoch 46; iter: 200; batch classifier loss: 0.422455; batch adversarial loss: 0.347769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373321; batch adversarial loss: 0.384916\n",
      "epoch 47; iter: 200; batch classifier loss: 0.471244; batch adversarial loss: 0.392785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422794; batch adversarial loss: 0.436257\n",
      "epoch 48; iter: 200; batch classifier loss: 0.336931; batch adversarial loss: 0.352224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422306; batch adversarial loss: 0.349562\n",
      "epoch 49; iter: 200; batch classifier loss: 0.311838; batch adversarial loss: 0.502256\n",
      "epoch 0; iter: 0; batch classifier loss: 87.649834; batch adversarial loss: 0.645956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 200; batch classifier loss: 6.966563; batch adversarial loss: 0.619411\n",
      "epoch 1; iter: 0; batch classifier loss: 11.899750; batch adversarial loss: 0.596918\n",
      "epoch 1; iter: 200; batch classifier loss: 3.605996; batch adversarial loss: 0.519822\n",
      "epoch 2; iter: 0; batch classifier loss: 2.431391; batch adversarial loss: 0.558654\n",
      "epoch 2; iter: 200; batch classifier loss: 1.908173; batch adversarial loss: 0.536450\n",
      "epoch 3; iter: 0; batch classifier loss: 2.704957; batch adversarial loss: 0.428824\n",
      "epoch 3; iter: 200; batch classifier loss: 2.023658; batch adversarial loss: 0.423146\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612531; batch adversarial loss: 0.457823\n",
      "epoch 4; iter: 200; batch classifier loss: 1.992843; batch adversarial loss: 0.404866\n",
      "epoch 5; iter: 0; batch classifier loss: 2.235471; batch adversarial loss: 0.346411\n",
      "epoch 5; iter: 200; batch classifier loss: 2.007464; batch adversarial loss: 0.377987\n",
      "epoch 6; iter: 0; batch classifier loss: 2.075370; batch adversarial loss: 0.469681\n",
      "epoch 6; iter: 200; batch classifier loss: 0.206262; batch adversarial loss: 0.472892\n",
      "epoch 7; iter: 0; batch classifier loss: 9.739493; batch adversarial loss: 0.452109\n",
      "epoch 7; iter: 200; batch classifier loss: 2.782314; batch adversarial loss: 0.420317\n",
      "epoch 8; iter: 0; batch classifier loss: 0.792081; batch adversarial loss: 0.426569\n",
      "epoch 8; iter: 200; batch classifier loss: 0.893860; batch adversarial loss: 0.386219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587582; batch adversarial loss: 0.415906\n",
      "epoch 9; iter: 200; batch classifier loss: 0.307363; batch adversarial loss: 0.449078\n",
      "epoch 10; iter: 0; batch classifier loss: 0.774657; batch adversarial loss: 0.449743\n",
      "epoch 10; iter: 200; batch classifier loss: 0.461568; batch adversarial loss: 0.402594\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602892; batch adversarial loss: 0.330227\n",
      "epoch 11; iter: 200; batch classifier loss: 0.300918; batch adversarial loss: 0.460681\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253876; batch adversarial loss: 0.474682\n",
      "epoch 12; iter: 200; batch classifier loss: 0.378116; batch adversarial loss: 0.446466\n",
      "epoch 13; iter: 0; batch classifier loss: 0.401748; batch adversarial loss: 0.322297\n",
      "epoch 13; iter: 200; batch classifier loss: 0.348923; batch adversarial loss: 0.517017\n",
      "epoch 14; iter: 0; batch classifier loss: 0.364434; batch adversarial loss: 0.438182\n",
      "epoch 14; iter: 200; batch classifier loss: 0.354806; batch adversarial loss: 0.378929\n",
      "epoch 15; iter: 0; batch classifier loss: 0.439718; batch adversarial loss: 0.372309\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333380; batch adversarial loss: 0.392196\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414968; batch adversarial loss: 0.433749\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375545; batch adversarial loss: 0.333181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.334773; batch adversarial loss: 0.469257\n",
      "epoch 17; iter: 200; batch classifier loss: 0.480277; batch adversarial loss: 0.379875\n",
      "epoch 18; iter: 0; batch classifier loss: 0.393354; batch adversarial loss: 0.366293\n",
      "epoch 18; iter: 200; batch classifier loss: 0.338140; batch adversarial loss: 0.385919\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362381; batch adversarial loss: 0.398417\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365529; batch adversarial loss: 0.460173\n",
      "epoch 20; iter: 0; batch classifier loss: 0.367876; batch adversarial loss: 0.401849\n",
      "epoch 20; iter: 200; batch classifier loss: 0.306285; batch adversarial loss: 0.430214\n",
      "epoch 21; iter: 0; batch classifier loss: 0.363125; batch adversarial loss: 0.464898\n",
      "epoch 21; iter: 200; batch classifier loss: 0.323580; batch adversarial loss: 0.361816\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417419; batch adversarial loss: 0.335146\n",
      "epoch 22; iter: 200; batch classifier loss: 0.407188; batch adversarial loss: 0.373348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485280; batch adversarial loss: 0.405733\n",
      "epoch 23; iter: 200; batch classifier loss: 0.310483; batch adversarial loss: 0.434606\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457999; batch adversarial loss: 0.368126\n",
      "epoch 24; iter: 200; batch classifier loss: 0.447112; batch adversarial loss: 0.354306\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327110; batch adversarial loss: 0.365617\n",
      "epoch 25; iter: 200; batch classifier loss: 0.313918; batch adversarial loss: 0.415998\n",
      "epoch 26; iter: 0; batch classifier loss: 0.306849; batch adversarial loss: 0.390486\n",
      "epoch 26; iter: 200; batch classifier loss: 0.342416; batch adversarial loss: 0.418684\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348617; batch adversarial loss: 0.423764\n",
      "epoch 27; iter: 200; batch classifier loss: 0.475847; batch adversarial loss: 0.427590\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351834; batch adversarial loss: 0.397931\n",
      "epoch 28; iter: 200; batch classifier loss: 0.380965; batch adversarial loss: 0.427118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.377594; batch adversarial loss: 0.442797\n",
      "epoch 29; iter: 200; batch classifier loss: 0.329291; batch adversarial loss: 0.450334\n",
      "epoch 30; iter: 0; batch classifier loss: 0.367164; batch adversarial loss: 0.307205\n",
      "epoch 30; iter: 200; batch classifier loss: 0.326946; batch adversarial loss: 0.346212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.336594; batch adversarial loss: 0.319411\n",
      "epoch 31; iter: 200; batch classifier loss: 0.263687; batch adversarial loss: 0.385516\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309308; batch adversarial loss: 0.469912\n",
      "epoch 32; iter: 200; batch classifier loss: 0.307398; batch adversarial loss: 0.430768\n",
      "epoch 33; iter: 0; batch classifier loss: 0.375263; batch adversarial loss: 0.378012\n",
      "epoch 33; iter: 200; batch classifier loss: 0.375006; batch adversarial loss: 0.485396\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392219; batch adversarial loss: 0.336309\n",
      "epoch 34; iter: 200; batch classifier loss: 0.318116; batch adversarial loss: 0.392865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.374873; batch adversarial loss: 0.362522\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347701; batch adversarial loss: 0.419521\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323120; batch adversarial loss: 0.330871\n",
      "epoch 36; iter: 200; batch classifier loss: 0.393780; batch adversarial loss: 0.323236\n",
      "epoch 37; iter: 0; batch classifier loss: 0.313576; batch adversarial loss: 0.334909\n",
      "epoch 37; iter: 200; batch classifier loss: 0.396296; batch adversarial loss: 0.399866\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262504; batch adversarial loss: 0.411279\n",
      "epoch 38; iter: 200; batch classifier loss: 0.368557; batch adversarial loss: 0.394596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362653; batch adversarial loss: 0.349785\n",
      "epoch 39; iter: 200; batch classifier loss: 0.323178; batch adversarial loss: 0.237099\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381989; batch adversarial loss: 0.444154\n",
      "epoch 40; iter: 200; batch classifier loss: 0.330648; batch adversarial loss: 0.347910\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319640; batch adversarial loss: 0.330574\n",
      "epoch 41; iter: 200; batch classifier loss: 0.315511; batch adversarial loss: 0.336999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.312051; batch adversarial loss: 0.444534\n",
      "epoch 42; iter: 200; batch classifier loss: 0.318468; batch adversarial loss: 0.296053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454292; batch adversarial loss: 0.375980\n",
      "epoch 43; iter: 200; batch classifier loss: 0.369314; batch adversarial loss: 0.371255\n",
      "epoch 44; iter: 0; batch classifier loss: 0.337153; batch adversarial loss: 0.400533\n",
      "epoch 44; iter: 200; batch classifier loss: 0.309009; batch adversarial loss: 0.388568\n",
      "epoch 45; iter: 0; batch classifier loss: 0.279704; batch adversarial loss: 0.548734\n",
      "epoch 45; iter: 200; batch classifier loss: 0.334735; batch adversarial loss: 0.365482\n",
      "epoch 46; iter: 0; batch classifier loss: 0.300541; batch adversarial loss: 0.427372\n",
      "epoch 46; iter: 200; batch classifier loss: 0.312498; batch adversarial loss: 0.446112\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464004; batch adversarial loss: 0.368868\n",
      "epoch 47; iter: 200; batch classifier loss: 0.355999; batch adversarial loss: 0.419465\n",
      "epoch 48; iter: 0; batch classifier loss: 0.302942; batch adversarial loss: 0.383670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 200; batch classifier loss: 0.339236; batch adversarial loss: 0.489796\n",
      "epoch 49; iter: 0; batch classifier loss: 0.313936; batch adversarial loss: 0.403936\n",
      "epoch 49; iter: 200; batch classifier loss: 0.301604; batch adversarial loss: 0.380497\n",
      "epoch 0; iter: 0; batch classifier loss: 5.011238; batch adversarial loss: 0.769551\n",
      "epoch 0; iter: 200; batch classifier loss: 7.425304; batch adversarial loss: 0.673340\n",
      "epoch 1; iter: 0; batch classifier loss: 10.360415; batch adversarial loss: 0.639864\n",
      "epoch 1; iter: 200; batch classifier loss: 5.809455; batch adversarial loss: 0.553599\n",
      "epoch 2; iter: 0; batch classifier loss: 2.536075; batch adversarial loss: 0.569865\n",
      "epoch 2; iter: 200; batch classifier loss: 2.650975; batch adversarial loss: 0.489792\n",
      "epoch 3; iter: 0; batch classifier loss: 2.529573; batch adversarial loss: 0.528549\n",
      "epoch 3; iter: 200; batch classifier loss: 1.404363; batch adversarial loss: 0.468081\n",
      "epoch 4; iter: 0; batch classifier loss: 1.008184; batch adversarial loss: 0.532409\n",
      "epoch 4; iter: 200; batch classifier loss: 0.775029; batch adversarial loss: 0.546171\n",
      "epoch 5; iter: 0; batch classifier loss: 1.295835; batch adversarial loss: 0.446907\n",
      "epoch 5; iter: 200; batch classifier loss: 1.274378; batch adversarial loss: 0.410897\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591933; batch adversarial loss: 0.445191\n",
      "epoch 6; iter: 200; batch classifier loss: 0.844520; batch adversarial loss: 0.464724\n",
      "epoch 7; iter: 0; batch classifier loss: 0.802937; batch adversarial loss: 0.378158\n",
      "epoch 7; iter: 200; batch classifier loss: 0.370609; batch adversarial loss: 0.403319\n",
      "epoch 8; iter: 0; batch classifier loss: 1.279632; batch adversarial loss: 0.413171\n",
      "epoch 8; iter: 200; batch classifier loss: 0.646498; batch adversarial loss: 0.365927\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343269; batch adversarial loss: 0.568505\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379042; batch adversarial loss: 0.432689\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426667; batch adversarial loss: 0.450596\n",
      "epoch 10; iter: 200; batch classifier loss: 0.460508; batch adversarial loss: 0.473574\n",
      "epoch 11; iter: 0; batch classifier loss: 0.427799; batch adversarial loss: 0.402635\n",
      "epoch 11; iter: 200; batch classifier loss: 0.424656; batch adversarial loss: 0.464480\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391328; batch adversarial loss: 0.431369\n",
      "epoch 12; iter: 200; batch classifier loss: 0.327947; batch adversarial loss: 0.312683\n",
      "epoch 13; iter: 0; batch classifier loss: 0.296538; batch adversarial loss: 0.373010\n",
      "epoch 13; iter: 200; batch classifier loss: 0.465397; batch adversarial loss: 0.390121\n",
      "epoch 14; iter: 0; batch classifier loss: 0.441563; batch adversarial loss: 0.395814\n",
      "epoch 14; iter: 200; batch classifier loss: 0.396798; batch adversarial loss: 0.445380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311768; batch adversarial loss: 0.410666\n",
      "epoch 15; iter: 200; batch classifier loss: 0.418837; batch adversarial loss: 0.417458\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337030; batch adversarial loss: 0.357663\n",
      "epoch 16; iter: 200; batch classifier loss: 0.349937; batch adversarial loss: 0.442001\n",
      "epoch 17; iter: 0; batch classifier loss: 0.445764; batch adversarial loss: 0.427562\n",
      "epoch 17; iter: 200; batch classifier loss: 0.397703; batch adversarial loss: 0.472261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353622; batch adversarial loss: 0.354097\n",
      "epoch 18; iter: 200; batch classifier loss: 0.405369; batch adversarial loss: 0.414075\n",
      "epoch 19; iter: 0; batch classifier loss: 0.329995; batch adversarial loss: 0.459958\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316712; batch adversarial loss: 0.398467\n",
      "epoch 20; iter: 0; batch classifier loss: 0.336318; batch adversarial loss: 0.394280\n",
      "epoch 20; iter: 200; batch classifier loss: 0.452433; batch adversarial loss: 0.341359\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289446; batch adversarial loss: 0.447060\n",
      "epoch 21; iter: 200; batch classifier loss: 0.271197; batch adversarial loss: 0.329965\n",
      "epoch 22; iter: 0; batch classifier loss: 0.410565; batch adversarial loss: 0.454474\n",
      "epoch 22; iter: 200; batch classifier loss: 0.412751; batch adversarial loss: 0.343457\n",
      "epoch 23; iter: 0; batch classifier loss: 0.793552; batch adversarial loss: 0.479933\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371390; batch adversarial loss: 0.542169\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353204; batch adversarial loss: 0.463336\n",
      "epoch 24; iter: 200; batch classifier loss: 0.356063; batch adversarial loss: 0.485596\n",
      "epoch 25; iter: 0; batch classifier loss: 0.337878; batch adversarial loss: 0.351557\n",
      "epoch 25; iter: 200; batch classifier loss: 0.397429; batch adversarial loss: 0.322319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413322; batch adversarial loss: 0.432851\n",
      "epoch 26; iter: 200; batch classifier loss: 0.369222; batch adversarial loss: 0.309139\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416258; batch adversarial loss: 0.469640\n",
      "epoch 27; iter: 200; batch classifier loss: 0.386875; batch adversarial loss: 0.478462\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460168; batch adversarial loss: 0.410666\n",
      "epoch 28; iter: 200; batch classifier loss: 0.381052; batch adversarial loss: 0.401499\n",
      "epoch 29; iter: 0; batch classifier loss: 0.344820; batch adversarial loss: 0.449779\n",
      "epoch 29; iter: 200; batch classifier loss: 0.335965; batch adversarial loss: 0.355076\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433650; batch adversarial loss: 0.351150\n",
      "epoch 30; iter: 200; batch classifier loss: 0.313074; batch adversarial loss: 0.499647\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429718; batch adversarial loss: 0.403836\n",
      "epoch 31; iter: 200; batch classifier loss: 0.278453; batch adversarial loss: 0.352034\n",
      "epoch 32; iter: 0; batch classifier loss: 0.351419; batch adversarial loss: 0.432798\n",
      "epoch 32; iter: 200; batch classifier loss: 0.324964; batch adversarial loss: 0.391755\n",
      "epoch 33; iter: 0; batch classifier loss: 0.248857; batch adversarial loss: 0.391340\n",
      "epoch 33; iter: 200; batch classifier loss: 0.559378; batch adversarial loss: 0.442321\n",
      "epoch 34; iter: 0; batch classifier loss: 0.316293; batch adversarial loss: 0.483855\n",
      "epoch 34; iter: 200; batch classifier loss: 0.430380; batch adversarial loss: 0.347164\n",
      "epoch 35; iter: 0; batch classifier loss: 0.306275; batch adversarial loss: 0.335706\n",
      "epoch 35; iter: 200; batch classifier loss: 0.321648; batch adversarial loss: 0.497366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.372491; batch adversarial loss: 0.318165\n",
      "epoch 36; iter: 200; batch classifier loss: 0.334817; batch adversarial loss: 0.352754\n",
      "epoch 37; iter: 0; batch classifier loss: 0.354847; batch adversarial loss: 0.549877\n",
      "epoch 37; iter: 200; batch classifier loss: 0.333238; batch adversarial loss: 0.396303\n",
      "epoch 38; iter: 0; batch classifier loss: 0.401173; batch adversarial loss: 0.459927\n",
      "epoch 38; iter: 200; batch classifier loss: 0.353090; batch adversarial loss: 0.402926\n",
      "epoch 39; iter: 0; batch classifier loss: 0.426607; batch adversarial loss: 0.394637\n",
      "epoch 39; iter: 200; batch classifier loss: 0.345504; batch adversarial loss: 0.376419\n",
      "epoch 40; iter: 0; batch classifier loss: 0.343131; batch adversarial loss: 0.449907\n",
      "epoch 40; iter: 200; batch classifier loss: 0.332949; batch adversarial loss: 0.388136\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403639; batch adversarial loss: 0.362738\n",
      "epoch 41; iter: 200; batch classifier loss: 0.326178; batch adversarial loss: 0.376672\n",
      "epoch 42; iter: 0; batch classifier loss: 0.330214; batch adversarial loss: 0.343926\n",
      "epoch 42; iter: 200; batch classifier loss: 0.303515; batch adversarial loss: 0.503233\n",
      "epoch 43; iter: 0; batch classifier loss: 0.295893; batch adversarial loss: 0.380397\n",
      "epoch 43; iter: 200; batch classifier loss: 0.368348; batch adversarial loss: 0.390803\n",
      "epoch 44; iter: 0; batch classifier loss: 0.331792; batch adversarial loss: 0.452441\n",
      "epoch 44; iter: 200; batch classifier loss: 0.385503; batch adversarial loss: 0.436161\n",
      "epoch 45; iter: 0; batch classifier loss: 0.249969; batch adversarial loss: 0.424603\n",
      "epoch 45; iter: 200; batch classifier loss: 0.406399; batch adversarial loss: 0.361660\n",
      "epoch 46; iter: 0; batch classifier loss: 0.348458; batch adversarial loss: 0.363133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 200; batch classifier loss: 0.287770; batch adversarial loss: 0.455077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.354398; batch adversarial loss: 0.548461\n",
      "epoch 47; iter: 200; batch classifier loss: 0.360498; batch adversarial loss: 0.385005\n",
      "epoch 48; iter: 0; batch classifier loss: 0.323066; batch adversarial loss: 0.389321\n",
      "epoch 48; iter: 200; batch classifier loss: 0.234073; batch adversarial loss: 0.348227\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428525; batch adversarial loss: 0.376637\n",
      "epoch 49; iter: 200; batch classifier loss: 0.403683; batch adversarial loss: 0.389120\n",
      "epoch 0; iter: 0; batch classifier loss: 34.946327; batch adversarial loss: 1.059033\n",
      "epoch 0; iter: 200; batch classifier loss: 7.362378; batch adversarial loss: 0.867830\n",
      "epoch 1; iter: 0; batch classifier loss: 1.984664; batch adversarial loss: 0.686881\n",
      "epoch 1; iter: 200; batch classifier loss: 4.448523; batch adversarial loss: 0.683302\n",
      "epoch 2; iter: 0; batch classifier loss: 6.946095; batch adversarial loss: 0.701050\n",
      "epoch 2; iter: 200; batch classifier loss: 1.267366; batch adversarial loss: 0.523172\n",
      "epoch 3; iter: 0; batch classifier loss: 4.265534; batch adversarial loss: 0.581720\n",
      "epoch 3; iter: 200; batch classifier loss: 0.653782; batch adversarial loss: 0.496726\n",
      "epoch 4; iter: 0; batch classifier loss: 1.067804; batch adversarial loss: 0.462995\n",
      "epoch 4; iter: 200; batch classifier loss: 0.927153; batch adversarial loss: 0.441050\n",
      "epoch 5; iter: 0; batch classifier loss: 0.933908; batch adversarial loss: 0.470554\n",
      "epoch 5; iter: 200; batch classifier loss: 0.836156; batch adversarial loss: 0.455307\n",
      "epoch 6; iter: 0; batch classifier loss: 0.890567; batch adversarial loss: 0.404862\n",
      "epoch 6; iter: 200; batch classifier loss: 2.033178; batch adversarial loss: 0.472778\n",
      "epoch 7; iter: 0; batch classifier loss: 0.650603; batch adversarial loss: 0.485745\n",
      "epoch 7; iter: 200; batch classifier loss: 0.937080; batch adversarial loss: 0.423830\n",
      "epoch 8; iter: 0; batch classifier loss: 0.642121; batch adversarial loss: 0.337238\n",
      "epoch 8; iter: 200; batch classifier loss: 0.431224; batch adversarial loss: 0.408579\n",
      "epoch 9; iter: 0; batch classifier loss: 0.325895; batch adversarial loss: 0.437087\n",
      "epoch 9; iter: 200; batch classifier loss: 0.461111; batch adversarial loss: 0.395342\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582070; batch adversarial loss: 0.322465\n",
      "epoch 10; iter: 200; batch classifier loss: 0.391173; batch adversarial loss: 0.436737\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537611; batch adversarial loss: 0.399127\n",
      "epoch 11; iter: 200; batch classifier loss: 0.315948; batch adversarial loss: 0.345073\n",
      "epoch 12; iter: 0; batch classifier loss: 0.588549; batch adversarial loss: 0.283377\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429305; batch adversarial loss: 0.349441\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430988; batch adversarial loss: 0.549330\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353779; batch adversarial loss: 0.350711\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559705; batch adversarial loss: 0.462441\n",
      "epoch 14; iter: 200; batch classifier loss: 0.434068; batch adversarial loss: 0.366183\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415102; batch adversarial loss: 0.473140\n",
      "epoch 15; iter: 200; batch classifier loss: 0.397832; batch adversarial loss: 0.493263\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442922; batch adversarial loss: 0.359629\n",
      "epoch 16; iter: 200; batch classifier loss: 0.436705; batch adversarial loss: 0.496547\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392539; batch adversarial loss: 0.486666\n",
      "epoch 17; iter: 200; batch classifier loss: 0.528273; batch adversarial loss: 0.416390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448965; batch adversarial loss: 0.350956\n",
      "epoch 18; iter: 200; batch classifier loss: 0.304817; batch adversarial loss: 0.428117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365603; batch adversarial loss: 0.407248\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387132; batch adversarial loss: 0.373728\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368206; batch adversarial loss: 0.412064\n",
      "epoch 20; iter: 200; batch classifier loss: 0.412310; batch adversarial loss: 0.343809\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455162; batch adversarial loss: 0.410894\n",
      "epoch 21; iter: 200; batch classifier loss: 0.437294; batch adversarial loss: 0.359777\n",
      "epoch 22; iter: 0; batch classifier loss: 0.383487; batch adversarial loss: 0.383186\n",
      "epoch 22; iter: 200; batch classifier loss: 0.487862; batch adversarial loss: 0.364522\n",
      "epoch 23; iter: 0; batch classifier loss: 0.365124; batch adversarial loss: 0.374713\n",
      "epoch 23; iter: 200; batch classifier loss: 0.328818; batch adversarial loss: 0.352073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.412255; batch adversarial loss: 0.478841\n",
      "epoch 24; iter: 200; batch classifier loss: 0.427845; batch adversarial loss: 0.485795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.322861; batch adversarial loss: 0.383649\n",
      "epoch 25; iter: 200; batch classifier loss: 0.287584; batch adversarial loss: 0.314651\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363689; batch adversarial loss: 0.403311\n",
      "epoch 26; iter: 200; batch classifier loss: 0.331834; batch adversarial loss: 0.459603\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377610; batch adversarial loss: 0.316779\n",
      "epoch 27; iter: 200; batch classifier loss: 0.350313; batch adversarial loss: 0.372725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397979; batch adversarial loss: 0.399835\n",
      "epoch 28; iter: 200; batch classifier loss: 0.343143; batch adversarial loss: 0.505400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.348161; batch adversarial loss: 0.510084\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338245; batch adversarial loss: 0.373579\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390384; batch adversarial loss: 0.500613\n",
      "epoch 30; iter: 200; batch classifier loss: 0.427254; batch adversarial loss: 0.522550\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390794; batch adversarial loss: 0.365332\n",
      "epoch 31; iter: 200; batch classifier loss: 0.461955; batch adversarial loss: 0.407058\n",
      "epoch 32; iter: 0; batch classifier loss: 0.388725; batch adversarial loss: 0.378621\n",
      "epoch 32; iter: 200; batch classifier loss: 0.298322; batch adversarial loss: 0.369160\n",
      "epoch 33; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.387254\n",
      "epoch 33; iter: 200; batch classifier loss: 0.325124; batch adversarial loss: 0.472651\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350107; batch adversarial loss: 0.393822\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328226; batch adversarial loss: 0.444728\n",
      "epoch 35; iter: 0; batch classifier loss: 0.295142; batch adversarial loss: 0.366563\n",
      "epoch 35; iter: 200; batch classifier loss: 0.294195; batch adversarial loss: 0.414538\n",
      "epoch 36; iter: 0; batch classifier loss: 0.322890; batch adversarial loss: 0.467864\n",
      "epoch 36; iter: 200; batch classifier loss: 0.329924; batch adversarial loss: 0.289051\n",
      "epoch 37; iter: 0; batch classifier loss: 0.283582; batch adversarial loss: 0.491118\n",
      "epoch 37; iter: 200; batch classifier loss: 0.313632; batch adversarial loss: 0.457031\n",
      "epoch 38; iter: 0; batch classifier loss: 0.297276; batch adversarial loss: 0.372616\n",
      "epoch 38; iter: 200; batch classifier loss: 0.316806; batch adversarial loss: 0.391785\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322788; batch adversarial loss: 0.372841\n",
      "epoch 39; iter: 200; batch classifier loss: 0.427804; batch adversarial loss: 0.517191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253547; batch adversarial loss: 0.432489\n",
      "epoch 40; iter: 200; batch classifier loss: 0.328202; batch adversarial loss: 0.452559\n",
      "epoch 41; iter: 0; batch classifier loss: 0.394390; batch adversarial loss: 0.422623\n",
      "epoch 41; iter: 200; batch classifier loss: 0.520950; batch adversarial loss: 0.288951\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396397; batch adversarial loss: 0.470997\n",
      "epoch 42; iter: 200; batch classifier loss: 0.325950; batch adversarial loss: 0.394525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.316254; batch adversarial loss: 0.487394\n",
      "epoch 43; iter: 200; batch classifier loss: 0.368356; batch adversarial loss: 0.471982\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375539; batch adversarial loss: 0.408637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 200; batch classifier loss: 0.372456; batch adversarial loss: 0.367216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.347583; batch adversarial loss: 0.461049\n",
      "epoch 45; iter: 200; batch classifier loss: 0.367362; batch adversarial loss: 0.332134\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382968; batch adversarial loss: 0.481443\n",
      "epoch 46; iter: 200; batch classifier loss: 0.349227; batch adversarial loss: 0.436819\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362101; batch adversarial loss: 0.349596\n",
      "epoch 47; iter: 200; batch classifier loss: 0.393379; batch adversarial loss: 0.505211\n",
      "epoch 48; iter: 0; batch classifier loss: 0.344760; batch adversarial loss: 0.385158\n",
      "epoch 48; iter: 200; batch classifier loss: 0.294458; batch adversarial loss: 0.358625\n",
      "epoch 49; iter: 0; batch classifier loss: 0.360043; batch adversarial loss: 0.362116\n",
      "epoch 49; iter: 200; batch classifier loss: 0.358058; batch adversarial loss: 0.427663\n",
      "epoch 0; iter: 0; batch classifier loss: 26.145233; batch adversarial loss: 0.722515\n",
      "epoch 0; iter: 200; batch classifier loss: 3.587595; batch adversarial loss: 0.611389\n",
      "epoch 1; iter: 0; batch classifier loss: 1.063875; batch adversarial loss: 0.586512\n",
      "epoch 1; iter: 200; batch classifier loss: 11.896105; batch adversarial loss: 0.538839\n",
      "epoch 2; iter: 0; batch classifier loss: 6.168639; batch adversarial loss: 0.550196\n",
      "epoch 2; iter: 200; batch classifier loss: 2.829658; batch adversarial loss: 0.466259\n",
      "epoch 3; iter: 0; batch classifier loss: 2.543673; batch adversarial loss: 0.498826\n",
      "epoch 3; iter: 200; batch classifier loss: 2.041200; batch adversarial loss: 0.401598\n",
      "epoch 4; iter: 0; batch classifier loss: 2.669992; batch adversarial loss: 0.451715\n",
      "epoch 4; iter: 200; batch classifier loss: 1.804471; batch adversarial loss: 0.394118\n",
      "epoch 5; iter: 0; batch classifier loss: 1.742771; batch adversarial loss: 0.430779\n",
      "epoch 5; iter: 200; batch classifier loss: 1.012187; batch adversarial loss: 0.386267\n",
      "epoch 6; iter: 0; batch classifier loss: 1.087281; batch adversarial loss: 0.422260\n"
     ]
    }
   ],
   "source": [
    "Search = ModelSearch(models, metrics, hyperparameters, thresholds)\n",
    "Search.grid_search(data_orig, privileged=privileged, unprivileged=unprivileged, preprocessors=preprocessors, postprocessors=postprocessors)\n",
    "\n",
    "Search.to_csv(\"fklearn/interface/static/data/test-file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "2c6e7f3a299b"
   },
   "source": [
    "## Step 5: Render visualization of search results\n",
    "\n",
    "Along with the ability to run a grid search, fairkit-learn also provides functionality to visualize the results of the grid search. Fairkit-learn uses Bokeh to render a visualization within the notebook, which you can use when completing the next task to explore trained models' performance and fairness.\n",
    "\n",
    "The visualzation includes a graph that plots the search results that are pareto optimal. Each data point in the graph is a model with its own settings (e.g., hyper-parameters, pre/post processing). Each model class has its own color to make it easier to see which models are being shown in the visualization. To get more information on each model's settings, hover over the data point of interest; a tooltip will pop up with model settings.\n",
    "\n",
    "Within the visualization, you can control what metrics and models are being included in the visualization. The drop down menus allow you to specify the x and y axes for the graph. The checklist below the list of models allows you to select which metrics can be considered in the graph.\n",
    "\n",
    "To view the *Pareto frontier* for any two metrics (e.g., accuracy and disparate impact), select those two metrics from the drop down menu and **only** check those boxes in the checklist.\n",
    "\n",
    "Below we provide code to load Bokeh and plot the results from the search in the interactive plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "d75c4def39e12"
   },
   "outputs": [],
   "source": [
    "# Import packages for visualization\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.application import Application\n",
    "\n",
    "# load Bokeh\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "2ad7c38dbbfc5"
   },
   "outputs": [],
   "source": [
    "from fklearn.interface.plot import *\n",
    "\n",
    "# Define function that takes in a document and attaches the bokeh server to it\n",
    "def modify_doc(doc):\n",
    "    \n",
    "    # Load custom styles (for notebook only)\n",
    "    custom_css = Div(text=\"<link rel='stylesheet' type='text/css' href='fklearn/interface/static/css/styles-notebook.css'>\")\n",
    "    add_btn = Button(label=\"Add Plot\", button_type=\"success\")\n",
    "    remove_btn = Button(label=\"Remove Plot\", button_type=\"danger\")\n",
    "\n",
    "    # Construct our viewport\n",
    "    l = layout([\n",
    "        [custom_css],\n",
    "        create_plot(\"fklearn/interface/static/data/test-file.csv\")\n",
    "    ], sizing_mode=\"fixed\", css_classes=[\"layout-container\"])\n",
    "\n",
    "    doc.add_root(l)\n",
    "    \n",
    "# Set up the application\n",
    "handler = FunctionHandler(modify_doc)\n",
    "app = Application(handler)\n",
    "\n",
    "# Render visualization in the notebook\n",
    "show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "1b8ebeec276e7"
   },
   "source": [
    "## Step 6: Export visualization (optional)\n",
    "\n",
    "The visualization can be viewed within this notebook and re-rendered as many times as needed, but can also be exported for future viewing and comparison to other plots. You can export the visualization and relevant information by clicking the ``Export Plot`` button in the visualization. \n",
    "\n",
    "This will save create two files: plot.png and plot.json.\n",
    "Plot.png is an image of the plot.\n",
    "Plot.json is a JSON file with the informational bits from the plot, such as what models are being shown and what metrics are selected.\n",
    "\n",
    "Each time the export button is clicked, if plot.png and plot.json exist they are overwritten. If you wish to save plots for comparision, make sure you rename each file after export."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "5b86de1c27a81"
   },
   "source": [
    "## Step 7: Evaluate overall model quality\n",
    "\n",
    "Now that we've explored the various model configurations and their performance and fairness, we are ready to select the model(s) that we want to evaluate for overall quality.\n",
    "\n",
    "To do so, you will need to create and train the model(s) (with proper hyperparameters, pre-processing, and post-processing as specified in the search output) you selected and then evaluate overall model quality.\n",
    "\n",
    "Below we provide (commented) code that shows how to intialize the various models and algorithms you have access to. You can use the code provided or modify as you see fit when completing the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "3abfa158b66ed"
   },
   "outputs": [],
   "source": [
    "# split dataset for evaluation\n",
    "# data_orig_train, data_orig_test = data_orig.split([0.7], shuffle=False)\n",
    "\n",
    "# model is populated with default values; modifying parameters is allowed but optional\n",
    "# model = LogisticRegression(penalty='l2', dual=False,tol=0.0001,C=1.0,\n",
    "#                       fit_intercept=True,intercept_scaling=1,class_weight=None,\n",
    "#                       random_state=None,solver='liblinear',max_iter=100, \n",
    "#                       multi_class='warn',verbose=0,warm_start=False,\n",
    "#                       n_jobs=None)\n",
    "\n",
    "#model = KNeighborsClassifier(n_neighbors=5,weights='uniform',algorithm='auto',\n",
    "#                          leaf_size=30,p=2,metric='minkowski',metric_params=None,\n",
    "#                          n_jobs=None)\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators='warn',criterion='gini',max_depth=None,\n",
    "#                            min_samples_leaf=1,min_weight_fraction_leaf=0.0,\n",
    "#                            min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "#                             random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "#model = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, \n",
    "#          probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "#          max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "\n",
    "# If this is not your first time creating the Adversarial Debiasing model, to avoid future errors,\n",
    "# uncomment the code below before running the code that initializing TensorFlow session and model:\n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "#sess = tf.Session()\n",
    "#model = AdversarialDebiasing(privileged_groups=privileged,\n",
    "#                          unprivileged_groups=unprivileged,\n",
    "#                          scope_name='debiased_classifier',\n",
    "#                          debias=True,\n",
    "#                          sess=sess)\n",
    "\n",
    "\n",
    "# you can modify repair level (optional)\n",
    "#pre_alg = DisparateImpactRemover(repair_level=1.0)\n",
    "# training data\n",
    "#pre_train_data = pre_alg.fit_transform(data_orig_train)\n",
    "# test data\n",
    "#pre_test_data = pre_alg.fit_transform(data_orig_test)\n",
    "\n",
    "\n",
    "\n",
    "# Reweighing\n",
    "\n",
    "#pre_alg = Reweighing(unprivileged_groups=unprivileged, privileged_groups=privileged)\n",
    "# train\n",
    "#pre_alg = pre_alg.fit(dataset_orig_train)\n",
    "#pre_train_data = pre_alg.transform(data_orig_train)\n",
    "# test\n",
    "#pre_alg = pre_alg.fit(dataset_orig_test)\n",
    "#pre_test_data = pre_alg.transform(data_orig_test)\n",
    "\n",
    "\n",
    "# train model with pre-processed data\n",
    "#model.fit(pre_train_data)\n",
    "\n",
    "# train model with original data \n",
    "# model.fit(data_orig_train)\n",
    "\n",
    "\n",
    "# process trained model\n",
    "# Calibrated Equal Odds\n",
    "#post_alg = CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged,\n",
    "#                                         privileged_groups=privileged,\n",
    "#                                         cost_constraint='weighted',\n",
    "#                                         seed=None)\n",
    "\n",
    "\n",
    "\n",
    "# Reject Option Classification \n",
    "# With this algorithm, you can specify \"metric_name\" with the metric you want to optimize for.\n",
    "# The options are \"Statistical parity difference\", \"Average odds difference\", or \"Equal opportunity difference\"\n",
    "\n",
    "# post_alg = RejectOptionClassification(unprivileged_groups=unprivileged,\n",
    "#                                      privileged_groups=privileged,\n",
    "#                                      low_class_thresh=0.01,\n",
    "#                                      high_class_thresh=0.99,num_class_thresh=100, \n",
    "#                                      num_ROC_margin=50,metric_name='Statistical parity difference',\n",
    "#                                      metric_ub=0.05, metric_lb=-0.05)\n",
    "\n",
    "\n",
    "\n",
    "# test with pre-processed test data\n",
    "#predictions = model.predict(pre_test_data)\n",
    "\n",
    "# test with original test data\n",
    "# predictions = model.predict(data_orig_test)\n",
    "\n",
    "\n",
    "# fit with post-processing model using pre-processed data\n",
    "#post_model = post_alg.fit(pre_test_data, predictions)\n",
    "\n",
    "# fit with post-processing model using original data\n",
    "# post_model = post_alg.fit(data_orig_test, predictions)\n",
    "\n",
    "\n",
    "\n",
    "# update predictions using post-processed model\n",
    "#predictions = post_model.predict(pre_test_data)\n",
    "\n",
    "# evaluate overall model quality on post-processed model\n",
    "#quality_score = classifier_quality_score(post_model, predictions, \n",
    "#                                             unprivileged_groups=unprivileged, \n",
    "#                                             privileged_groups=privileged)\n",
    "\n",
    "# evaluate overall model quality on model without post-processing\n",
    "#quality_score = classifier_quality_score(model, predictions, \n",
    "#                                             unprivileged_groups=unprivileged, \n",
    "#                                             privileged_groups=privileged)\n",
    "\n",
    "#print(\"Overall quality = \" + str(quality_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "f01ce8da8c30d"
   },
   "source": [
    "# Task 3: Model evaluation with fairkit-learn\n",
    "\n",
    "Your turn again! Use what you learned in the above tutorial to train and evaluate models for performance, fairness, and overall quality. You will use functionality provided by fairkit-learn to meet the following goals:\n",
    "\n",
    "1. **Describe a model you believe will perform the best (e.g., have the highest accuracy score).** \n",
    "\n",
    "2. **Describe a model you believe will be the most fair, regardless of performance (e.g., minimizes the value of difference fairness metrics or maximizes disparate impact).** \n",
    "\n",
    "3. **Describe a model you believe will best balance both performance and fairness (e.g., have the highest classifier quality score).** \n",
    "\n",
    "Make sure you include any modifications to model hyper-parameters and any pre-/post-processing algorithms used. **As a reminder, there is no \"absolute best\" model for each of the above goals. You are expected to explore the space of model configurations available to find a model that best meets the above goals.**\n",
    "\n",
    "**Keep in mind, training machine learning models is often a time intensive endeavor.** One way you can minimize time to finish this task is to minimize the search space (e.g., number of models included in a single search). You can also minimize time when evaluating the number of times you have to, for example, train a given model to then evaluate it. You can do this by putting the code that initializes and trains your model(s) in its own separate cell and only execute this cell when needed.\n",
    "\n",
    "## Submitting your response\n",
    "\n",
    "Once you feel you've met the above goals, go to the Evaluating ML Models Exercise Response Form to enter your responses under the section labeled 'Task 3'.\n",
    "\n",
    "If you accidentally closed your response form, check your email for the link to re-open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "23c64e4f35267"
   },
   "outputs": [],
   "source": [
    "# TODO : Use this cell to write code for completing task 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "656fbc7fd4794"
   },
   "source": [
    "Once you've completed this final task, make sure you're satisfied with your responses, complete the exercise feedback portion, and submit the form."
   ]
  }
 ],
 "metadata": {
  "comet_paths": [
   [
    "4c7b42fa/ML Model Eval Assignment.ipynb",
    1567249528393
   ],
   [
    "008a0d50/Task 1.ipynb",
    1567536844745
   ],
   [
    "008a0d50/Task_1.ipynb",
    1567538584157
   ],
   [
    "7f57d529/Task_1.ipynb",
    1567557189361
   ],
   [
    "7f57d529/Task_3.ipynb",
    1567557229394
   ],
   [
    "3f045f6d/Task_3.ipynb",
    1567625417784
   ]
  ],
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
